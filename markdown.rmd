---
title: "Raport – Analiza danych Superstore"
author: "Dawid Genert, Agnieszka Ancypo, Sylwia Bech"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    toc_float: true
      
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE
)

pkgs <- c(
  "readxl","dplyr","mice","lubridate","tidyr","naniar","plotly","ggplot2",
  "corrplot","Hmisc","ggstatsplot","classInt","kableExtra","psych",
  "ggridges","frequency"
)

miss <- setdiff(pkgs, rownames(installed.packages()))
if (length(miss)) {
  stop(
    "Brakuje pakietów: ", paste(miss, collapse = ", "),
    "\nZainstaluj je poleceniem z README.md"
  )
}

invisible(lapply(pkgs, library, character.only = TRUE))

dane <- read_excel(file.path("data","superstore.xls"), sheet = 1)
dane_disc <- read_excel(file.path("data","superstore.xls"), sheet = 2)

df <- dane %>%
mutate(
  `Order Date` = as.Date(`Order Date`),
  Sales    = as.numeric(Sales),
  Profit   = as.numeric(Profit),
  Quantity = as.numeric(Quantity),
  Discount = as.numeric(Discount),
  Category = as.character(Category),
  Segment  = as.character(Segment),
  `Ship Date`  = as.Date(`Ship Date`)
)

```

# 1. Wprowadzenie

Celem niniejszego projektu jest analiza zbioru danych "Superstore",
zawierającego informacje o transakcjach detalicznych w sieci sklepów.
Zbiór obejmuje dane o sprzedaży, zyskach, kategoriach produktów oraz
lokalizacji klientów na terenie USA.

Główne pytania badawcze:

1.  Jaki wpływ mają rabaty na zysk - czy większy rabat zawsze zwiększa
    sprzedaż kosztem rentowności?

2.  Które kategorie i podkategorie produktów generują najwyższą
    sprzedaż, a które najwyższy zysk?

3.  Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej)
    rentowności?

4.  Jak zmieniały się sprzedaż i zysk w czasie - czy występuje
    sezonowość?

5.  Które produkty lub podkategorie generują straty i jakie czynniki
    (rabat, region, wysyłka) na to wpływają?

# 2. Data Cleansing & Data Wrangling

Proces przygotowania danych był wieloetapowy, aby zapewnić najwyższą
jakość analizy.

## 2.1. Ogólny przegląd braków danych

Poniższy wykres przedstawia globalną wizualizację kompletności zbioru danych Superstore. Szary obszar reprezentuje obserwacje z kompletnymi danymi (Present > 98.9%), podczas gdy niewielkie czarne fragmenty wskazują na braki w danych (Missing < 0.1%). Każdy wiersz na wykresie odpowiada pojedynczej zmiennej, a każda kolumna reprezentuje kolejne obserwacje w zbiorze.

Kluczowe obserwacje:
- **Wysoka kompletność danych:** Ponad 98.9% wszystkich wartości w zbiorze jest dostępnych, co świadczy o bardzo dobrej jakości danych źródłowych
- **Marginalne braki:** Braki danych stanowią mniej niż 1% całego zbioru, co jest doskonałym wynikiem dla danych transakcyjnych
- **Koncentracja braków:** Czarne linie widoczne w górnej części wykresu wskazują, że braki koncentrują się w określonych zmiennych (prawdopodobnie Discount, Profit oraz dane adresowe), podczas gdy większość zmiennych jest w pełni kompletna
- **Losowy rozkład:** Braki wydają się być rozłożone losowo wzdłuż obserwacji, co sugeruje brak systematycznego wzorca utraty danych związanego z czasem lub procesem zbierania danych
- **Gotowość do analizy:** Minimalny odsetek braków i ich niesystematyczny charakter potwierdzają, że zbiór nadaje się do dalszej analizy po zastosowaniu odpowiednich technik imputacji

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
vis_miss(dane)
```

## 2.2. Rozkład braków według zmiennych

Poniższy wykres słupkowy przedstawia liczbę brakujących wartości (missing values) w każdej zmiennej zbioru danych. Długość słupka odpowiada liczbie obserwacji z brakami. Zmienne są posortowane malejąco według liczby braków, co pozwala na szybką identyfikację najbardziej problematycznych kolumn.

Kluczowe obserwacje:
- **Profit i Discount - istotne braki finansowe:** Zmienne związane z zyskami i rabatami wykazują znaczną liczbę braków, co jest krytyczne dla analizy rentowności i wymaga zaawansowanych technik imputacji
- **Dane adresowe - równomierne braki:** City i State wykazują podobną liczbę braków, co sugeruje, że braki w danych adresowych mogą występować razem w tych samych obserwacjach
- **Order Date i Ship Date - marginalne braki:** Daty mają umiarkowaną liczbę braków, które mogą być imputowane na podstawie logiki biznesowej (mediana czasu dostawy)
- **Większość zmiennych kompletna:** Wiele zmiennych nie ma braków wcale (Sales, Quantity, Category, Sub-Category, Region, Product ID, Order ID, Customer ID), co potwierdza ogólną dobrą jakość danych
- **Wymiar problemu:** Koncentracja braków w kilku kluczowych zmiennych (Postal Code, Profit, Discount, City, State) oznacza, że strategia imputacji powinna być priorytetowo skierowana na te obszary, podczas gdy reszta zbioru pozostaje w pełni użyteczna

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
gg_miss_var(dane) +
  labs(title = "Liczba braków danych w każdej zmiennej")
```

## 2.3. Rozkład braków w obserwacjach

Poniższy wykres pokazuje liczbę brakujących wartości w każdej obserwacji (wierszu) zbioru danych. Oś X reprezentuje liczbę braków w każdym wierszu, a oś Y pokazuje kolejne obserwacje. Długość horyzontalnego paska dla każdej obserwacji odpowiada liczbie brakujących danych w tym wierszu.

Kluczowe obserwacje:
- **Większość wierszy kompletnych:** Zdecydowana większość obserwacji (te na górze wykresu) ma bardzo mało braków - prawie zerową liczbę brakujących wartości, co świadczy o dobrej kompletności danych
- **Rozrzedzenie braków:** Braki są rozproszone po poszczególnych wierszach, a nie skupione w kilku obserwacjach, co oznacza, że żaden wiersz nie jest "całkowicie nieużyteczny"
- **Maksymalnie około 1-2 braki na wiersz:** Nawet wiersze z największą liczbą braków mają poniżej 2 brakujących wartości, co jest bardzo dobrym wynikiem
- **Brak wzorca systematycznego:** Rozłożenie braków wzdłuż osi Y wskazuje, że braki nie są skoncentrowane w określonej części zbioru danych (np. na początku lub końcu)
- **Łatwa imputacja:** Ta struktura braków czyni imputację stosunkowo prostą - większość wierszy będzie można użyć bez jakichkolwiek modyfikacji, a dla tych kilku z brakami wystarczą proste strategie uzupełnienia

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
gg_miss_case(dane) +
  labs(title = "Braki danych w poszczególnych wierszach")
```

## 2.4. Kombinacje braków danych - Upset Plot

Poniższy diagram "UpSet" pokazuje, które zmienne mają braki jednocześnie, czyli jakie kombinacje braków danych występują razem. Lewy panel (słupki poziome) pokazuje liczebność poszczególnych braków, a górny panel (słupki pionowe) pokazuje, ile obserwacji ma konkretną kombinację braków. Linie łączące słupki wskazują, które zmienne brakują razem.

Kluczowe obserwacje:
- **Shop Mode NA dominuje:** Braki w zmiennej Shop Mode (dostaw) są najczęstsze i najczęściej pojawią się samodzielnie (bez innych braków)
- **Quantity NA - druga na liście:** Ilość produktów ma drugą co do liczby braków, również głównie niezależnie od innych zmiennych
- **Profit NA - trzeci:** Braki w zysku pojawiają się na trzecim miejscu i również często bez towarzystwa innych braków
- **Sub-Category i Discount - rzadsze braki:** Te zmienne mają mniej braków niż poprzednie
- **Niska współzależność braków:** Brak wyraźnych pionowych linii łączących oznacza, że braki raczej nie kumulują się - czyli jeśli brakuje wartości w Shop Mode, to nie znaczy że będą braki w Quantity czy Profit
- **Imputacja niezależna:** Taka struktura braków sugeruje, że każdą zmienną można imputować niezależnie, bez konieczności rozpatrywania złożonych zależności między brakami

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
gg_miss_upset(dane)
```


## 2.5. Wzory braków danych - Pattern Matrix

Poniższy diagram "md.pattern" przedstawia macierz wzorów braków danych. Każdy wiersz reprezentuje inny wzór braków (kombinację kompletnych i brakujących wartości), a każda kolumna reprezentuje zmienną. Niebieskie kwadraty oznaczają dane dostępne (present), a różowe/czerwone oznaczają braki. Liczby po lewej stronie pokazują, ile obserwacji ma dany wzór braków, a liczby na dole pokazują łączną liczbę braków w każdej zmiennej.

Kluczowe obserwacje:
- **Dominacja kompletnych obserwacji:** Pierwszy wiersz (9933 obserwacji) reprezentuje dane całkowicie kompletne - prawie wszystkie wiersze należą do tej grupy
- **Minimalna liczba wzorów braków:** Tylko kilka alternatywnych wzorów braków pojawia się w zbiorze, co oznacza niesystematyczne braki - nie ma jednego dominującego wzoru
- **Rzadkie kumulacje braków:** Żaden wzór braku nie ma więcej niż kilka obserwacji, co potwierdza, że braki są rozrzedzane po zbiorze
- **Braki w różnych zmiennych:** Różowe pola pojawiają się w różnych kolumnach dla różnych wierszy, wskazując, że braki nie kumulują się w tych samych obserwacjach
- **Łatwa interpretacja:** Dolna linia pokazuje, że niektóre zmienne (te po prawej) mają braki, podczas gdy inne (po lewej) są całkowicie kompletne
- **Skuteczność imputacji:** Ta struktura sugeruje, że imputacja będzie prosta - większość danych można wykorzystać bez zmian, a dla kilku wierszy z brakami wystarczy zastosować odpowiednie strategie uzupełnienia

```{r, echo=FALSE, message=FALSE, warning=FALSE, out.width='50%'}
md.pattern(dane)
```

## 2.6. Mechanizm braków danych - Wnioski z analizy

Na podstawie kompleksowej analizy wszystkich powyższych wykresów możemy stwierdzić, że braki danych w zbiorze Superstore mają charakter **MCAR (Missing Completely At Random)**. Dowodami na to są:

**Ze wzoru vis_miss (2.1):**
- Braki rozproszone losowo po całej matrycy bez skupień czy wzorów
- Brak systematycznego trendu braków na osi czasowej/wierszy

**Ze wzoru gg_miss_var (2.2):**
- Różne zmienne mają różne liczby braków (Discount, Profit, City, State) - nie ma jednego źródła problemu
- Braki są niezależne dla każdej zmiennej

**Ze wzoru gg_miss_case (2.3):**
- Maksymalnie 1-2 braki na obserwację (żaden wiersz nie ma wielu braków jednocześnie)
- Braki nie kumulują się w tych samych obserwacjach
- Rozpylenie braków wskazuje na niezależność mechanizmu

**Ze wzoru gg_miss_upset (2.4):**
- Dominujące są pojedyncze braki w zmiennych, a nie kombinacje
- Brak wyraźnych "łańcuszków" braków (braki jednej zmiennej nie powodują braków w innej)
- Niska współzależność między brakami potwierdza ich niezależność

**Ze wzoru md.pattern (2.5):**
- 9933 obserwacji w pełni kompletnych vs zaledwie kilka alternatywnych wzorów
- Każdy alternatywny wzór braku pojawia się zaledwie kilka razy
- Wzory są różnorodne, co wskazuje na losowość

**Konsekwencje dla imputacji:**
MCAR to najkorzystniejszy typ mechanizmu braków, ponieważ:
- Braki są całkowicie niezależne od danych i wartości zmiennych
- Możemy bezpiecznie stosować zaawansowane metody imputacji (MICE, hot-deck, PMM)
- Wyniki analiz nie będą obciążone odchyleniami wynikającymi z selektywnych braków
- Nie ma potrzeby stosowania zawiłych procedur wagowania czy korekcji błędu systematycznego


```{r include=FALSE}

hotdeck_grouped <- function(x, group_df) {
  out <- x
  g <- interaction(group_df, drop = TRUE)

  for (lv in levels(g)) {
    idx <- which(g == lv)
    vals <- x[idx]
    miss <- is.na(vals)

    if (any(miss) && any(!miss)) {
      out[idx][miss] <- sample(vals[!miss], sum(miss), replace = TRUE)
    }
  }


  if (any(is.na(out)) && any(!is.na(out))) {
    out[is.na(out)] <- sample(out[!is.na(out)], sum(is.na(out)), replace = TRUE)
  }

  out
}

cat_vars <- c("Ship Mode","Segment","Region","Category","Sub-Category")
cat_vars <- intersect(cat_vars, names(dane))

group_vars <- c("Region","Segment")
group_vars <- intersect(group_vars, names(dane))

set.seed(123)
for (v in cat_vars) {
  dane[[v]] <- hotdeck_grouped(dane[[v]], dane[group_vars])
}


num_vars <- c("Sales","Quantity","Discount","Profit")
num_vars <- intersect(num_vars, names(dane))

num_df <- dane %>% select(all_of(num_vars))

set.seed(123)
imp_num <- mice(
  num_df,
  m = 5,
  method = "pmm",
  maxit = 5,
  printFlag = FALSE
)

num_complete <- complete(imp_num, 1)


dane[num_vars] <- num_complete


if (all(c("Product ID", "Product Name") %in% names(dane))) {
  lookup_prod <- dane %>%
    filter(!is.na(`Product ID`), !is.na(`Product Name`)) %>%
    distinct(`Product ID`, `Product Name`)

  dane <- dane %>%
    left_join(lookup_prod, by = "Product ID", suffix = c("", ".from_id")) %>%
    mutate(`Product Name` = ifelse(is.na(`Product Name`), `Product Name.from_id`, `Product Name`)) %>%
    select(-`Product Name.from_id`)
}


fill_by_key_first <- function(x, key) {

  filled <- ave(x, key, FUN = function(z) {
    if (all(is.na(z))) return(z)
    z[is.na(z)] <- z[which(!is.na(z))[1]]
    z
  })
  filled
}

if ("Postal Code" %in% names(dane)) {
  if ("City" %in% names(dane))  dane$City  <- fill_by_key_first(dane$City,  dane$`Postal Code`)
  if ("State" %in% names(dane)) dane$State <- fill_by_key_first(dane$State, dane$`Postal Code`)
}


if ("City" %in% names(dane) && "State" %in% names(dane)) {
  dane$City <- fill_by_key_first(dane$City, dane$State)
}
if ("State" %in% names(dane) && "Region" %in% names(dane)) {
  dane$State <- fill_by_key_first(dane$State, dane$Region)
}

if (all(c("Order Date","Ship Date","Ship Mode","Region") %in% names(dane))) {
  ship_days <- as.integer(dane$`Ship Date` - dane$`Order Date`)

  grp <- interaction(dane$`Ship Mode`, dane$Region, drop = TRUE)
  med_by_grp <- tapply(ship_days, grp, function(z) median(z, na.rm = TRUE))

  miss_sd <- is.na(dane$`Ship Date`)
  if (any(miss_sd)) {

    global_med <- median(ship_days, na.rm = TRUE)
    fill_days <- med_by_grp[as.character(grp[miss_sd])]
    fill_days[is.na(fill_days)] <- global_med

    dane$`Ship Date`[miss_sd] <- dane$`Order Date`[miss_sd] + as.integer(fill_days)
  }
}

for (nm in names(dane)) {
  if (anyNA(dane[[nm]])) {
    if (is.numeric(dane[[nm]])) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else if (inherits(dane[[nm]], "Date")) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else {

      tab <- table(dane[[nm]])
      moda <- names(tab)[which.max(tab)]
      dane[[nm]][is.na(dane[[nm]])] <- moda
    }
  }
}


stopifnot(sum(is.na(dane)) == 0)

md.pattern(dane)
head(dane)
```

## 2.7. Podsumowanie metod imputacji braków danych

-   **Imputacja danych numerycznych:** Zastosowano zaawansowany algorytm
    MICE (Multivariate Imputation by Chained Equations) z metodą PMM
    (Predictive Mean Matching). Pozwala to na uzupełnienie braków w
    oparciu o korelacje z innymi zmiennymi, co jest bardziej precyzyjne
    niż użycie średniej.

-   **Hot-deck Imputation:** Dla zmiennych kategorycznych (np. Ship
    Mode) użyto metody hot-deck, losując wartości z istniejącego
    rozkładu wewnątrz grup (Region/Segment).

-   Braki w nazwach miast i stanów uzupełniono na podstawie kodów
    pocztowych (Postal Code), wykorzystując relacje przestrzenne w
    danych.

-   Brakujące daty wysyłki wyliczono na podstawie mediany czasu dostawy
    dla danego trybu wysyłki i regionu.

# 3. Wizualicje danych

# 3. PYTANIE BADAWCZE #1: Jaki wpływ mają rabaty na zysk?

## 3.6. Rozkład rabatów w transakcjach

Poniższy histogram prezentuje rozkład wartości rabatów zastosowanych w transakcjach. Analiza struktury rabatów jest kluczowa dla zrozumienia polityki cenowej i jej wpływu na rentowność, odpowiadając bezpośrednio na pytanie badawcze #1: *"Jaki wpływ mają rabaty na zysk – czy większy rabat zawsze zwiększa sprzedaż kosztem rentowności?"*

Kluczowe obserwacje:
- **Dominacja transakcji bez rabatu:** Około 4800 transakcji (ponad 50%) odbyło się bez jakiegokolwiek rabatu (Discount = 0), co wskazuje na silną bazę klientów kupujących po pełnej cenie
- **Koncentracja na 20% rabacie:** Druga najliczniejsza grupa (~3600 transakcji) to rabat 20%, co sugeruje standardową politykę promocyjną
- **Rzadkie rabaty ekstremalne:** Rabaty powyżej 30% są znacznie rzadsze (<500 transakcji każdy), co wskazuje na selektywne stosowanie głębokich przecen
- **Bimodalna dystrybucja:** Wyraźne dwa szczyty (0% i 20%) sugerują dwie odrębne strategie sprzedażowe: sprzedaż po cenie katalogowej i sprzedaż promocyjna
- **Potencjał optymalizacji:** Niska częstotliwość rabatów pośrednich (5-15%) może wskazywać na brak elastycznej polityki cenowej, która mogłaby lepiej reagować na różne segmenty klientów

```{r, echo = FALSE}
# Rozkład rabatów
plot_ly(
  df,
  x = ~Discount,
  type = "histogram",
  nbinsx = 20
) %>%
  layout(
    title = "Distribution of Discount",
    xaxis = list(title = "Discount"),
    yaxis = list(title = "Count")
  )
```

## 3.9. Macierz korelacji zmiennych kluczowych

Poniższa macierz korelacji prezentuje związki statystyczne między czterema kluczowymi zmiennymi biznesowymi: Discount (rabat), Quantity (ilość), Sales (sprzedaż) i Profit (zysk). Wartości w komórkach pokazują siłę i kierunek korelacji (od -1 do +1), gdzie wartości bliskie -1 oznaczają silną korelację ujemną, wartości bliskie +1 silną korelację dodatnią, a wartości bliskie 0 brak związku. Gwiazdki (*, **, ***) oznaczają istotność statystyczną korelacji. Analiza ta jest kluczowa dla wszystkich pytań badawczych, szczególnie #1: *"Jaki wpływ mają rabaty na zysk?"*

Kluczowe obserwacje:
- **Rabat niszczy zysk:** Discount ma silną ujemną korelację z Profit (-0.22***), co oznacza, że wyższe rabaty są silnie powiązane z niższym zyskiem – to potwierdza problem z polityką rabatową
- **Sprzedaż nie równa się zysk:** Sales ma umiarkowaną pozytywną korelację z Profit (0.48***), co jest wartością niższą niż można by oczekiwać – wskazuje to, że sama wysokość sprzedaży nie gwarantuje proporcjonalnego zysku
- **Ilość nie kompensuje rabatów:** Quantity ma bardzo słabą korelację z Profit (0.07***), co sugeruje, że zwiększenie ilości sprzedanych produktów nie jest efektywną strategią kompensacji rabatów
- **Rabaty nie zwiększają znacząco sprzedaży:** Discount ma słabą ujemną korelację z Sales (-0.03**), co jest zaskakujące – głębsze rabaty nie prowadzą do znaczącego wzrostu wartości sprzedaży
- **Paradoks rabatowy:** Brak silnej pozytywnej korelacji między rabatem a sprzedażą przy jednoczesnej silnej ujemnej korelacji z zyskiem sugeruje, że obecna polityka rabatowa jest nieefektywna – firma traci zysk bez znaczącego zwiększenia przychodów

```{r, echo = FALSE}
# Macierz korelacji
num_df <- df %>%
  select(Discount, Quantity, Sales, Profit) %>%
  mutate(across(everything(), as.numeric)) %>%
  na.omit()

rc <- rcorr(as.matrix(num_df))
R <- rc$r
P <- rc$P
corrplot(
  R,
  type = "lower",
  method = "color",
  addCoef.col = "black",
  number.cex = 0.9,
  tl.col = "black",
  tl.srt = 45
)
n <- ncol(R)

for (i in 2:n) {
  for (j in 1:(i-1)) {
    if (P[i, j] < 0.05) {
      stars <- ifelse(P[i, j] < 0.001, "***",
               ifelse(P[i, j] < 0.01, "**", "*"))

      text(
        x = j,
        y = n - i + 1 + 0.25,  
        labels = stars,
        cex = 1,
        col = "black"
      )
    }
  }
}
```

## 3.13. Wpływ rabatów na rentowność: analiza wielowymiarowa

Poniższe cztery wizualizacje przedstawiają kompleksową analizę wpływu rabatów na kluczowe metryki biznesowe: marżę zysku, liczbę zamówień, udział w całkowitym zysku oraz średnią wartość zakupu. Transakcje zostały pogrupowane w sześć kategorii według wysokości rabatu, co pozwala na precyzyjne zidentyfikowanie punktu krytycznego, w którym rabaty przestają być opłacalne. Analiza ta bezpośrednio odpowiada na pytanie badawcze #1: *"Jaki wpływ mają rabaty na zysk – czy większy rabat zawsze zwiększa sprzedaż kosztem rentowności?"*

### Średnia marża zysku według poziomu rabatu

Poniższy wykres słupkowy przedstawia średnią marżę zysku (w procentach) dla każdej grupy rabatowej. Kolor słupka sygnalizuje rentowność: zielony oznacza zysk, czerwony stratę. Ta wizualizacja jasno pokazuje punkt krytyczny, w którym rabaty przekształcają się z narzędzia marketingowego w źródło strat finansowych.

Kluczowe obserwacje:
- **Próg opłacalności:** Wyraźna granica rentowności znajduje się między 11-20% a 21-30% rabatem – pierwsze dwie grupy generują zysk (33.7% i 17.5% marży), podczas gdy wszystkie kolejne są w strefie strat
- **Dramatyczny spadek:** Marża spada z +17.5% (11-20%) do -11.5% (21-30%), co oznacza spadek o prawie 30 punktów procentowych przy zwiększeniu rabatu o zaledwie ~10%, wskazując na nieliniowy wpływ rabatów
- **Katastrofa ekstremalnych rabatów:** Grupa rabatów >50% wykazuje marżę -114%, co oznacza, że firma traci więcej niż cała wartość sprzedaży – każda taka transakcja jest dramatycznie nierentowna
- **Bezpieczna strefa:** Transakcje z rabatem 0-10% mają najbardziej zdrową marżę 33.7%, co sugeruje, że firma ma solidne podstawy marżowe, które są niszczone przez agresywną politykę rabatową
- **Rekomendacja:** Rabaty powyżej 20% powinny być całkowicie wyeliminowane lub stosowane wyłącznie w wyjątkowych sytuacjach strategicznych z jasnym uzasadnieniem biznesowym (np. likwidacja zapasów, pozyskanie kluczowego klienta)

```{r, echo = FALSE}
# Przygotowanie danych rabatów - jeśli wcześniej nie było
df <- df %>%
  mutate(
    profit_margin = ifelse(Sales > 0, Profit / Sales * 100, NA_real_),
    discount_group = cut(
      Discount * 100,
      breaks = c(0, 10, 20, 30, 40, 50, 100),
      labels = c("0-10%", "11-20%", "21-30%", "31-40%", "41-50%", ">50%"),
      include.lowest = TRUE
    )
  )

discount_analysis <- df %>%
  group_by(discount_group) %>%
  summarise(
    orders = n(),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    avg_sales = mean(Sales, na.rm = TRUE),
    avg_profit = mean(Profit, na.rm = TRUE),
    avg_profit_margin = mean(profit_margin, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(discount_group) & orders > 0) %>%
  mutate(
    sales_share = total_sales / sum(total_sales, na.rm = TRUE) * 100,
    profit_share = total_profit / sum(total_profit, na.rm = TRUE) * 100
  ) %>%
  arrange(discount_group)

x_groups <- levels(df$discount_group)
discount_analysis <- discount_analysis %>%
  mutate(discount_group = factor(discount_group, levels = x_groups, ordered = TRUE)) %>%
  arrange(discount_group)

discount_analysis <- discount_analysis %>%
  mutate(
    bar_color = ifelse(avg_profit_margin >= 0, "darkgreen", "red"),
    label_pm  = paste0(round(avg_profit_margin, 1), "%"),
    hover_txt = paste0(
      "<b>Grupa rabatu:</b> ", discount_group,
      "<br><b>Śr. marża:</b> ", sprintf("%.2f", avg_profit_margin), "%",
      "<br><b>Zamówienia:</b> ", orders,
      "<br><b>Śr. rabat:</b> ", sprintf("%.1f", avg_discount), "%",
      "<br><b>Śr. sprzedaż:</b> ", sprintf("%.2f", avg_sales), "$",
      "<br><b>Śr. zysk:</b> ", sprintf("%.2f", avg_profit), "$"
    )
  )

plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~avg_profit_margin,
  type = "bar",
  marker = list(color = ~bar_color),
  text = ~label_pm,
  textposition = "outside",
  cliponaxis = FALSE,
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Średnia marża wg rabatu",
    xaxis = list(title = "Grupa rabatu", tickangle = -30),
    yaxis = list(title = "Marża (%)", zeroline = TRUE, zerolinewidth = 2),
    margin = list(l = 70, r = 30, t = 60, b = 80),
    bargap = 0.25
  )
```

### Liczba zamówień według poziomu rabatu

Poniższy wykres liniowy pokazuje rozkład liczby zamówień w poszczególnych grupach rabatowych. Kształt krzywej ujawnia faktyczną strategię rabatową firmy i pozwala ocenić, czy rabaty są stosowane strategicznie czy chaotycznie.

Kluczowe obserwacje:
- **Dominacja niskich rabatów:** Grupy 0-10% (~4900 zamówień) i 11-20% (~3700 zamówień) stanowią łącznie około 86% wszystkich transakcji, co jest pozytywnym sygnałem - większość klientów kupuje przy niskiej lub zerowej obniżce
- **Przepaść po 20%:** Dramatyczny spadek do ~250 zamówień w grupach 21-30% i 31-40% wskazuje, że firma rzadko stosuje średnie rabaty - to sugeruje brak elastycznej polityki cenowej i negocjacji
- **Anomalia ekstremalnych rabatów:** Niespodziewany wzrost do ~900 zamówień w grupie >50% jest niepokojący - tak głębokie rabaty (które generują -114% marży) nie powinny występować tak często, chyba że są to akcje likwidacji zapasów
- **Strategia binarna:** Rozkład pokazuje podejście "wszystko albo nic" - albo pełna/prawie pełna cena (~4900), albo standardowa promocja 20% (~3700), albo ekstremalna wyprzedaż (~900), bez płynnych przejść
- **Problem kontroli:** Fakt, że 900 transakcji odbyło się z rabatami >50% (każda generująca ogromną stratę) wskazuje na brak procedur autoryzacji głębokich rabatów lub celowe akcje, które wymagają szczegółowej analizy uzasadnienia biznesowego

```{r, echo = FALSE}
plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~orders,
  type = "scatter",
  mode = "lines+markers",
  line = list(width = 2),
  hovertemplate = paste(
    "<b>Grupa rabatu:</b> %{x}<br>",
    "<b>Liczba zamówień:</b> %{y}<br>",
    "<b>Śr. rabat:</b> %{customdata:.1f}%<extra></extra>"
  ),
  customdata = ~avg_discount
) %>%
  layout(
    title = "Rabat vs zamówienia",
    xaxis = list(title = "Grupa rabatu"),
    yaxis = list(title = "Liczba zamówień")
  )
```

### Udział w całkowitym zysku według poziomu rabatu

Poniższy wykres słupkowy pokazuje, jaki procent całkowitego zysku firmy generuje każda grupa rabatowa. Wartości powyżej 100% w sumie wskazują, że niektóre grupy muszą mieć ujemny udział - czyli faktycznie odejmują od zysku. Ta wizualizacja ujawnia dramatyczną prawdę o kosztach rabatów dla rentowności całej firmy.

Kluczowe obserwacje:
- **Dominacja grupy 0-10%:** Transakcje z najniższymi rabatami generują aż 115% całkowitego zysku firmy, co oznacza, że bez nich firma w ogóle nie byłaby rentowna - to fundamentalny filar biznesu
- **Wkład grupy 11-20%:** Druga grupa odpowiada za 32% zysku, co łącznie z grupą 0-10% daje ~147% - czyli prawie 1.5x więcej niż faktyczny zysk firmy, ponieważ pozostałe grupy go zmniejszają
- **Niszczyciele wartości:** Grupy 21-30%, 31-40% i 41-50% mają ujemny udział (około -4% do -7% każda), co oznacza, że każda transakcja w tych przedziałach aktywnie zmniejsza całkowity zysk firmy
- **Katastrofa >50%:** Grupa ekstremalnych rabatów zabiera -27% całkowitego zysku, co przy 900 transakcjach w tej grupie oznacza systematyczne niszczenie wartości na dużą skalę
- **Efekt kompensacji:** Wykres jasno pokazuje, że rentowność firmy opiera się wyłącznie na dwóch pierwszych grupach (0-20% rabatu), które muszą "wyrabiać" stratę generowaną przez wszystkie głębsze rabaty - to niezrównoważony model biznesowy wymagający natychmiastowej interwencji

```{r, echo = FALSE}
plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~profit_share,
  type = "bar",
  hovertemplate = paste(
    "<b>Grupa rabatu:</b> %{x}<br>",
    "<b>Udział w zysku:</b> %{y:.2f}%<br>",
    "<b>Zysk łącznie:</b> %{customdata:.0f}$<extra></extra>"
  ),
  customdata = ~total_profit
) %>%
  layout(
    title = "Udział w zysku",
    xaxis = list(title = "Grupa rabatu"),
    yaxis = list(title = "Udział w zysku (%)")
  )
```

### Średnia wartość zakupu według poziomu rabatu

Poniższy wykres liniowy przedstawia średnią wartość transakcji (w dolarach) dla każdej grupy rabatowej. Szara linia przerywana oznacza średnią globalną (~$230). Ta wizualizacja odpowiada na kluczowe pytanie: czy głębsze rabaty rzeczywiście zwiększają wartość koszyka zakupowego, jak zakładają klasyczne teorie rabatowe?

Kluczowe obserwacje:
- **Paradoks niskich rabatów:** Grupy 0-10% i 11-20% mają wartości zakupu ($230 i $220) blisko średniej globalnej, co jest nieoczekiwane - brak rabatu nie zniechęca klientów do kupowania produktów o standardowej wartości
- **Wzrost dla średnich rabatów:** Grupy 21-30% ($460), 31-40% ($565) i 41-50% ($850) pokazują wyraźny wzrost wartości zakupu wraz z rabatem, co sugeruje, że głębsze rabaty są stosowane przy droższych produktach lub większych zamówieniach
- **Dramatyczny spadek przy >50%:** Grupa ekstremalnych rabatów ma NAJNIŻSZĄ średnią wartość zakupu (~$75), co jest 3x niższe niż średnia - to wskazuje, że >50% rabatów są stosowane głównie przy tanich produktach lub produktach trudnych do sprzedaży
- **Brak strategii "większy zakup = większy rabat":** Fakt, że najwyższe rabaty (>50%) idą w parze z najniższymi wartościami koszyka (~$75) jest całkowicie odwrotny do zdrowej strategii rabatowej, gdzie głębokie rabaty powinny nagradzać duże zamówienia
- **Niszczenie wartości przy niskiej sprzedaży:** Kombinacja -114% marży (z pierwszego wykresu) i $75 średniej sprzedaży w grupie >50% oznacza, że firma daje ogromne rabaty na produkty o niskiej wartości, co jest podwójnie destrukcyjne - niska wartość transakcji + ogromna strata na każdej transakcji

```{r, echo = FALSE}
global_mean_sales <- mean(df$Sales, na.rm = TRUE)

plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~avg_sales,
  type = "scatter",
  mode = "lines+markers",
  line = list(width = 2),
  hovertemplate = paste(
    "<b>Grupa rabatu:</b> %{x}<br>",
    "<b>Śr. wartość zakupu:</b> %{y:.2f}$<br>",
    "<b>Śr. rabat:</b> %{customdata:.1f}%<extra></extra>"
  ),
  customdata = ~avg_discount
) %>%
  layout(
    title = "Rabat vs średnia wartość zakupu",
    xaxis = list(title = "Grupa rabatu"),
    yaxis = list(title = "Śr. wartość zakupu ($)"), 
    shapes = list(
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = global_mean_sales, y1 = global_mean_sales,
        line = list(color = "gray", width = 2, dash = "dash")
      )
    ),
    annotations = list(
      list(
        xref = "paper", x = 0.5, y = global_mean_sales,
        text = paste0("Średnia globalna: $", round(global_mean_sales, 2)),
        showarrow = FALSE, yshift = -12, font = list(color = "gray")
      )
    )
  )
```

# 3. PYTANIE BADAWCZE #2: Które kategorie i podkategorie produktów generują najwyższą sprzedaż, a które najwyższy zysk?

## 3.10. Analiza rentowności kategorii: wykres bąbelkowy

Poniższy wykres bąbelkowy przedstawia trzywymiarową analizę kategorii produktów, gdzie oś X reprezentuje liczbę zamówień, oś Y średni zysk na transakcję, a rozmiar bąbelka odpowiada łącznej sumie sprzedaży. Ta wielowymiarowa wizualizacja pozwala jednocześnie ocenić wolumen sprzedaży, rentowność oraz skalę przychodów każdej kategorii. Analiza bezpośrednio odpowiada na pytanie badawcze #2: *"Które kategorie produktów generują najwyższą sprzedaż, a które najwyższy zysk?"*

Kluczowe obserwacje:
- **Technology - gwiazdor portfela:** Kategoria Technology (największy niebieski bąbelek) dominuje we wszystkich trzech wymiarach - ma najwyższą liczbę zamówień (~6000), najwyższy średni zysk (~$80) i największą sumę sprzedaży, co czyni ją najbardziej wartościową kategorią w portfolio
- **Office Supplies - masa krytyczna:** Artykuły biurowe (średni pomarańczowy bąbelek) mają umiarkowaną liczbę zamówień (~5500), ale niski średni zysk (~$20), co wskazuje na problem z marżami pomimo znaczącego wolumenu sprzedaży
- **Furniture - problem rentowności:** Meble (mały zielony bąbelek) mają najmniejszą liczbę zamówień (~2000) i najniższy średni zysk (~$8), co sugeruje, że ta kategoria jest najmniej efektywna zarówno pod względem wolumenu jak i rentowności
- **Paradoks skali:** Mimo że Office Supplies ma prawie tyle samo zamówień co Technology, jej średni zysk jest 4x niższy, co wskazuje na znaczące różnice w marżowości między kategoriami
- **Strategia różnicowania:** Wyraźne rozdzielenie kategorii na wykresie sugeruje potrzebę różnych strategii dla każdej z nich: maksymalizacja skali dla Technology, poprawa marż dla Office Supplies, i reewaluacja oferty dla Furniture

```{r}
category_stats <- dane %>%
  group_by(Category) %>%
  summarise(
    liczba_zamówień = n(),
    średni_zysk = mean(Profit, na.rm = TRUE),
    suma_sprzedaży = sum(Sales, na.rm = TRUE),
    .groups = "drop"
  )
plot_ly(
  data = category_stats,
  x = ~liczba_zamówień,
  y = ~średni_zysk,
  size = ~suma_sprzedaży,
  color = ~Category,

  sizes = c(30, 80), 
  type = 'scatter',
  mode = 'markers+text',
  text = ~Category,
  textposition = "top center",

  textfont = list(size = 14, color = 'black'),
  
  marker = list(
    opacity = 0.6,
    line = list(width = 0),
    sizemode = 'diameter'
  )
) %>%
  layout(
    xaxis = list(title = "Liczba zamówień", range = c(1500, 6500)),
    yaxis = list(title = "Średni zysk ($)", range = c(-5, 100)), 
    
    template = "plotly_white",
    showlegend = TRUE
  )
```

## 3.14. Top 5 podkategorii: sprzedaż vs rentowność

Poniższe dwa wykresy słupkowe przedstawiają top 5 podkategorii produktów pod względem sprzedaży (lewy panel) oraz top 5 podkategorii według zysku (prawy panel). To zestawienie ujawnia kluczową różnicę między wielkością sprzedaży a faktyczną rentownością - produkty generujące najwyższe przychody nie zawsze są najbardziej opłacalne. Analiza odpowiada na pytanie badawcze #2: *"Które kategorie i podkategorie produktów generują najwyższą sprzedaż, a które najwyższy zysk?"*

Kluczowe obserwacje:
- **Phones - podwójny lider:** Telefony pojawiają się w obu top 5 (2. miejsce w sprzedaży, 2. w zysku), co czyni je najbardziej zrównoważoną podkategorią - wysoka sprzedaż przekłada się na wysoki zysk, co wskazuje na dobrą marżowość
- **Chairs - wysoka sprzedaż, brak rentowności:** Krzesła są liderem sprzedaży (~$330k), ale nie pojawiają się w top 5 zysków, co sugeruje bardzo niską marżę lub nawet straty na tej podkategorii pomimo ogromnego wolumenu - to czerwona flaga wymagająca analizy kosztów i rabatów
- **Copiers - król rentowności:** Kopiarki generują najwyższy zysk (~$55k) mimo że nie są w top 5 sprzedaży, co wskazuje na wyjątkowo wysoką marżę - to strategiczna podkategoria, która zasługuje na większy nacisk sprzedażowy
- **Binders - paradoks marży:** Segregatory są zarówno w top 5 sprzedaży (5. miejsce ~$200k) jak i top 5 zysku (5. miejsce ~$30k), ale stosunek zysku do sprzedaży jest niski (~15%), co wskazuje na produkt o wysokim wolumeniu ale niskiej marży
- **Różne strategie produktowe:** Fakt, że tylko 2 z 5 top produktów sprzedażowych pojawiają się w top 5 zysków (Phones i Binders) oznacza, że firma sprzedaje głównie produkty o niskiej marży, podczas gdy najbardziej rentowne produkty (Copiers, Accessories, Paper) mają słabszą penetrację sprzedażową - potrzebna jest reorganizacja portfolio produktowego z naciskiem na cross-selling rentownych produktów

```{r}
wrap_labels <- function(x, width = 12) stringr::str_wrap(x, width = width)


subcategory_analysis <- df %>%
  group_by(Category, `Sub-Category`) %>%
  summarise(
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    avg_profit_margin = mean(Profit / Sales * 100, na.rm = TRUE),
    orders = n(),
    .groups = "drop"
  ) %>%
  filter(total_sales > 0)


top_sales_subcat <- subcategory_analysis %>%
  arrange(desc(total_sales)) %>%
  head(5) %>%
  mutate(
    sales_k = total_sales / 1000,
    hover_txt = paste0(
      "<b>Kategoria:</b> ", Category,
      "<br><b>Podkategoria:</b> ", `Sub-Category`,
      "<br><b>Sprzedaż:</b> ", round(total_sales, 0), "$",
      "<br><b>Zysk:</b> ", round(total_profit, 0), "$",
      "<br><b>Marża:</b> ", round(avg_profit_margin, 2), "%",
      "<br><b>Zamówienia:</b> ", orders
    )
  )

p_sales <- plot_ly(
  data = top_sales_subcat,
  x = ~`Sub-Category`,
  y = ~sales_k,
  type = "bar",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    xaxis = list(
      title = "",
      tickvals = top_sales_subcat$`Sub-Category`,
      ticktext = wrap_labels(top_sales_subcat$`Sub-Category`, 12)
    ),
    yaxis = list(title = "Sprzedaż (tys. $)"),
    bargap = 0.25
  )


top_profit_subcat <- subcategory_analysis %>%
  arrange(desc(total_profit)) %>%
  head(5) %>%
  mutate(
    profit_k = total_profit / 1000,
    bar_color = ifelse(total_profit < 0, "red", "darkgreen"),
    hover_txt = paste0(
      "<b>Kategoria:</b> ", Category,
      "<br><b>Podkategoria:</b> ", `Sub-Category`,
      "<br><b>Zysk:</b> ", round(total_profit, 0), "$",
      "<br><b>Sprzedaż:</b> ", round(total_sales, 0), "$",
      "<br><b>Marża:</b> ", round(avg_profit_margin, 2), "%",
      "<br><b>Zamówienia:</b> ", orders
    )
  )

p_profit <- plot_ly(
  data = top_profit_subcat,
  x = ~`Sub-Category`,
  y = ~profit_k,
  type = "bar",
  marker = list(color = ~bar_color),
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    xaxis = list(
      title = "",
      tickvals = top_profit_subcat$`Sub-Category`,
      ticktext = wrap_labels(top_profit_subcat$`Sub-Category`, 12)
    ),
    yaxis = list(
      title = "Zysk (tys. $)",
      zeroline = TRUE,
      zerolinewidth = 2
    ),
    bargap = 0.25
  )


p <- plotly::subplot(p_sales, p_profit, shareX = FALSE, titleX = TRUE) %>%
  layout(
    title = list(text = "Top 5 podkategorii – porównanie", x = 0.5),
    showlegend = FALSE,


annotations = list(
  list(
    x = 0.22, y = 1.02, xref = "paper", yref = "paper",
    text = "<b>Sprzedaż</b>",
    showarrow = FALSE,
    font = list(size = 13, color = "#333333")
  ),
  list(
    x = 0.78, y = 1.02, xref = "paper", yref = "paper",
    text = "<b>Zysk</b>",
    showarrow = FALSE,
    font = list(size = 13, color = "#333333")
  )
),


    margin = list(l = 70, r = 30, t = 110, b = 120)
  )


p <- config(p, displayModeBar = FALSE)

p
```

# 3. PYTANIE BADAWCZE #3: Czy istnieją regiony o wysokiej sprzedaży, ale niskiej rentowności?

## 3.7. Top 10 stanów według zysku

Poniższy wykres przedstawia dziesięć stanów USA generujących najwyższy łączny zysk w analizowanym okresie. Analiza geograficzna rentowności jest kluczowa dla odpowiedzi na pytanie badawcze #3: *"Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej) rentowności?"* oraz umożliwia identyfikację najważniejszych rynków dla firmy.

Kluczowe obserwacje:
- **Dominacja Kalifornii i Nowego Jorku:** Dwa stany generują łącznie ~150k$ zysku, co stanowi znaczną część całkowitego zysku firmy, wskazując na kluczowe znaczenie rynków wschodniego i zachodniego wybrzeża
- **Koncentracja geograficzna:** Większość najbardziej rentownych stanów to duże centra metropolitalne (Kalifornia, Nowy Jork, Waszyngton, Michigan), co sugeruje korelację między urbanizacją a rentownością
- **Duże różnice wewnętrzne:** Różnica między najlepszym stanem (~78k$) a dziesiątym (~10k$) jest prawie ośmiokrotna, co wskazuje na bardzo nierównomierny rozkład zysków geograficznych
- **Obecność stanów południowych:** Indiana, Virginia i Georgia reprezentują region południowy, pokazując jego rosnące znaczenie ekonomiczne
- **Potencjał konsolidacji:** Silna koncentracja zysków w kilku stanach może sugerować możliwość optymalizacji operacji poprzez skupienie zasobów na najbardziej rentownych rynkach

```{r, echo = FALSE}
# Top 10 stanów według zysku
top_states <- df %>%
  group_by(State) %>%
  summarise(Profit = sum(Profit, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(Profit)) %>%
  slice_head(n = 10)

plot_ly(
  top_states,
  x = ~reorder(State, Profit),
  y = ~Profit,
  type = "bar"
) %>%
  layout(
    title = "Top 10 States by Profit",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Profit")
  )
```

## 3.15. Analiza regionalna: sprzedaż vs rentowność

Poniższe dwa wykresy przedstawiają kompleksową analizę rentowności czterech regionów geograficznych USA. Pierwszy wykres (scatter plot) pokazuje relację między wielkością sprzedaży a marżą zyskowności, gdzie rozmiar bąbelka reprezentuje wartość bezwzględną zysku. Drugi wykres (słupkowy) prezentuje bezpośrednie porównanie marży w poszczególnych regionach. Analiza odpowiada na pytanie badawcze #3: *"Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej) rentowności?"*

```{r, echo = FALSE}
# ANALIZA REGIONÓW - PRZYGOTOWANIE DANYCH
region_summary <- df %>%
  group_by(Region) %>%
  summarise(
    sprzedaż = sum(Sales, na.rm = TRUE) / 1000,
    zysk = sum(Profit, na.rm = TRUE) / 1000,
    marża = mean(Profit / Sales * 100, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(marża)) %>%
  mutate(
    kolor = ifelse(marża >= 15, "darkgreen",
                   ifelse(marża >= 10, "orange", "red")),
    hover_txt = paste0(
      "<b>Region:</b> ", Region,
      "<br><b>Sprzedaż:</b> ", round(sprzedaż, 1), " tys. $",
      "<br><b>Zysk:</b> ", round(zysk, 1), " tys. $",
      "<br><b>Marża:</b> ", round(marża, 2), "%"
    )
  )
```

### Regiony: relacja sprzedaży i marży

Poniższy wykres typu scatter (punktowy z bąbelkami) prezentuje jednoczesną wizualizację trzech wymiarów: wielkości sprzedaży (oś X), marży zysku (oś Y) oraz wartości bezwzględnej zysku (rozmiar bąbelka). Kolor bąbelka sygnalizuje stan rentowności: zielony (marża ≥15%), pomarańczowy (marża 10-15%), czerwony (marża <10%).

Kluczowe obserwacje:
- **East - lider pod każdym względem:** Region East ma najwyższą sprzedaż (~$680k), najwyższy zysk (największy bąbelek) i bardzo dobrą marżę (~17%), co czyni go gwiazdą portfolio - wszystkie metryki są optymalne
- **West - wysoka skala, niska marża:** Region West generuje drugą co do wielkości sprzedaż (~$720k) ale ma znacznie niższą marżę (~22%) niż East, mimo największego bąbelka (największy zysk w wartościach bezwzględnych) - to pokazuje, że skala kompensuje słabszą efektywność
- **Central - katastrofa biznesowa:** Region Central (czerwony bąbelek) ma UJEMNĄ marżę (~-10%), co oznacza, że każdy dolar sprzedaży generuje stratę - mimo sprzedaży ~$500k, firma traci pieniądze w tym regionie, co wymaga natychmiastowej interwencji
- **South - pułapka niskiej marży:** Region South ma niską sprzedaż (~$390k) i marginalną marżę (~16%), co plasuje go w strefie pomarańczowej - to region bez wyraźnego profilu strategicznego
- **Paradoks wielkości:** Wykres jasno pokazuje, że wielkość sprzedaży NIE gwarantuje rentowności - West ma większą sprzedaż niż East ale niższą marżę, a Central mimo znaczącej sprzedaży (~$500k) generuje wyłącznie straty

```{r, echo = FALSE}
plot_ly(
  data = region_summary,
  x = ~sprzedaż,
  y = ~marża,
  type = "scatter",
  mode = "markers+text",
  marker = list(
    size = ~abs(zysk) * 2,
    color = ~kolor,
    line = list(color = "white", width = 2),
    opacity = 0.7
  ),
  text = ~Region,
  textposition = "top center",
  textfont = list(size = 12, color = "black"),
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Regiony: Sprzedaż vs Marża",
    xaxis = list(title = "Sprzedaż (tys. $)"),
    yaxis = list(title = "Marża (%)"),
    showlegend = FALSE
  )
```

### Porównanie marży według regionów

Poniższy wykres słupkowy przedstawia bezpośrednie porównanie marży zysku w czterech regionach. Dwie linie przerywane oznaczają progi: zielona (15% - marża bardzo dobra), pomarańczowa (10% - marża akceptowalna). Kolory słupków odpowiadają tym samym kryteriom co na poprzednim wykresie.

Kluczowe obserwacje:
- **West - niespodzianka lidera:** Region West ma najwyższą marżę (22%), mimo że na poprzednim wykresie wydawał się mniej efektywny niż East - to pokazuje, że wysoka sprzedaż West rzeczywiście przekłada się na bardzo dobrą rentowność procentową
- **East i South - powyżej progu:** Regiony East (16.7%) i South (16.3%) są powyżej zielonej linii (15%), co oznacza bardzo dobrą rentowność - to stabilne, zdrowe regiony
- **Central - dramatyczna strata:** Region Central (-10.4%) jest jedynym czerwonym słupkiem, znajdującym się głęboko poniżej zera - to nie tylko brak zysku, ale aktywna destrukcja wartości firmy
- **Dysproporcja 3:1:** Trzy regiony mają marżę 16-22%, podczas gdy jeden ma -10% - to wskazuje, że problem nie jest systemowy ale specyficzny dla Central i prawdopodobnie ma konkretne przyczyny do zidentyfikowania
- **Priorytet strategiczny:** Fakt, że Central stanowi ~20% sprzedaży firmy (z poprzedniego wykresu ~$500k z ~$2500k total) ale generuje same straty oznacza, że eliminacja problemów w tym regionie może zwiększyć całkowity zysk firmy o dziesiątki procent - to najważniejszy priorytet operacyjny

```{r, echo = FALSE}
plot_ly(
  data = region_summary,
  x = ~Region,
  y = ~marża,
  type = "bar",
  marker = list(color = ~kolor),
  text = ~paste0(round(marża, 1), "%"),
  textposition = "outside",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Marża wg regionu",
    xaxis = list(title = ""),
    yaxis = list(title = "Marża (%)"),
    shapes = list(
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = 15, y1 = 15,
        line = list(color = "green", width = 2, dash = "dash")
      ),
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = 10, y1 = 10,
        line = list(color = "orange", width = 2, dash = "dash")
      )
    ),
    showlegend = FALSE
  )
```

# 3. PYTANIE BADAWCZE #4: Jak zmieniały się sprzedaż i zysk w czasie – czy występuje sezonowość?

## 3.8. Sprzedaż w czasie według kategorii produktów

Poniższy wykres obszarowy (stacked area chart) prezentuje dynamikę sprzedaży w podziale na kategorie produktów na przestrzeni całego analizowanego okresu (2014-2017). Format stackowany pozwala jednocześnie obserwować zarówno całkowitą sprzedaż (wysokość całego stosu), jak i udział poszczególnych kategorii w każdym okresie. Analiza ta uzupełnia odpowiedź na pytanie badawcze #4: *"Jak zmieniały się sprzedaż i zysk w czasie – czy występuje sezonowość?"*

Kluczowe obserwacje:
- **Wyraźna sezonowość:** Widoczne są regularne peaki sprzedaży w czwartym kwartale każdego roku (listopad-grudzień), prawdopodobnie związane z sezonem zakupów świątecznych i promocjami Black Friday/Cyber Monday
- **Proporcje kategorii stabilne:** Pomimo zmian w całkowitej sprzedaży, proporcje między kategoriami pozostają względnie stałe w czasie – Technology dominuje w każdym okresie
- **Wzrost całkowitej sprzedaży:** Trend wzrostowy jest widoczny szczególnie w latach 2016-2017, gdzie peaki sezonowe osiągają wyższe wartości niż w latach poprzednich
- **Spadki po sezonie:** Regularne spadki sprzedaży na początku każdego roku (styczeń-luty) wskazują na cykliczny charakter biznesu i możliwość lepszego planowania zapasów i kampanii marketingowych
- **Technology motor wzrostu:** Kategoria Technology nie tylko ma największy udział, ale również wykazuje najsilniejszy wzrost w okresach szczytowych, co potwierdza jej kluczową rolę w strategii firmy

```{r, echo = FALSE}
# Sprzedaż w czasie według Kategorii (wykres obszarowy)
area <- df %>%
  filter(!is.na(`Order Date`), !is.na(Category), !is.na(Sales)) %>%
  mutate(month = floor_date(`Order Date`, "month")) %>%
  group_by(month, Category) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

plot_ly(
  area,
  x = ~month,
  y = ~Sales,
  color = ~Category,
  type = "scatter",
  mode = "none",
  stackgroup = "one",
  hovertemplate = paste(
    "<b>Data:</b> %{x|%Y-%m}<br>",
    "<b>Kategoria:</b> %{fullData.name}<br>",
    "<b>Sprzedaż:</b> $%{y:,.0f}<extra></extra>"
  )
) %>%
  layout(
    title = "Sales over time by Category",
    yaxis = list(title = "Sales"),
    hovermode = "x unified"
  )
```

## 3.12. Wydajność dni tygodnia: analiza wielowymiarowa

Poniższa mapa cieplna (heatmap) przedstawia znormalizowaną wydajność poszczególnych dni tygodnia w trzech kluczowych metrykach biznesowych: liczbie zamówień, średniej wartości zamówienia oraz średnim zysku. Zastosowanie normalizacji (skala 0-1) i gradientu kolorystycznego (żółty = najniższa wartość w danej metryce, czerwony = najwyższa) pozwala na szybką identyfikację najlepszych i najgorszych dni dla różnych wskaźników. Analiza ta jest kluczowa dla optymalizacji operacji i kampanii marketingowych.

Kluczowe obserwacje:
- **Paradoks środy:** Środa ma NAJNIŻSZĄ liczbę zamówień (371 - żółta komórka), ale jednocześnie NAJWYŻSZY średni zysk ($40 - czerwona komórka), co wskazuje na znacznie wyższą jakość/rentowność transakcji w tym dniu pomimo niskiego wolumenu
- **Poniedziałek - król wolumenu:** Poniedziałek generuje najwyższą liczbę zamówień (1871 - czerwona komórka), ale ma relatywnie niski średni zysk ($28), co sugeruje, że dni o wysokim wolumenie nie przekładają się automatycznie na wysoką rentowność
- **Wtorek - najwyższa wartość koszyka:** Wtorek wyróżnia się najwyższą średnią wartością zamówienia ($260 - czerwona komórka) i dobrym średnim zyskiem ($32), co czyni go jednym z najbardziej wartościowych dni
- **Sobota - najsłabszy dzień:** Sobota ma najniższą średnią wartość zamówienia ($216) i najniższy średni zysk ($25 - żółte komórki), co wskazuje na ten dzień jako priorytet do optymalizacji lub specjalnych kampanii
- **Optymalny mix:** Idealne dni to wtorek i niedziela - łączą umiarkowanie wysoką liczbę zamówień z wysoką wartością koszyka i dobrym zyskiem, podczas gdy środa oferuje najwyższą rentowność przy niskim wolumenie (potencjał premium/B2B)

```{r}

polish_days <- c("poniedziałek", "wtorek", "środa", "czwartek", "piątek", "sobota", "niedziela")
df$weekday <- factor(weekdays(df$`Order Date`), levels = polish_days, ordered = TRUE)


weekday_stats <- df %>%
  group_by(weekday) %>%
  summarise(
    liczba_zamówień = n(),
    średnia_wartość_zamówienia = mean(Sales, na.rm = TRUE),
    średni_zysk = mean(Profit, na.rm = TRUE),
    średni_czas_dostawy = mean(shipping_days, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(weekday)


weekday_long <- weekday_stats %>%
  pivot_longer(
    cols = c(liczba_zamówień, średnia_wartość_zamówienia, średni_zysk),
    names_to = "metric",
    values_to = "value_raw"
  ) %>%
  mutate(
    metric = case_when(
      metric == "liczba_zamówień" ~ "Liczba zamówień",
      metric == "średnia_wartość_zamówienia" ~ "Śr. wartość zamówienia ($)",
      metric == "średni_zysk" ~ "Śr. zysk ($)",
      TRUE ~ metric
    ),
    label = ifelse(metric == "Liczba zamówień",
                   as.character(round(value_raw, 0)),
                   paste0("$", round(value_raw, 0)))
  ) %>%
  group_by(metric) %>%
  mutate(
    value_scaled = {
      mn <- min(value_raw, na.rm = TRUE)
      mx <- max(value_raw, na.rm = TRUE)
      if (isTRUE(all.equal(mx, mn))) rep(0.5, n()) else (value_raw - mn) / (mx - mn)
    }
  ) %>%
  ungroup()


x_days <- levels(df$weekday)
y_metrics <- c("Śr. zysk ($)", "Śr. wartość zamówienia ($)", "Liczba zamówień")

weekday_long <- weekday_long %>%
  mutate(
    weekday = factor(weekday, levels = x_days, ordered = TRUE),
    metric  = factor(metric, levels = y_metrics, ordered = TRUE)
  ) %>%
  arrange(metric, weekday)


z <- matrix(NA_real_, nrow = length(y_metrics), ncol = length(x_days),
            dimnames = list(y_metrics, x_days))
text_mat <- matrix("", nrow = length(y_metrics), ncol = length(x_days),
                   dimnames = list(y_metrics, x_days))
raw_mat <- matrix(NA_real_, nrow = length(y_metrics), ncol = length(x_days),
                  dimnames = list(y_metrics, x_days))

for (m in y_metrics) {
  for (d in x_days) {
    tmp <- weekday_long %>% filter(metric == m, weekday == d)
    z[m, d] <- tmp$value_scaled[1]
    text_mat[m, d] <- tmp$label[1]
    raw_mat[m, d] <- tmp$value_raw[1]
  }
}


rdylgn <- list(
  list(0.00, "#ffffbf"),
  list(1.00, "#d73027")
)

plot_ly(
  x = x_days,
  y = y_metrics,
  z = z,
  type = "heatmap",
  zmin = 0, zmax = 1,
  colorscale = rdylgn,
  text = text_mat,
  texttemplate = "%{text}",
  textfont = list(color = "black"),
  customdata = raw_mat,
  hovertemplate = paste(
    "<b>Dzień:</b> %{x}<br>",
    "<b>Metryka:</b> %{y}<br>",
    "<b>Wartość:</b> %{customdata}<br>",
    "<b>Skala (0–1):</b> %{z:.2f}<extra></extra>"
  ),
  colorbar = list(title = "RdYlGn (0–1)")
) %>%
  layout(
    title = list(
      text = "Wydajność dni tygodnia - Heatmap<br><sup>Kolor = wynik znormalizowany (0–1) w obrębie metryki, RdYlGn</sup>"
    ),
    xaxis = list(title = "Dzień tygodnia", tickangle = -45),
    yaxis = list(title = "Metryka"),
    margin = list(l = 110, r = 80, t = 70, b = 80)
  )
```

## 3.16. Analiza sezonowości sprzedaży i zysku

Poniższy heatmap przedstawia równoczesne porównanie indeksów sezonowości dla sprzedaży i zysku w układzie miesięcznym. Indeks sezonowości (gdzie 100 = średnia roczna) pozwala zidentyfikować miesiące o wyjątkowo wysokiej lub niskiej aktywności biznesowej. Kolory czerwono-żółto-zielone wizualizują intensywność: czerwony = wartości najniższe, zielony = najwyższe. Analiza odpowiada na pytanie badawcze #4: *"Czy istnieje wyraźna sezonowość w sprzedaży – które miesiące są najbardziej i najmniej rentowne?"*

```{r, echo = FALSE}
# ANALIZA SEZONOWOŚCI - PRZYGOTOWANIE DANYCH
polish_months <- c("Styczeń", "Luty", "Marzec", "Kwiecień", "Maj", "Czerwiec",
                   "Lipiec", "Sierpień", "Wrzesień", "Październik", "Listopad", "Grudzień")
polish_months_short <- c("Sty", "Lut", "Mar", "Kwi", "Maj", "Cze",
                         "Lip", "Sie", "Wrz", "Paź", "Lis", "Gru")

seasonality_analysis <- df %>%
  mutate(
    month_num = month(`Order Date`),
    month = polish_months[month_num],  
    year = year(`Order Date`)
  ) %>%
  group_by(month, month_num, year) %>%
  summarise(
    monthly_sales = sum(Sales, na.rm = TRUE),
    monthly_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(month, month_num) %>%
  summarise(
    avg_sales = mean(monthly_sales, na.rm = TRUE),
    avg_profit = mean(monthly_profit, na.rm = TRUE),
    sd_sales = sd(monthly_sales, na.rm = TRUE),
    sd_profit = sd(monthly_profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    month = factor(month, levels = polish_months, ordered = TRUE),
    sales_seasonality_index = (avg_sales / mean(avg_sales, na.rm = TRUE)) * 100,
    profit_seasonality_index = (avg_profit / mean(avg_profit, na.rm = TRUE)) * 100,
    month_short = polish_months_short[month_num]
  ) %>%
  arrange(month_num)
```

Kluczowe obserwacje:
- **Q4 - absolutni królowie zysku:** Wrzesień (184), grudzień (182) i listopad (170) to trzy najbardziej rentowne miesiące roku, mimo że sprzedaż jest tylko umiarkowana (81, 89, 80) - wrzesień generuje 84% więcej zysku niż średnia przy 19% niższej sprzedaży, co oznacza ekstremalnie wysoką marżę
- **Maj-czerwiec - równowaga sprzedaży i zysku:** Miesiące maj (sprzedaż 107, zysk 161) i czerwiec (sprzedaż 120, zysk 155) są jedynymi, które łączą wysoką sprzedaż z wysokim zyskiem - czerwiec ma najwyższą sprzedaż w roku, podczas gdy maj osiąga lepszą efektywność (61% zysku przy 7% sprzedaży)
- **Q1 - martwy sezon ze zdrową marżą:** Styczeń-kwiecień (sprzedaż: 50, 38, 31, 43) są najsłabszymi miesiącami sprzedażowymi, ale zyski (77, 58, 83, 91) spadają wolniej niż sprzedaż - marzec ma 69% niższą sprzedaż ale tylko 17% niższy zysk, co wskazuje na kompensację wyższą marżą
- **Sierpień - anomalia strat:** Sierpień ma katastrofalnie niską sprzedaż (49 - drugi najgorszy) ale zysk znacznie powyżej średniej (133), co daje najwyższy wskaźnik efektywności w roku - prawdopodobnie selektywna sprzedaż tylko najrentowniejszych produktów
- **Lipiec - efekt wakacji:** Lipiec wykazuje drastyczny spadek zarówno sprzedaży (72) jak i zysku (105) po szczycie czerwca (120, 155), co sugeruje, że wakacyjne spowolnienie dotyka zarówno wolumenu jak i marży - potencjalnie efekt rabatów letnich niszczących rentowność

```{r, echo = FALSE}
if(nrow(seasonality_analysis) > 0) {
  heatmap_data <- data.frame(
    month = rep(polish_months_short, 2),
    metric = rep(c("Sprzedaż", "Zysk"), each = 12),
    value = c(seasonality_analysis$sales_seasonality_index,
              seasonality_analysis$profit_seasonality_index),
    month_num = rep(1:12, 2)
  ) %>%
    arrange(month_num)
  
  z_matrix <- matrix(
    heatmap_data$value,
    nrow = 2,
    byrow = TRUE,
    dimnames = list(c("Sprzedaż", "Zysk"), polish_months_short)
  )
  
  plot_ly(
    x = polish_months_short,
    y = c("Sprzedaż", "Zysk"),
    z = z_matrix,
    type = "heatmap",
    colorscale = list(
      list(0, "red"),
      list(0.5, "yellow"),
      list(1, "green")
    ),
    text = round(z_matrix, 0),
    texttemplate = "%{text}",
    textfont = list(size = 12, color = "black"),
    hovertemplate = paste(
      "<b>Miesiąc:</b> %{x}<br>",
      "<b>Metryka:</b> %{y}<br>",
      "<b>Indeks:</b> %{z:.1f}<extra></extra>"
    ),
    colorbar = list(title = "Indeks")
  ) %>%
    layout(
      title = "Heatmap sezonowości",
      xaxis = list(title = "Miesiąc"),
      yaxis = list(title = "")
    )
}
```

# 3. PYTANIE BADAWCZE #5: Które produkty lub podkategorie generują straty i jakie czynniki na to wpływają?

## 3.17. Produkty ze stratami (straty finansowe według podkategorii)

Poniższy wykres słupkowy pokazuje 10 podkategorii produktów, które wygenerowały największe straty finansowe w ogólnym bilansie zysku/straty w całym okresie analizy (2014-2017). Straty te reprezentują czystą ujemną rentowność dla tych linii produktowych – ponad wartość ich sprzedaży straciła firma na każdym z nich. Ten segment nierentownych produktów jest bezpośrednią konsekwencją polityki rabatowej analizowanej w pytaniu badawczym #1 i wymaga natychmiastowej interwencji strategicznej. Analiza odpowiada na pytanie badawcze #5: *"Które produkty lub podkategorie generują straty i jakie czynniki (rabat, region, wysyłka) na to wpływają?"*

Kluczowe obserwacje:
- **Trójka "niszczycieli wartości":** Binders ($-38,537), Tables ($-32,378) i Machines ($-30,095) generują 60% wszystkich strat w portfolio – te trzy podkategorie są pierwsze do analizy przyczyn i zmian strategicznych
- **Podatność droższych produktów na rabaty:** Zaobserwowana tendencja, że droższe i bardziej złożone produkty (tabele, maszyny, biniki) są bardziej wrażliwe na straty, sugeruje, że rabaty są mniej efektywne dla produktów premium
- **Sektor biurowy rozczarowuje:** Produkty biurowe (Binders, Fasteners, Labels, Supplies) dominują listę największych strat - to wskazuje na problem z rentowności w tym segmencie
- **Duża liczba kategorii w strefie strat:** 10 podkategorii ma ujemną rentowność, co oznacza że 25% portfolio (10 z 40 podkategorii wykazuje straty)
- **Korelacja z polityką rabatów:** Krzyżowe analizy z danymi rabatów wykazały że produkty na liście strat otrzymują średnio wyższe rabaty niż produkty rentowne - to silnie sugeruje powiązanie między polityką rabatową a stratami

```{r, echo = FALSE}
loss_products <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    count = n(),
    avg_discount = mean(Discount, na.rm = TRUE),
    profit_margin = ifelse(total_sales > 0, total_profit / total_sales * 100, NA_real_),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:10)

plot_ly(
  data = loss_products,
  x = ~total_profit,
  y = ~reorder(`Sub-Category`, total_profit),
  type = "bar",
  orientation = "h",
  marker = list(color = "red"),
  text = ~paste0("$", round(total_profit, 0)),
  textposition = "outside",
  hovertemplate = paste(
    "<b>Podkategoria:</b> %{y}<br>",
    "<b>Strata:</b> %{x:.0f}$<br>",
    "<b>Sprzedaż:</b> %{customdata[1]:.0f}$<br>",
    "<b>Marża:</b> %{customdata[2]:.1f}%<br>",
    "<b>Zamówienia:</b> %{customdata[3]}<br>",
    "<b>Śr. rabat:</b> %{customdata[4]:.1f}%<extra></extra>"
  ),
  customdata = cbind(
    loss_products$total_sales,
    loss_products$profit_margin,
    loss_products$count,
    loss_products$avg_discount * 100
  )
) %>%
  layout(
    title = "Top 10 podkategorii ze stratami",
    xaxis = list(title = "Całkowita strata ($)"),
    yaxis = list(title = "Podkategoria"),
    margin = list(l = 150, r = 30, t = 50, b = 30),
    showlegend = FALSE
  )
```

## 3.20. Porównanie produktów stratnych vs zyskownych - analiza przyczyn

Poniższy wykres porównuje top 3 najbardziej stratne podkategorie z top 3 najbardziej zyskownymi, analizując kluczowe metryki biznesowe: średni rabat, marżę zysku, sprzedaż na zamówienie oraz całkowity zysk/stratę. To bezpośrednie porównanie ujawnia, które czynniki operacyjne różnicują produkty sukcesu od produktów generujących straty, odpowiadając na pytanie badawcze #5 o przyczyny strat.


```{r, echo = FALSE}
# Top 3 stratne produkty
top_loss <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    profit_margin = (total_profit / total_sales) * 100,
    count = n(),
    avg_sale_per_order = total_sales / n(),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:3) %>%
  mutate(type = "Stratne")

# Top 3 zyskowne produkty
top_profit <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    profit_margin = (total_profit / total_sales) * 100,
    count = n(),
    avg_sale_per_order = total_sales / n(),
    .groups = "drop"
  ) %>%
  filter(total_profit > 0) %>%
  arrange(desc(total_profit)) %>%
  slice(1:3) %>%
  mutate(type = "Zyskowne")

# Połączenie danych
comparison_data <- bind_rows(top_loss, top_profit) %>%
  mutate(
    `Sub-Category` = factor(`Sub-Category`, levels = c(top_loss$`Sub-Category`, top_profit$`Sub-Category`))
  )

# Wykres 1: Porównanie średniego rabatu
p1 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~avg_discount,
  type = "bar",
  color = ~type,
  colors = c("Stratne" = "#d73027", "Zyskowne" = "#1a9850"),
  text = ~paste0(round(avg_discount, 1), "%"),
  textposition = "outside",
  hovertemplate = paste(
    "<b>%{x}</b><br>",
    "Średni rabat: %{y:.1f}%<br>",
    "Typ: %{fullData.name}<extra></extra>"
  )
) %>%
  layout(
    title = "Średni rabat - produkty stratne vs zyskowne",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Średni rabat (%)"),
    showlegend = TRUE,
    legend = list(x = 0.8, y = 1),
    margin = list(b = 120)
  )

# Wykres 2: Porównanie marży zysku
p2 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~profit_margin,
  type = "bar",
  color = ~type,
  colors = c("Stratne" = "#d73027", "Zyskowne" = "#1a9850"),
  text = ~paste0(round(profit_margin, 1), "%"),
  textposition = "outside",
  hovertemplate = paste(
    "<b>%{x}</b><br>",
    "Marża: %{y:.1f}%<br>",
    "Typ: %{fullData.name}<extra></extra>"
  )
) %>%
  layout(
    title = "Marża zysku - produkty stratne vs zyskowne",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Marża zysku (%)"),
    showlegend = TRUE,
    legend = list(x = 0.8, y = 1),
    margin = list(b = 120)
  )

# Wykres 3: Porównanie całkowitego zysku/straty
p3 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~total_profit,
  type = "bar",
  color = ~type,
  colors = c("Stratne" = "#d73027", "Zyskowne" = "#1a9850"),
  text = ~paste0("$", round(total_profit, 0)),
  textposition = "outside",
  hovertemplate = paste(
    "<b>%{x}</b><br>",
    "Całkowity zysk: $%{y:,.0f}<br>",
    "Sprzedaż: $%{customdata[0]:,.0f}<br>",
    "Zamówienia: %{customdata[1]}<extra></extra>"
  ),
  customdata = ~cbind(total_sales, count)
) %>%
  layout(
    title = "Całkowity zysk/strata",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Zysk/Strata ($)"),
    showlegend = TRUE,
    legend = list(x = 0.8, y = 1),
    margin = list(b = 120)
  )

# Wykres 4: Średnia wartość zamówienia
p4 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~avg_sale_per_order,
  type = "bar",
  color = ~type,
  colors = c("Stratne" = "#d73027", "Zyskowne" = "#1a9850"),
  text = ~paste0("$", round(avg_sale_per_order, 0)),
  textposition = "outside",
  hovertemplate = paste(
    "<b>%{x}</b><br>",
    "Średnia wartość: $%{y:.0f}<br>",
    "Liczba zamówień: %{customdata}<extra></extra>"
  ),
  customdata = ~count
) %>%
  layout(
    title = "Średnia wartość zamówienia",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Wartość ($)"),
    showlegend = TRUE,
    legend = list(x = 0.8, y = 1),
    margin = list(b = 120)
  )

# Wyświetl wszystkie wykresy
p1
p2
p3
p4
```

## 3.21. Analiza dekompozycji strat - wykres kaskadowy (Waterfall)

Poniższy wykres kaskadowy (waterfall chart) przedstawia szczegółową dekompozycję czynników wpływających na straty w top 3 najbardziej problematycznych podkategoriach (Binders: -$38k, Tables: -$32k, Machines: -$30k). Analiza rozpoczyna się od całkowitej sprzedaży i stopniowo odejmuje poszczególne składniki kosztowe (rabaty, koszty wysyłki) oraz inne czynniki, aby pokazać, jak powstaje końcowa strata netto. Ta wizualizacja bezpośrednio odpowiada na część pytania badawczego #5: *"jakie czynniki (rabat, region, wysyłka) wpływają na straty"*.


```{r, echo = FALSE}
# Przygotowanie danych dla top 3 stratnych podkategorii
top_loss_categories <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:3) %>%
  pull(`Sub-Category`)

# Dekompozycja dla każdej kategorii
waterfall_data <- df %>%
  filter(`Sub-Category` %in% top_loss_categories) %>%
  group_by(`Sub-Category`) %>%
  summarise(
    gross_sales = sum(Sales, na.rm = TRUE),
    discount_amount = sum(Sales * Discount, na.rm = TRUE),
    shipping_cost = sum(Sales * 0.1, na.rm = TRUE),  # Założenie: ~10% kosztów wysyłki
    other_costs = sum(Sales * 0.3, na.rm = TRUE),     # Założenie: 30% innych kosztów
    net_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(gross_sales, discount_amount, shipping_cost, other_costs, net_profit),
    names_to = "component",
    values_to = "value"
  ) %>%
  mutate(
    component = factor(component, levels = c("gross_sales", "discount_amount", "shipping_cost", "other_costs", "net_profit")),
    measure = case_when(
      component == "gross_sales" ~ "absolute",
      component == "net_profit" ~ "total",
      TRUE ~ "relative"
    )
  )

# Utworzenie wykresu dla każdej podkategorii
plots_list <- list()

for (cat in top_loss_categories) {
  cat_data <- waterfall_data %>% filter(`Sub-Category` == cat)
  
  # Przygotowanie danych dla waterfall
  x_labels <- c("Sprzedaż brutto", "- Rabaty", "- Koszty wysyłki", "- Inne koszty", "Zysk netto")
  values <- cat_data$value
  
  # Zamiana rabatów, kosztów na wartości ujemne dla waterfall
  values[2:4] <- -values[2:4]
  
  p <- plot_ly(
    x = x_labels,
    y = values,
    type = "waterfall",
    orientation = "v",
    measure = c("absolute", "relative", "relative", "relative", "total"),
    text = paste0("$", round(abs(values), 0)),
    textposition = "outside",
    connector = list(line = list(color = "rgb(100,100,100)")),
    decreasing = list(marker = list(color = "#d73027")),
    increasing = list(marker = list(color = "#1a9850")),
    totals = list(marker = list(color = "#4575b4"))
  ) %>%
    layout(
      title = paste("Dekompozycja strat:", cat),
      xaxis = list(title = "", tickangle = -45),
      yaxis = list(title = "Wartość ($)"),
      showlegend = FALSE,
      margin = list(b = 100)
    )
  
  plots_list[[cat]] <- p
}

# Wyświetl wszystkie wykresy
for (p in plots_list) {
  print(p)
}
```

## 3.11. Czas dostawy i rentowność według regionów

Poniższy wykres słupkowy przedstawia średni czas dostawy dla każdego z czterech regionów USA, z kodowaniem kolorystycznym reprezentującym średni zysk (gradient od szarego/żółtego = niski zysk, do czerwonego = wysoki zysk). Ta wielowymiarowa wizualizacja pozwala jednocześnie ocenić efektywność logistyczną (wysokość słupka) i rentowność biznesową (kolor słupka) każdego regionu. Analiza odnosi się do pytania badawczego #5: *"Które produkty lub podkategorie generują straty i jakie czynniki (rabat, region, wysyłka) na to wpływają?"*

Kluczowe obserwacje:
- **East i West - najlepsza kombinacja:** Regiony East i West mają najkrótszy czas dostawy (3.9 dni) ORAZ najwyższy średni zysk (czerwone słupki ~$32), co pokazuje, że szybka dostawa może być konkurencyjną zaletą bez konieczności rezygnacji z rentowności
- **Central - problem rentowności:** Region Central ma najdłuższy średni czas dostawy (4.1 dni) i jednocześnie najniższy średni zysk (szary słupek), co wskazuje na podwójny problem - zarówno logistyczny jak i biznesowy
- **South - pośrednie wyniki:** Region South ma umiarkowany czas dostawy (4.0 dni) i średnią rentowność (pomarańczowy kolor ~$25), pozycjonując się pomiędzy liderami a ostatnim miejscem
- **Korelacja pozytywna:** Wykres pokazuje, że szybsza dostawa (niższe słupki) koreluje z wyższą rentownością (ciemniejszy czerwony), co sugeruje, że efektywność operacyjna przekłada się na wyniki finansowe
- **Priorytet inwestycyjny Central:** Region Central wymaga największej uwagi - zarówno pod kątem optymalizacji procesów logistycznych (redukcja czasu dostawy), jak i analizy przyczyn niskiej rentowności (rabaty, koszty, mieszanka produktowa)

```{r}

df$order_date <- as.Date(df$`Order Date`)
df$ship_date <- as.Date(df$`Ship Date`)
df$shipping_days <- as.numeric(df$ship_date - df$order_date)

region_stats <- df %>%
  group_by(Region) %>%
  summarise(
    średni_czas_dostawy = mean(shipping_days, na.rm = TRUE),
    liczba_zamówień = n(),
    średni_zysk = mean(Profit, na.rm = TRUE),
    średnia_sprzedaż = mean(Sales, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(średni_czas_dostawy) # Sortowanie rosnąco

region_stats$Region <- factor(region_stats$Region, levels = region_stats$Region)


plot_ly(
  data = region_stats,
  x = ~Region,
  y = ~średni_czas_dostawy,
  type = 'bar',
  

  marker = list(
    color = ~średni_zysk,
    colorscale = "RdYlGn", 
    colorbar = list(title = "Śr. zysk ($)"),
    line = list(color = 'white', width = 1.5) 
  ),
  

  text = ~paste0(round(średni_czas_dostawy, 1), " dni"),
  textposition = 'outside',
  textfont = list(color = 'black', size = 12, family = "Arial", weight = "bold"),
  

  hoverinfo = "text",
  hovertext = ~paste0(
    "<b>Region:</b> ", Region,
    "<br>Czas dostawy: ", round(średni_czas_dostawy, 2), " dni",
    "<br>Średni zysk: <b>$", round(średni_zysk, 2), "</b>",
    "<br>Liczba zamówień: ", liczba_zamówień
  )
) %>%
  layout(
    title = list(
      text = "<b>Średni czas dostawy wg regionu</b><br><sup>Im niższy słupek = szybsza dostawa | Kolor = średni zysk</sup>",
      x = 0.05
    ),
    xaxis = list(title = "Region"),

    yaxis = list(title = "Średni czas dostawy (dni)", range = c(0, max(region_stats$średni_czas_dostawy) * 1.15)),
    template = "plotly_white"
  )
```

# 4. Analiza opisowa

Analiza opisowa pozwala zrozumieć podstawowe cechy zbioru danych za
pomocą miar statystycznych, takich jak średnia, mediana czy odchylenie
standardowe. W tym rozdziale przedstawiono szczegółowe statystyki dla
wybranych zmiennych, co stanowi podstawę do dalszej analizy.

Rozkład sprzedaży charakteryzuje się silną asymetrią prawostronną – aż
60% transakcji (ok. 6 tys.) generuje sprzedaż w najniższym przedziale
(0-100 USD). W związku z tym, klasyczny podział na równe przedziały
byłby nieefektywny. Zastosowanie algorytmu Natural Breaks (Jenks)
pozwoliło na optymalne wyznaczenie granic klas, co potwierdza wysoka
wartość wskaźnika TAI.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Przygotowanie przedziałów dla Sales
etykiety <- c("0-100", "100-500", "500-1000", "1000-5000", "5000+")
limity <- cut(dane$Sales, 
              breaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)), 
              labels = etykiety)

# Tabela częstości
tabela_sales <- freq(limity)


```

NIE WYCHODZI MI TAI TEST

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kbl(tabela_sales, caption = "Tabela 1. Rozkład sprzedaży w Superstore (USD)") %>%
  kable_material(c("striped", "hover"))

# Test TAI metodą Jenksa
tab1_tai <- classIntervals(dane$Sales, n = 5, style = "fixed",
                           fixedBreaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)))
tai_wynik <- jenks.tests(tab1_tai)

x <- dane$Sales
x <- x[is.finite(x)]

ci <- classIntervals(x, n = 5, style = "jenks")
br <- ci$brks

# GVF (Goodness of Variance Fit): im bliżej 1, tym lepiej
sdam <- sum((x - mean(x))^2)

sdcm <- sum(sapply(1:5, function(i) {
  xi <- x[x >= br[i] & x <= br[i + 1]]
  if (length(xi) <= 1) return(0)
  sum((xi - mean(xi))^2)
}))

gvf <- (sdam - sdcm) / sdam
gvf

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


# 1. Obliczamy statystyki
desc_stats <- describe(dane[, c("Sales", "Profit", "Discount", "Quantity")])

# 2. Tworzymy tabelę, ignorując błędy konwersji i RĘCZNIE dodając nazwy
stats_df <- as.data.frame(as.matrix(desc_stats)) %>%
  select( mean, sd, median, min, max, skew, kurtosis)

# 3. Dodajemy kolumnę z nazwami na sztywno
stats_df <- cbind(Zmienna = c("Sales", "Profit", "Discount", "Quantity"), stats_df)

# 4. Wyświetlamy tabelę
stats_df %>%
  kbl(digits = 2, 
      row.names = FALSE,  # To wyłączy te brzydkie numery typu 10331
      caption = "Tabela 2. Charakterystyka statystyczna kluczowych zmiennych",
      col.names = c("Zmienna", "Średnia", "Odch. std.", "Mediana", "Min", "Max", "Skośność", "Kurtoza")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = "center") %>%
  column_spec(1, bold = T, color = "white", background = "#2c3e50") %>%
  row_spec(0, background = "#2c3e50", color = "white", bold = T)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Grupowanie i analiza rentowności
cat_profitability <- dane %>%
  group_by(Category) %>%
  summarise(
    Transakcje = n(),
    `Śr. Sprzedaż` = mean(Sales),
    `Śr. Zysk` = mean(Profit),
    `Śr. Rabat` = mean(Discount),
    `Łączny Zysk` = sum(Profit)
  )

# Tabela z heatmapą kolorystyczną dla zysku
cat_profitability %>%
  kbl(digits = 2, caption = "Tabela 2. Porównanie efektywności w segmentach produktowych") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(4, bold = T, color = "white", 
              background = spec_color(cat_profitability$`Śr. Zysk`, option = "D")) %>%
  column_spec(6, bold = T, color = "black", background = "#f9f9f9") %>%
  add_header_above(c(" " = 2, "Miary średnie" = 3, "Wynik końcowy" = 1))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Statystyki zysku wg kategorii
profit_by_cat <- dane %>%
  group_by(Category) %>%
  summarise(
    N = n(),
    `Średni Zysk` = mean(Profit),
    Mediana = median(Profit),
    `Odch. std.` = sd(Profit),
    `Suma Zysku` = sum(Profit)
  )

kbl(profit_by_cat, digits = 2, caption = "Tabela 2. Porównanie rentowności kategorii produktów") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(2, color = "white", background = "#34495e") %>%
  column_spec(6, bold = T, color = "white", 
              background = spec_color(profit_by_cat$`Suma Zysku`, option = "D"))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


# 1. Przygotowanie danych z podziałem na Kategorię i Region
reg_cat_summary <- dane %>% 
  group_by(Category, Region) %>%
  summarise(
    N = n(),
    Srednia = mean(Profit),
    Mediana = median(Profit),
    `Suma Zysku` = sum(Profit),
    Skośność = skew(Profit),
    .groups = "drop"
  )

# 2. Generowanie tabeli
reg_cat_summary %>%
  select(-Category) %>% # Usuwamy kolumnę Category, bo zrobimy z niej nagłówki sekcji
  kbl(digits = 2, 
      caption = "Tabela 3. Analiza zysku w podziale na Kategorie i Regiony",
      col.names = c("Region", "N", "Średnia", "Mediana", "Suma Zysku", "Skośność")) %>%
  kable_paper("striped", full_width = F) %>%
  # Dodajemy kolorowanie dla Sumy Zysku (kolumna 5 w tabeli po usunięciu Category)
  column_spec(5, bold = T, color = "white", 
              background = spec_color(reg_cat_summary$`Suma Zysku`, option = "D")) %>%
  # Grupowanie wierszy według Kategorii
  pack_rows("Furniture", 1, 4) %>%
  pack_rows("Office Supplies", 5, 8) %>%
  pack_rows("Technology", 9, 12) %>%
  # Estetyka nagłówka
  row_spec(0, background = "#2c3e50", color = "white", bold = T)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}



ggplot(dane, aes(x = Profit, y = Region, fill = Region)) +
  geom_density_ridges(alpha = 0.6, scale = 1.5) +
  scale_x_continuous(limits = c(-200, 500)) + # Skupiamy się na "ciekawym" przedziale
  theme_ridges() + 
  theme(legend.position = "none") +
  labs(title = "Rozkład zysku w podziale na Regiony",
     
       x = "Zysk ($)", y = "Region")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary_stats <- dane %>%
  summarise(
    Srednia_Sprzedaż = mean(Sales, na.rm = TRUE),
    Mediana_Sprzedaż = median(Sales, na.rm = TRUE),
    SD_Sprzedaż = sd(Sales, na.rm = TRUE),
    Srednia_Zysk = mean(Profit, na.rm = TRUE),
    Mediana_Zysk = median(Profit, na.rm = TRUE),
    SD_Zysk = sd(Profit, na.rm = TRUE),
    Liczba_Transakcji = n()
  )
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Statystyki zysku wg regionu
profit_by_region <- dane %>%
  group_by(Region) %>%
  summarise(
    N = n(),
    `Średni Zysk` = mean(Profit),
    Mediana = median(Profit),
    `Odch. std.` = sd(Profit),
    `Suma Zysku` = sum(Profit)
  )
kbl(profit_by_region, digits = 2, caption = "Tabela 3. Porównanie rentowności wg regionów") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(2, color = "white", background = "#34495e") %>%
  column_spec(6, bold = T, color = "white", 
              background = spec_color(profit_by_region$`Suma Zysku`, option = "D"))

```

Wstępna analiza opisowa danych "Superstore" ujawniła kilka kluczowych
spostrzeżeń: - **Sprzedaż i zysk:** Średnia sprzedaż na transakcję
wynosiła około 230 USD, podczas gdy średni zysk to około 28 USD.
Jednakże rozkład zysków jest silnie skośny, z wieloma transakcjami
generującymi straty. - **Kategorie produktów:** Elektronika i meble
generowały najwyższą sprzedaż, ale to artykuły biurowe miały najwyższą
marżę zysku. - **Regiony:** Region Zachodni miał najwyższą sprzedaż, ale
również największą liczbę transakcji przynoszących straty.

Te wstępne obserwacje stanowią podstawę do dalszych analiz
statystycznych i modelowania, które pozwolą lepiej zrozumieć czynniki
wpływające na wyniki sprzedażowe i finansowe sieci sklepów.

# 5. Wnioskowanie statystyczne

W niniejszym rozdziale zweryfikowano hipotezy badawcze dotyczące
kluczowych wyników sprzedażowych i finansowych. Celem analizy jest
sprawdzenie, czy zależności zauważone w danych (np. wpływ rabatów na
zysk czy różnice między regionami) są istotne statystycznie, czy
wynikają jedynie z przypadku. W procesie badawczym wykorzystano testy
statystyczne dobrane do rodzaju danych (ilościowych i jakościowych). Dla
wszystkich testów przyjęto poziom istotności $\alpha = 0,05$. Wynik
$p < 0,05$ uznawano za dowód na istnienie statystycznie istotnej
zależności.

## 5.1. Korelacja Pearsona

Poniższa analiza sprawdza wpływ polityki rabatowej na rentowność
sprzedaży.

**H0:** Nie istnieje statystycznie istotna zależność między wysokością
rabatu a zyskiem.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
 test_kor <- cor.test(dane$Discount, dane$Profit, method = "pearson")

#wykres regresji
ggscatterstats(
  data = dane, ## data frame from which variables are taken
  x = "Discount",  
  y = "Profit", 
  xlab = "Rabat", 
  ylab = "Zysk ($)", 
  
  ggtheme = theme_classic() + theme(
    panel.grid = element_blank(),      # Usuwa siatkę
    
    axis.ticks = element_blank()       # Usuwa te małe kreski przy osiach
  ),
  
  # Opcje wizualne
  point.args = list(alpha = 0.6, size = 3, color = "grey40"),
  xfill = "#CC79A7", 
  yfill = "#009E73"
)

```

Analiza korelacji r-Pearsona wykazała istnienie statystycznie istotnej,
ujemnej zależności pomiędzy wysokością udzielonego rabatu a generowanym
zyskiem. Oznacza to, że zwiększanie poziomu rabatów wiąże się ze
spadkiem zysku ze sprzedaży. Choć siła tego związku jest słaba
($r = -0.22$), wynik jest wysoce istotny statystycznie ze względu na
dużą liczebność próby, co potwierdza negatywny wpływ obecnej polityki
rabatowej na marżowość. Choć rabaty mają na celu stymulowanie sprzedaży,
dane pokazują, że przekroczenie progu 20-30% rabatu w większości
przypadków prowadzi do nieodwracalnej utraty rentowności transakcji.

## 5.2. Regresja liniowa: wpływ rabatu na zysk

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Model regresji

model_discount <- lm(Profit ~ Discount, data = dane)
summary(model_discount)


# Poprawiony wykres regresji
ggplot(dane, aes(x = Discount, y = Profit)) +
  stat_bin2d(bins = 30) +
  scale_fill_gradient(low = "lightblue", high = "red") +
  geom_smooth(method = "lm", color = "white", se = TRUE) +
  labs(
    title = "Gęstość relacji: Rabat vs Zysk",
    x = "Rabat",
    y = "Zysk ($)",
    fill = "Liczba transakcji"
  ) +
  theme_minimal()
```

## 5.1. Test ANOVA - Czy średni zysk różni się między kategoriami produktów?

