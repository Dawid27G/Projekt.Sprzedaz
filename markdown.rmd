---
title: "Raport – Analiza danych Superstore"
author: "Dawid Genert, Agnieszka Ancypo, Sylwia Bech"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    toc_float: true
      
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  warning = FALSE
)

pkgs <- c(
  "readxl","dplyr","mice","lubridate","tidyr","naniar","plotly","ggplot2",
  "corrplot","Hmisc","ggstatsplot","classInt","kableExtra","psych",
  "ggridges","frequency", "rmdformats", "DT"
)

miss <- setdiff(pkgs, rownames(installed.packages()))
if (length(miss)) {
  stop(
    "Brakuje pakietów: ", paste(miss, collapse = ", "),
    "\nZainstaluj je poleceniem z README.md"
  )
}

invisible(lapply(pkgs, library, character.only = TRUE))

dane <- read_excel(file.path("data","superstore.xls"), sheet = 1)
dane_disc <- read_excel(file.path("data","superstore.xls"), sheet = 2)

df <- dane %>%
mutate(
  `Order Date` = as.Date(`Order Date`),
  Sales    = as.numeric(Sales),
  Profit   = as.numeric(Profit),
  Quantity = as.numeric(Quantity),
  Discount = as.numeric(Discount),
  Category = as.character(Category),
  Segment  = as.character(Segment),
  `Ship Date`  = as.Date(`Ship Date`)
)

```

# 1. Wprowadzenie

Celem niniejszego projektu jest analiza zbioru danych "Superstore",
zawierającego informacje o transakcjach detalicznych w sieci sklepów.
Zbiór obejmuje dane o sprzedaży, zyskach, kategoriach produktów oraz
lokalizacji klientów na terenie USA.

Główne pytania badawcze:

1.  Jaki wpływ mają rabaty na zysk - czy większy rabat zawsze zwiększa
    sprzedaż kosztem rentowności?

2.  Które kategorie i podkategorie produktów generują najwyższą
    sprzedaż, a które najwyższy zysk?

3.  Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej)
    rentowności?

4.  Jak zmieniały się sprzedaż i zysk w czasie - czy występuje
    sezonowość?

5.  Które produkty lub podkategorie generują straty i jakie czynniki
    (rabat, region, wysyłka) na to wpływają?

# 2. Data Cleansing & Data Wrangling

Proces przygotowania danych był wieloetapowy, aby zapewnić najwyższą
jakość analizy.

## 2.1. Ogólny przegląd braków danych

Poniższy wykres przedstawia globalną wizualizację kompletności zbioru
danych Superstore. Szary obszar reprezentuje obserwacje z kompletnymi
danymi (Present \> 98.9%), podczas gdy niewielkie czarne fragmenty
wskazują na braki w danych (Missing \< 0.1%). Każdy wiersz na wykresie
odpowiada pojedynczej zmiennej, a każda kolumna reprezentuje kolejne
obserwacje w zbiorze.

Kluczowe obserwacje: - **Wysoka kompletność danych:** Ponad 98.9%
wszystkich wartości w zbiorze jest dostępnych, co świadczy o bardzo
dobrej jakości danych źródłowych - **Marginalne braki:** Braki danych
stanowią mniej niż 1% całego zbioru, co jest doskonałym wynikiem dla
danych transakcyjnych - **Koncentracja braków:** Czarne linie widoczne w
górnej części wykresu wskazują, że braki koncentrują się w określonych
zmiennych (prawdopodobnie Discount, Profit oraz dane adresowe), podczas
gdy większość zmiennych jest w pełni kompletna - **Losowy rozkład:**
Braki wydają się być rozłożone losowo wzdłuż obserwacji, co sugeruje
brak systematycznego wzorca utraty danych związanego z czasem lub
procesem zbierania danych - **Gotowość do analizy:** Minimalny odsetek
braków i ich niesystematyczny charakter potwierdzają, że zbiór nadaje
się do dalszej analizy po zastosowaniu odpowiednich technik imputacji

```{r, echo=FALSE, message=FALSE, warning=FALSE}
vis_miss(dane)
```

## 2.2. Rozkład braków według zmiennych

Poniższy wykres słupkowy przedstawia liczbę brakujących wartości
(missing values) w każdej zmiennej zbioru danych. Długość słupka
odpowiada liczbie obserwacji z brakami. Zmienne są posortowane malejąco
według liczby braków, co pozwala na szybką identyfikację najbardziej
problematycznych kolumn.

Kluczowe obserwacje: - **Profit i Discount - istotne braki finansowe:**
Zmienne związane z zyskami i rabatami wykazują znaczną liczbę braków, co
jest krytyczne dla analizy rentowności i wymaga zaawansowanych technik
imputacji - **Dane adresowe - równomierne braki:** City i State wykazują
podobną liczbę braków, co sugeruje, że braki w danych adresowych mogą
występować razem w tych samych obserwacjach - **Order Date i Ship Date -
marginalne braki:** Daty mają umiarkowaną liczbę braków, które mogą być
imputowane na podstawie logiki biznesowej (mediana czasu dostawy)
-**Większość zmiennych kompletna:** Wiele zmiennych nie ma braków wcale
(Sales, Quantity, Category, Sub-Category, Region, Product ID, Order ID,
Customer ID), co potwierdza ogólną dobrą jakość danych - **Wymiar
problemu:** Koncentracja braków w kilku kluczowych zmiennych (Postal
Code, Profit, Discount, City, State) oznacza, że strategia imputacji
powinna być priorytetowo skierowana na te obszary, podczas gdy reszta
zbioru pozostaje w pełni użyteczna

```{r, echo=FALSE, message=FALSE, warning=FALSE}
gg_miss_var(dane) +
  labs(title = "Liczba braków danych w każdej zmiennej")
```

## 2.3. Rozkład braków w obserwacjach

Poniższy wykres pokazuje liczbę brakujących wartości w każdej obserwacji
(wierszu) zbioru danych. Oś X reprezentuje liczbę braków w każdym
wierszu, a oś Y pokazuje kolejne obserwacje. Długość horyzontalnego
paska dla każdej obserwacji odpowiada liczbie brakujących danych w tym
wierszu.

Kluczowe obserwacje: - **Większość wierszy kompletnych:** Zdecydowana
większość obserwacji (te na górze wykresu) ma bardzo mało braków -
prawie zerową liczbę brakujących wartości, co świadczy o dobrej
kompletności danych - **Rozrzedzenie braków:** Braki są rozproszone po
poszczególnych wierszach, a nie skupione w kilku obserwacjach, co
oznacza, że żaden wiersz nie jest "całkowicie nieużyteczny"
-**Maksymalnie około 1-2 braki na wiersz:** Nawet wiersze z największą
liczbą braków mają poniżej 2 brakujących wartości, co jest bardzo dobrym
wynikiem - **Brak wzorca systematycznego:** Rozłożenie braków wzdłuż osi
Y wskazuje, że braki nie są skoncentrowane w określonej części zbioru
danych (np. na początku lub końcu) - **Łatwa imputacja:** Ta struktura
braków czyni imputację stosunkowo prostą - większość wierszy będzie
można użyć bez jakichkolwiek modyfikacji, a dla tych kilku z brakami
wystarczą proste strategie uzupełnienia

```{r, echo=FALSE, message=FALSE, warning=FALSE}
gg_miss_case(dane) +
  labs(title = "Braki danych w poszczególnych wierszach")
```

## 2.4. Kombinacje braków danych - Upset Plot

Poniższy diagram "UpSet" pokazuje, które zmienne mają braki
jednocześnie, czyli jakie kombinacje braków danych występują razem. Lewy
panel (słupki poziome) pokazuje liczebność poszczególnych braków, a
górny panel (słupki pionowe) pokazuje, ile obserwacji ma konkretną
kombinację braków. Linie łączące słupki wskazują, które zmienne brakują
razem.

Kluczowe obserwacje: - **Shop Mode NA dominuje:** Braki w zmiennej Shop
Mode (dostaw) są najczęstsze i najczęściej pojawią się samodzielnie (bez
innych braków) - **Quantity NA - druga na liście:** Ilość produktów ma
drugą co do liczby braków, również głównie niezależnie od innych
zmiennych - **Profit NA - trzeci:** Braki w zysku pojawiają się na
trzecim miejscu i również często bez towarzystwa innych braków -
**Sub-Category i Discount - rzadsze braki:** Te zmienne mają mniej
braków niż poprzednie - **Niska współzależność braków:** Brak wyraźnych
pionowych linii łączących oznacza, że braki raczej nie kumulują się -
czyli jeśli brakuje wartości w Shop Mode, to nie znaczy że będą braki w
Quantity czy Profit - **Imputacja niezależna:** Taka struktura braków
sugeruje, że każdą zmienną można imputować niezależnie, bez konieczności
rozpatrywania złożonych zależności między brakami

```{r, echo=FALSE, message=FALSE, warning=FALSE}
gg_miss_upset(dane)
```

## 2.5. Wzory braków danych - Pattern Matrix

Poniższy diagram "md.pattern" przedstawia macierz wzorów braków danych.
Każdy wiersz reprezentuje inny wzór braków (kombinację kompletnych i
brakujących wartości), a każda kolumna reprezentuje zmienną. Niebieskie
kwadraty oznaczają dane dostępne (present), a różowe/czerwone oznaczają
braki. Liczby po lewej stronie pokazują, ile obserwacji ma dany wzór
braków, a liczby na dole pokazują łączną liczbę braków w każdej
zmiennej.

Kluczowe obserwacje: - **Dominacja kompletnych obserwacji:** Pierwszy
wiersz (9933 obserwacji) reprezentuje dane całkowicie kompletne - prawie
wszystkie wiersze należą do tej grupy - **Minimalna liczba wzorów
braków:** Tylko kilka alternatywnych wzorów braków pojawia się w
zbiorze, co oznacza niesystematyczne braki - nie ma jednego dominującego
wzoru - **Rzadkie kumulacje braków:** Żaden wzór braku nie ma więcej niż
kilka obserwacji, co potwierdza, że braki są rozrzedzane po zbiorze -
**Braki w różnych zmiennych:** Różowe pola pojawiają się w różnych
kolumnach dla różnych wierszy, wskazując, że braki nie kumulują się w
tych samych obserwacjach - **Łatwa interpretacja:** Dolna linia
pokazuje, że niektóre zmienne (te po prawej) mają braki, podczas gdy
inne (po lewej) są całkowicie kompletne - **Skuteczność imputacji:** Ta
struktura sugeruje, że imputacja będzie prosta - większość danych można
wykorzystać bez zmian, a dla kilku wierszy z brakami wystarczy
zastosować odpowiednie strategie uzupełnienia

```{r, echo=FALSE, message=FALSE, warning=FALSE}
md.pattern(dane)
```

## 2.6. Mechanizm braków danych - Wnioski z analizy

Na podstawie kompleksowej analizy wszystkich powyższych wykresów możemy
stwierdzić, że braki danych w zbiorze Superstore mają charakter **MCAR
(Missing Completely At Random)**. Dowodami na to są:

-   **Ze wzoru vis_miss (2.1):** - Braki rozproszone losowo po całej
    matrycy bez skupień czy wzorów - Brak systematycznego trendu braków
    na osi czasowej/wierszy

-   **Ze wzoru gg_miss_var (2.2):** - Różne zmienne mają różne liczby
    braków (Discount, Profit, City, State) - nie ma jednego źródła
    problemu - Braki są niezależne dla każdej zmiennej

-   **Ze wzoru gg_miss_case (2.3):** - Maksymalnie 1-2 braki na
    obserwację (żaden wiersz nie ma wielu braków jednocześnie) - Braki
    nie kumulują się w tych samych obserwacjach - Rozpylenie braków
    wskazuje na niezależność mechanizmu

-   **Ze wzoru gg_miss_upset (2.4):** - Dominujące są pojedyncze braki w
    zmiennych, a nie kombinacje - Brak wyraźnych "łańcuszków" braków
    (braki jednej zmiennej nie powodują braków w innej) - Niska
    współzależność między brakami potwierdza ich niezależność

-   **Ze wzoru md.pattern (2.5):** - 9933 obserwacji w pełni kompletnych
    vs zaledwie kilka alternatywnych wzorów - Każdy alternatywny wzór
    braku pojawia się zaledwie kilka razy - Wzory są różnorodne, co
    wskazuje na losowość

-   **Konsekwencje dla imputacji:** MCAR to najkorzystniejszy typ
    mechanizmu braków, ponieważ: - Braki są całkowicie niezależne od
    danych i wartości zmiennych - Możemy bezpiecznie stosować
    zaawansowane metody imputacji (MICE, hot-deck, PMM) - Wyniki analiz
    nie będą obciążone odchyleniami wynikającymi z selektywnych braków -
    Nie ma potrzeby stosowania zawiłych procedur wagowania czy korekcji
    błędu systematycznego

```{r include=FALSE}

hotdeck_grouped <- function(x, group_df) {
  out <- x
  g <- interaction(group_df, drop = TRUE)

  for (lv in levels(g)) {
    idx <- which(g == lv)
    vals <- x[idx]
    miss <- is.na(vals)

    if (any(miss) && any(!miss)) {
      out[idx][miss] <- sample(vals[!miss], sum(miss), replace = TRUE)
    }
  }


  if (any(is.na(out)) && any(!is.na(out))) {
    out[is.na(out)] <- sample(out[!is.na(out)], sum(is.na(out)), replace = TRUE)
  }

  out
}

cat_vars <- c("Ship Mode","Segment","Region","Category","Sub-Category")
cat_vars <- intersect(cat_vars, names(dane))

group_vars <- c("Region","Segment")
group_vars <- intersect(group_vars, names(dane))

set.seed(123)
for (v in cat_vars) {
  dane[[v]] <- hotdeck_grouped(dane[[v]], dane[group_vars])
}


num_vars <- c("Sales","Quantity","Discount","Profit")
num_vars <- intersect(num_vars, names(dane))

num_df <- dane %>% select(all_of(num_vars))

set.seed(123)
imp_num <- mice(
  num_df,
  m = 5,
  method = "pmm",
  maxit = 5,
  printFlag = FALSE
)

num_complete <- complete(imp_num, 1)


dane[num_vars] <- num_complete


if (all(c("Product ID", "Product Name") %in% names(dane))) {
  lookup_prod <- dane %>%
    filter(!is.na(`Product ID`), !is.na(`Product Name`)) %>%
    distinct(`Product ID`, `Product Name`)

  dane <- dane %>%
    left_join(lookup_prod, by = "Product ID", suffix = c("", ".from_id")) %>%
    mutate(`Product Name` = ifelse(is.na(`Product Name`), `Product Name.from_id`, `Product Name`)) %>%
    select(-`Product Name.from_id`)
}


fill_by_key_first <- function(x, key) {

  filled <- ave(x, key, FUN = function(z) {
    if (all(is.na(z))) return(z)
    z[is.na(z)] <- z[which(!is.na(z))[1]]
    z
  })
  filled
}

if ("Postal Code" %in% names(dane)) {
  if ("City" %in% names(dane))  dane$City  <- fill_by_key_first(dane$City,  dane$`Postal Code`)
  if ("State" %in% names(dane)) dane$State <- fill_by_key_first(dane$State, dane$`Postal Code`)
}


if ("City" %in% names(dane) && "State" %in% names(dane)) {
  dane$City <- fill_by_key_first(dane$City, dane$State)
}
if ("State" %in% names(dane) && "Region" %in% names(dane)) {
  dane$State <- fill_by_key_first(dane$State, dane$Region)
}

if (all(c("Order Date","Ship Date","Ship Mode","Region") %in% names(dane))) {
  ship_days <- as.integer(dane$`Ship Date` - dane$`Order Date`)

  grp <- interaction(dane$`Ship Mode`, dane$Region, drop = TRUE)
  med_by_grp <- tapply(ship_days, grp, function(z) median(z, na.rm = TRUE))

  miss_sd <- is.na(dane$`Ship Date`)
  if (any(miss_sd)) {

    global_med <- median(ship_days, na.rm = TRUE)
    fill_days <- med_by_grp[as.character(grp[miss_sd])]
    fill_days[is.na(fill_days)] <- global_med

    dane$`Ship Date`[miss_sd] <- dane$`Order Date`[miss_sd] + as.integer(fill_days)
  }
}

for (nm in names(dane)) {
  if (anyNA(dane[[nm]])) {
    if (is.numeric(dane[[nm]])) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else if (inherits(dane[[nm]], "Date")) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else {

      tab <- table(dane[[nm]])
      moda <- names(tab)[which.max(tab)]
      dane[[nm]][is.na(dane[[nm]])] <- moda
    }
  }
}


stopifnot(sum(is.na(dane)) == 0)

md.pattern(dane)
head(dane)
```

## 2.7. Podsumowanie metod imputacji braków danych

-   **Imputacja danych numerycznych:** Zastosowano zaawansowany algorytm
    MICE (Multivariate Imputation by Chained Equations) z metodą PMM
    (Predictive Mean Matching). Pozwala to na uzupełnienie braków w
    oparciu o korelacje z innymi zmiennymi, co jest bardziej precyzyjne
    niż użycie średniej.

-   **Hot-deck Imputation:** Dla zmiennych kategorycznych (np. Ship
    Mode) użyto metody hot-deck, losując wartości z istniejącego
    rozkładu wewnątrz grup (Region/Segment).

-   Braki w nazwach miast i stanów uzupełniono na podstawie kodów
    pocztowych (Postal Code), wykorzystując relacje przestrzenne w
    danych.

-   Brakujące daty wysyłki wyliczono na podstawie mediany czasu dostawy
    dla danego trybu wysyłki i regionu.

# 3. Wizualicje danych

## 3.1. PYTANIE BADAWCZE 1: Jaki wpływ mają rabaty na zysk?

### Rozkład rabatów w transakcjach

Poniższy histogram prezentuje rozkład wartości rabatów zastosowanych w
transakcjach. Analiza struktury rabatów jest kluczowa dla zrozumienia
polityki cenowej i jej wpływu na rentowność, odpowiadając bezpośrednio
na pytanie badawcze #1: *"Jaki wpływ mają rabaty na zysk – czy większy
rabat zawsze zwiększa sprzedaż kosztem rentowności?"*

Kluczowe obserwacje: - **Dominacja transakcji bez rabatu:** Około 4800
transakcji (ponad 50%) odbyło się bez jakiegokolwiek rabatu (Discount =
0), co wskazuje, że firma posiada baze klientów gotowych płacić pełną
cenę - **Koncentracja na 20% rabacie:** Druga najliczniejsza grupa
(\~3600 transakcji) to rabat 20%, co sugeruje standardową politykę
promocyjną - **Rzadkie rabaty ekstremalne:** Rabaty powyżej 30% są
znacznie rzadsze (\<500 transakcji każdy), co wskazuje na selektywne
stosowanie głębokich przecen - **Bimodalna dystrybucja:** Wyraźne dwa
szczyty (0% i 20%) sugerują dwie odrębne strategie sprzedażowe: sprzedaż
po cenie katalogowej i sprzedaż promocyjna - **Potencjał
optymalizacji:** Niska częstotliwość rabatów pośrednich (5-15%) może
wskazywać na brak elastycznej polityki rabatów, która mogłaby lepiej
reagować na różne segmenty klientów

```{r, echo = FALSE}
# Rozkład rabatów
plot_ly(
  df,
  x = ~Discount,
  type = "histogram",
  nbinsx = 20,
  marker = list(
    color = ~count,
    colorscale = "RdYlGn",
    showscale = TRUE,
    colorbar = list(title = "Count")
  )
) %>%
  layout(
    title = "Distribution of Discount",
    xaxis = list(title = "Discount"),
    yaxis = list(title = "Count")
  )
```

### Macierz korelacji zmiennych kluczowych

Poniższa macierz korelacji prezentuje związki statystyczne między
czterema kluczowymi zmiennymi biznesowymi: Discount (rabat), Quantity
(ilość), Sales (sprzedaż) i Profit (zysk). Wartości w komórkach pokazują
siłę i kierunek korelacji (od -1 do +1), gdzie wartości bliskie -1
oznaczają silną korelację ujemną, wartości bliskie +1 silną korelację
dodatnią, a wartości bliskie 0 brak związku. Gwiazdki (*, **,*** )
oznaczają istotność statystyczną korelacji. Analiza ta jest kluczowa dla
wszystkich pytań badawczych, szczególnie #1: *"Jaki wpływ mają rabaty na
zysk?"*

Kluczowe obserwacje:

\- **Rabat niszczy zysk:** Discount ma silną ujemną korelację z Profit
(-0.22***), co oznacza, że wyższe rabaty są silnie powiązane z niższym
zyskiem – to potwierdza problem z polityką rabatową***

***-** Sprzedaż nie równa się zysk: **Sales ma umiarkowaną pozytywną
korelację z Profit (0.48***), co jest wartością niższą niż można by
oczekiwać – wskazuje to, że sama wysokość sprzedaży nie gwarantuje
proporcjonalnego zysku

\- **Ilość nie kompensuje rabatów:** Quantity ma bardzo słabą korelację
z Profit (0.07\***), co sugeruje, że zwiększenie ilości sprzedanych
produktów nie jest efektywną strategią kompensacji rabatów**

**-** Rabaty nie zwiększają znacząco sprzedaży: **Discount ma słabą
ujemną korelację z Sales (-0.03**), co jest zaskakujące – głębsze rabaty
nie prowadzą do znaczącego wzrostu wartości sprzedaży

\- **Paradoks rabatowy:** Brak silnej pozytywnej korelacji między
rabatem a sprzedażą przy jednoczesnej silnej ujemnej korelacji z zyskiem
sugeruje, że obecna polityka rabatowa jest nieefektywna – firma traci
zysk bez znaczącego zwiększenia przychodów

```{r, echo = FALSE}
# Macierz korelacji
num_df <- df %>%
  select(Discount, Quantity, Sales, Profit) %>%
  mutate(across(everything(), as.numeric)) %>%
  na.omit()

rc <- rcorr(as.matrix(num_df))
R <- rc$r
P <- rc$P
corrplot(
  R,
  type = "lower",
  method = "color",
  addCoef.col = "black",
  number.cex = 0.9,
  tl.col = "black",
  tl.srt = 45
)
n <- ncol(R)

for (i in 2:n) {
  for (j in 1:(i-1)) {
    if (P[i, j] < 0.05) {
      stars <- ifelse(P[i, j] < 0.001, "***",
               ifelse(P[i, j] < 0.01, "**", "*"))

      text(
        x = j,
        y = n - i + 1 + 0.25,  
        labels = stars,
        cex = 1,
        col = "black"
      )
    }
  }
}
```

### Wpływ rabatów na rentowność: analiza wielowymiarowa

Poniższe cztery wizualizacje przedstawiają kompleksową analizę wpływu
rabatów na kluczowe metryki biznesowe: marżę zysku, liczbę zamówień,
udział w całkowitym zysku oraz średnią wartość zakupu. Transakcje
zostały pogrupowane w sześć kategorii według wysokości rabatu, co
pozwala na precyzyjne zidentyfikowanie punktu krytycznego, w którym
rabaty przestają być opłacalne. Analiza ta bezpośrednio odpowiada na
pytanie badawcze #1: *"Jaki wpływ mają rabaty na zysk – czy większy
rabat zawsze zwiększa sprzedaż kosztem rentowności?"*

### Średnia marża zysku według poziomu rabatu

Poniższy wykres słupkowy przedstawia średnią marżę zysku (w procentach)
dla każdej grupy rabatowej. Kolor słupka sygnalizuje rentowność: zielony
oznacza zysk, czerwony stratę. Ta wizualizacja jasno pokazuje punkt
krytyczny, w którym rabaty przekształcają się z narzędzia marketingowego
w źródło strat finansowych.

Kluczowe obserwacje:

\- **Próg opłacalności:** Wyraźna granica rentowności znajduje się
między 11-20% a 21-30% rabatem – pierwsze dwie grupy generują zysk
(33.7% i 17.5% marży), podczas gdy wszystkie kolejne są w strefie
strat - **Dramatyczny spadek:** Marża spada z +17.5% (11-20%) do -11.5%
(21-30%), co oznacza spadek o prawie 30 punktów procentowych przy
zwiększeniu rabatu o zaledwie \~10%, wskazując na nieliniowy wpływ
rabatów

\- **Katastrofa ekstremalnych rabatów:** Grupa rabatów \>50% wykazuje
marżę -114%, co oznacza, że firma traci więcej niż cała wartość
sprzedaży – każda taka transakcja jest dramatycznie nierentowna

\- **Bezpieczna strefa:** Transakcje z rabatem 0-10% mają najbardziej
zdrową marżę 33.7%, co sugeruje, że firma ma solidne podstawy marżowe,
które są niszczone przez agresywną politykę rabatową

```{r, echo = FALSE}
df <- df %>%
  mutate(
    profit_margin = ifelse(Sales > 0, Profit / Sales * 100, NA_real_),
    discount_group = cut(
      Discount * 100,
      breaks = c(0, 10, 20, 30, 40, 50, 100),
      labels = c("0-10%", "11-20%", "21-30%", "31-40%", "41-50%", ">50%"),
      include.lowest = TRUE
    )
  )

discount_analysis <- df %>%
  group_by(discount_group) %>%
  summarise(
    orders = n(),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    avg_sales = mean(Sales, na.rm = TRUE),
    avg_profit = mean(Profit, na.rm = TRUE),
    avg_profit_margin = mean(profit_margin, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(discount_group) & orders > 0) %>%
  mutate(
    sales_share = total_sales / sum(total_sales, na.rm = TRUE) * 100,
    profit_share = total_profit / sum(total_profit, na.rm = TRUE) * 100
  ) %>%
  arrange(discount_group)

x_groups <- levels(df$discount_group)
discount_analysis <- discount_analysis %>%
  mutate(discount_group = factor(discount_group, levels = x_groups, ordered = TRUE)) %>%
  arrange(discount_group)

discount_analysis <- discount_analysis %>%
  mutate(
    bar_color = ifelse(avg_profit_margin >= 0, "darkgreen", "red"),
    label_pm  = paste0(round(avg_profit_margin, 1), "%"),
    hover_txt = paste0(
      "<b>Grupa rabatu:</b> ", discount_group,
      "<br><b>Śr. marża:</b> ", sprintf("%.2f", avg_profit_margin), "%",
      "<br><b>Zamówienia:</b> ", orders,
      "<br><b>Śr. rabat:</b> ", sprintf("%.1f", avg_discount), "%",
      "<br><b>Śr. sprzedaż:</b> ", sprintf("%.2f", avg_sales), "$",
      "<br><b>Śr. zysk:</b> ", sprintf("%.2f", avg_profit), "$"
    )
  )

plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~avg_profit_margin,
  type = "bar",
  marker = list(color = ~bar_color),
  text = ~label_pm,
  textposition = "outside",
  cliponaxis = FALSE,
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Średnia marża wg rabatu",
    xaxis = list(title = "Grupa rabatu", tickangle = -30),
    yaxis = list(title = "Marża (%)", zeroline = TRUE, zerolinewidth = 2),
    margin = list(l = 70, r = 30, t = 60, b = 80),
    bargap = 0.25
  )
```

### Liczba zamówień według poziomu rabatu

Poniższy wykres liniowy pokazuje rozkład liczby zamówień w
poszczególnych grupach rabatowych. Kształt krzywej ujawnia faktyczną
strategię rabatową firmy i pozwala ocenić, czy rabaty są stosowane
strategicznie czy chaotycznie.

Kluczowe obserwacje:

\- **Dominacja niskich rabatów:** Grupy 0-10% (\~4900 zamówień) i 11-20%
(\~3700 zamówień) stanowią łącznie około 86% wszystkich transakcji, co
jest pozytywnym sygnałem - większość klientów kupuje przy niskiej lub
zerowej obniżce

\- **Przepaść po 20%:** Dramatyczny spadek do \~250 zamówień w grupach
21-30% i 31-40% wskazuje, że firma rzadko stosuje średnie rabaty - to
sugeruje brak elastycznej polityki cenowej i negocjacji

\- **Anomalia ekstremalnych rabatów:** Niespodziewany wzrost do \~900
zamówień w grupie \>50% jest niepokojący - tak głębokie rabaty (które
generują -114% marży) nie powinny występować tak często, chyba że są to
akcje likwidacji zapasów

\- **Strategia binarna:** Rozkład pokazuje podejście "wszystko albo
nic" - albo pełna/prawie pełna cena (\~4900), albo standardowa promocja
20% (\~3700), albo ekstremalna wyprzedaż (\~900), bez płynnych przejść

\- **Problem kontroli:** Fakt, że 900 transakcji odbyło się z rabatami
\>50% (każda generująca ogromną stratę) wskazuje na brak procedur
autoryzacji głębokich rabatów lub celowe akcje, które wymagają
szczegółowej analizy uzasadnienia biznesowego

Ten wykres raczej można wyrzucic bo nie wnosi nic nowego do analizy

```{r, echo = FALSE}
plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~orders,
  type = "scatter",
  mode = "lines+markers",
  line = list(width = 2),
  hovertemplate = paste(
    "<b>Grupa rabatu:</b> %{x}<br>",
    "<b>Liczba zamówień:</b> %{y}<br>",
    "<b>Śr. rabat:</b> %{customdata:.1f}%<extra></extra>"
  ),
  customdata = ~avg_discount
) %>%
  layout(
    title = "Rabat vs zamówienia",
    xaxis = list(title = "Grupa rabatu"),
    yaxis = list(title = "Liczba zamówień")
  )
```

### Udział w całkowitym zysku według poziomu rabatu

Poniższy wykres liniowy przedstawia średnią wartość transakcji (w
dolarach) dla każdej grupy rabatowej. Szara linia przerywana oznacza
średnią globalną (\~\$230). Ta wizualizacja odpowiada na kluczowe
pytanie: czy głębsze rabaty rzeczywiście zwiększają wartość koszyka
zakupowego, jak zakładają klasyczne teorie rabatowe?

Kluczowe obserwacje:

\- **Paradoks niskich rabatów:** Grupy 0-10% i 11-20% mają wartości
zakupu (\$230 i \$220) blisko średniej globalnej, co jest
nieoczekiwane - brak rabatu nie zniechęca klientów do kupowania
produktów o standardowej wartości

\- **Wzrost dla średnich rabatów:** Grupy 21-30% (\$460), 31-40% (\$565)
i 41-50% (\$850) pokazują wyraźny wzrost wartości zakupu wraz z rabatem,
co sugeruje, że głębsze rabaty są stosowane przy droższych produktach
lub większych zamówieniach

\- **Dramatyczny spadek przy \>50%:** Grupa ekstremalnych rabatów ma
NAJNIŻSZĄ średnią wartość zakupu (\~\$75), co jest 3x niższe niż
średnia - to wskazuje, że \>50% rabatów są stosowane głównie przy tanich
produktach lub produktach trudnych do sprzedaży

\- **Brak strategii "większy zakup = większy rabat":** Fakt, że
najwyższe rabaty (\>50%) idą w parze z najniższymi wartościami koszyka
(\~\$75) jest całkowicie odwrotny do zdrowej strategii rabatowej, gdzie
głębokie rabaty powinny nagradzać duże zamówienia

\- **Niszczenie wartości przy niskiej sprzedaży:** Kombinacja -114%
marży (z pierwszego wykresu) i \$75 średniej sprzedaży w grupie \>50%
oznacza, że firma daje ogromne rabaty na produkty o niskiej wartości, co
jest podwójnie destrukcyjne - niska wartość transakcji + ogromna strata
na każdej transakcji

```{r, echo = FALSE}
global_mean_sales <- mean(df$Sales, na.rm = TRUE)

plot_ly(
  data = discount_analysis,
  x = ~discount_group,
  y = ~avg_sales,
  type = "scatter",
  mode = "lines+markers",
  line = list(width = 2),
  hovertemplate = paste(
    "<b>Grupa rabatu:</b> %{x}<br>",
    "<b>Śr. wartość zakupu:</b> %{y:.2f}$<br>",
    "<b>Śr. rabat:</b> %{customdata:.1f}%<extra></extra>"
  ),
  customdata = ~avg_discount
) %>%
  layout(
    title = "Rabat vs średnia wartość zakupu",
    xaxis = list(title = "Grupa rabatu"),
    yaxis = list(title = "Śr. wartość zakupu ($)"), 
    shapes = list(
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = global_mean_sales, y1 = global_mean_sales,
        line = list(color = "gray", width = 2, dash = "dash")
      )
    ),
    annotations = list(
      list(
        xref = "paper", x = 0.5, y = global_mean_sales,
        text = paste0("Średnia globalna: $", round(global_mean_sales, 2)),
        showarrow = FALSE, yshift = -12, font = list(color = "gray")
      )
    )
  )
```

### Wpływ rabatów na marże według regionów
Kluczowe obserwacje:
- **Strata na każdej sztuce:** Region Centralny (rabat 24%) = marża ujemna (-10%). Agresywne cięcie cen prowadzi do sprzedaży poniżej granicy opłacalności. Rabat nie przyciąga wystarczającej liczby klientów, by zrekompensować utraconą marżę.
- **Strefa bezpiecznego rabatu:** Regiony East i South (rabat ~14–15%) = marża 16–17%.Umiarkowane rabaty utrzymują konkurencyjność bez rujnowania rentowności. To optymalny przedział dla zachowania zdrowego balansu między zachętą a zyskiem.
- **Optimum niskiego rabatu:** Region West (rabat 11%) = marża 22%
Najmniejsze rabaty przekładają się na najwyższą marżę i największy łączny zysk. Klienci w tym regionie są lojalni wobec marki, a nie ceny.
- **Mit „więcej rabatu = więcej klientów”:** Centralny ma wysoki rabat, ale niski wolumen sprzedaży. Mimo najwyższych opustów liczba zamówień jest tam niższa niż w regionach z niższymi rabatami. To dowód, że głębokie promocje przyciągają niewłaściwy segment lub nie budują lojalności.
- **Rabat bez wzrostu wolumenu = podwójna strata:** Centralny łączy niską średnią sprzedaż z ujemną marżą.Firma traci na każdej transakcji, a jednocześnie nie osiąga wzrostu wartości koszyka ani liczby zamówień. To najgorszy możliwy scenariusz cenowy.

```{r echo=FALSE}

# 1. Przygotowanie danych
rabaty_region <- df %>%
  group_by(Region) %>%
  summarise(
    średni_rabat = mean(Discount, na.rm = TRUE) * 100,
    średnia_sprzedaż = mean(Sales, na.rm = TRUE),
    średni_zysk = mean(Profit, na.rm = TRUE),
    marża_zysku = mean(Profit / Sales * 100, na.rm = TRUE),
    liczba_zamówień = n(),
    łączna_sprzedaż = sum(Sales, na.rm = TRUE) / 1000,
    łączny_zysk = sum(Profit, na.rm = TRUE) / 1000,
    .groups = "drop"
  ) %>%
  arrange(desc(średni_rabat))

# 2. Tworzenie wykresu
p_rabaty_region <- plot_ly(
  data = rabaty_region,
  x = ~średni_rabat,
  y = ~marża_zysku,
  type = "scatter",
  mode = "markers+text",
  text = ~Region,
  textposition = "top center",
  marker = list(
    size = ~sqrt(liczba_zamówień/50) * 15,
    color = ~średni_rabat,
    colorscale = "RdYlBu",
    reversescale = TRUE,
    showscale = TRUE,
    colorbar = list(title = "Śr. rabat (%)"),
    line = list(color = "white", width = 2)
  ),
  hovertemplate = paste(
    "<b>%{text}</b><br>",
    "Śr. rabat: %{x:.1f}%<br>",
    "Marża: %{y:.1f}%<br>",
    "Śr. sprzedaż: $%{customdata[0]:.2f}<br>", # poprawiony indeks customdata
    "Zamówienia: %{customdata[1]:,}<extra></extra>"
  ),
  customdata = ~cbind(średnia_sprzedaż, liczba_zamówień) # cbind jest bezpieczniejszy dla plotly
) %>%
  layout(
    title = list(
      text = "<b>NISZCZĄCY WPŁYW RABATÓW</b>",
      x = 0.05
    ),
    xaxis = list(title = "Średni rabat (%)"),
    yaxis = list(title = "Marża zysku (%)"),
    shapes = list(
      list(
        type = "line",
        x0 = 0, x1 = max(rabaty_region$średni_rabat) * 1.1,
        y0 = mean(rabaty_region$marża_zysku),
        y1 = mean(rabaty_region$marża_zysku),
        line = list(color = "gray", width = 2, dash = "dash")
      )
    )
  ) # Tutaj było najwięcej błędów w nawiasach

# 3. Wyświetlenie wykresu
p_rabaty_region
```

## 3.2. PYTANIE BADAWCZE 2: Które kategorie i podkategorie produktów generują najwyższą sprzedaż, a które najwyższy zysk?

### Analiza rentowności kategorii: wykres bąbelkowy

Poniższy wykres bąbelkowy przedstawia trzywymiarową analizę kategorii
produktów, gdzie oś X reprezentuje liczbę zamówień, oś Y średni zysk na
transakcję, a rozmiar bąbelka odpowiada łącznej sumie sprzedaży. Ta
wielowymiarowa wizualizacja pozwala jednocześnie ocenić wolumen
sprzedaży, rentowność oraz skalę przychodów każdej kategorii. Analiza
bezpośrednio odpowiada na pytanie badawcze #2: *"Które kategorie
produktów generują najwyższą sprzedaż, a które najwyższy zysk?"*

Kluczowe obserwacje:

\- **Technology - gwiazdor portfela:** Kategoria Technology (największy
niebieski bąbelek) dominuje we wszystkich trzech wymiarach - ma
najwyższą liczbę zamówień (\~6000), najwyższy średni zysk (\~\$80) i
największą sumę sprzedaży, co czyni ją najbardziej wartościową kategorią
w portfolio

\- **Office Supplies - masa krytyczna:** Artykuły biurowe (średni
pomarańczowy bąbelek) mają umiarkowaną liczbę zamówień (\~5500), ale
niski średni zysk (\~\$20), co wskazuje na problem z marżami pomimo
znaczącego wolumenu sprzedaży

\- **Furniture - problem rentowności:** Meble (mały zielony bąbelek)
mają najmniejszą liczbę zamówień (\~2000) i najniższy średni zysk
(\~\$8), co sugeruje, że ta kategoria jest najmniej efektywna zarówno
pod względem wolumenu jak i rentowności

\- **Paradoks skali:** Mimo że Office Supplies ma prawie tyle samo
zamówień co Technology, jej średni zysk jest 4x niższy, co wskazuje na
znaczące różnice w marżowości między kategoriami

\- **Strategia różnicowania:** Wyraźne rozdzielenie kategorii na
wykresie sugeruje potrzebę różnych strategii dla każdej z nich:
maksymalizacja skali dla Technology, poprawa marż dla Office Supplies, i
reewaluacja oferty dla Furniture

```{r echo=FALSE}
category_stats <- dane %>%
  group_by(Category) %>%
  summarise(
    liczba_zamówień = n(),
    średni_zysk = mean(Profit, na.rm = TRUE),
    suma_sprzedaży = sum(Sales, na.rm = TRUE),
    .groups = "drop"
  )
plot_ly(
  data = category_stats,
  x = ~liczba_zamówień,
  y = ~średni_zysk,
  size = ~suma_sprzedaży,
  color = ~Category,

  sizes = c(30, 80), 
  type = 'scatter',
  mode = 'markers+text',
  text = ~Category,
  textposition = "top center",

  textfont = list(size = 14, color = 'black'),
  
  marker = list(
    opacity = 0.6,
    line = list(width = 0),
    sizemode = 'diameter'
  )
) %>%
  layout(
    xaxis = list(title = "Liczba zamówień", range = c(1500, 6500)),
    yaxis = list(title = "Średni zysk ($)", range = c(-5, 100)), 
    
    template = "plotly_white",
    showlegend = TRUE
  )
```

### Top 5 podkategorii: sprzedaż vs rentowność

Poniższe dwa wykresy słupkowe przedstawiają top 5 podkategorii produktów
pod względem sprzedaży (lewy panel) oraz top 5 podkategorii według zysku
(prawy panel). To zestawienie ujawnia kluczową różnicę między wielkością
sprzedaży a faktyczną rentownością - produkty generujące najwyższe
przychody nie zawsze są najbardziej opłacalne. Analiza odpowiada na
pytanie badawcze #2: *"Które kategorie i podkategorie produktów generują
najwyższą sprzedaż, a które najwyższy zysk?"*

Kluczowe obserwacje: - **Phones - podwójny lider:** Telefony pojawiają
się w obu top 5 (2. miejsce w sprzedaży, 2. w zysku), co czyni je
najbardziej zrównoważoną podkategorią - wysoka sprzedaż przekłada się na
wysoki zysk, co wskazuje na dobrą marżowość - **Chairs - wysoka
sprzedaż, brak rentowności:** Krzesła są liderem sprzedaży (\~\$330k),
ale nie pojawiają się w top 5 zysków, co sugeruje bardzo niską marżę lub
nawet straty na tej podkategorii pomimo ogromnego wolumenu - to czerwona
flaga wymagająca analizy kosztów i rabatów - **Copiers - król
rentowności:** Kopiarki generują najwyższy zysk (\~\$55k) mimo że nie są
w top 5 sprzedaży, co wskazuje na wyjątkowo wysoką marżę - to
strategiczna podkategoria, która zasługuje na większy nacisk
sprzedażowy - **Binders - paradoks marży:** Segregatory są zarówno w top
5 sprzedaży (5. miejsce \~\$200k) jak i top 5 zysku (5. miejsce
\~\$30k), ale stosunek zysku do sprzedaży jest niski (\~15%), co
wskazuje na produkt o wysokim wolumeniu ale niskiej marży - **Różne
strategie produktowe:** Fakt, że tylko 2 z 5 top produktów sprzedażowych
pojawiają się w top 5 zysków (Phones i Binders) oznacza, że firma
sprzedaje głównie produkty o niskiej marży, podczas gdy najbardziej
rentowne produkty (Copiers, Accessories, Paper) mają słabszą penetrację
sprzedażową - potrzebna jest reorganizacja portfolio produktowego z
naciskiem na cross-selling rentownych produktów

```{r echo=FALSE, warning=FALSE, message=FALSE}
wrap_labels <- function(x, width = 12) stringr::str_wrap(x, width = width)


subcategory_analysis <- df %>%
  group_by(Category, `Sub-Category`) %>%
  summarise(
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    avg_profit_margin = mean(Profit / Sales * 100, na.rm = TRUE),
    orders = n(),
    .groups = "drop"
  ) %>%
  filter(total_sales > 0)


top_sales_subcat <- subcategory_analysis %>%
  arrange(desc(total_sales)) %>%
  head(5) %>%
  mutate(
    sales_k = total_sales / 1000,
    hover_txt = paste0(
      "<b>Kategoria:</b> ", Category,
      "<br><b>Podkategoria:</b> ", `Sub-Category`,
      "<br><b>Sprzedaż:</b> ", round(total_sales, 0), "$",
      "<br><b>Zysk:</b> ", round(total_profit, 0), "$",
      "<br><b>Marża:</b> ", round(avg_profit_margin, 2), "%",
      "<br><b>Zamówienia:</b> ", orders
    )
  )

p_sales <- plot_ly(
  data = top_sales_subcat,
  x = ~`Sub-Category`,
  y = ~sales_k,
  type = "bar",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    xaxis = list(
      title = "",
      tickvals = top_sales_subcat$`Sub-Category`,
      ticktext = wrap_labels(top_sales_subcat$`Sub-Category`, 12)
    ),
    yaxis = list(title = "Sprzedaż (tys. $)"),
    bargap = 0.25
  )


top_profit_subcat <- subcategory_analysis %>%
  arrange(desc(total_profit)) %>%
  head(5) %>%
  mutate(
    profit_k = total_profit / 1000,
    bar_color = ifelse(total_profit < 0, "red", "darkgreen"),
    hover_txt = paste0(
      "<b>Kategoria:</b> ", Category,
      "<br><b>Podkategoria:</b> ", `Sub-Category`,
      "<br><b>Zysk:</b> ", round(total_profit, 0), "$",
      "<br><b>Sprzedaż:</b> ", round(total_sales, 0), "$",
      "<br><b>Marża:</b> ", round(avg_profit_margin, 2), "%",
      "<br><b>Zamówienia:</b> ", orders
    )
  )

p_profit <- plot_ly(
  data = top_profit_subcat,
  x = ~`Sub-Category`,
  y = ~profit_k,
  type = "bar",
  marker = list(color = ~bar_color),
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    xaxis = list(
      title = "",
      tickvals = top_profit_subcat$`Sub-Category`,
      ticktext = wrap_labels(top_profit_subcat$`Sub-Category`, 12)
    ),
    yaxis = list(
      title = "Zysk (tys. $)",
      zeroline = TRUE,
      zerolinewidth = 2
    ),
    bargap = 0.25
  )


p <- plotly::subplot(p_sales, p_profit, shareX = FALSE, titleX = TRUE) %>%
  layout(
    title = list(text = "Top 5 podkategorii – porównanie", x = 0.5),
    showlegend = FALSE,


annotations = list(
  list(
    x = 0.22, y = 1.02, xref = "paper", yref = "paper",
    text = "<b>Sprzedaż</b>",
    showarrow = FALSE,
    font = list(size = 13, color = "#333333")
  ),
  list(
    x = 0.78, y = 1.02, xref = "paper", yref = "paper",
    text = "<b>Zysk</b>",
    showarrow = FALSE,
    font = list(size = 13, color = "#333333")
  )
),


    margin = list(l = 70, r = 30, t = 110, b = 120)
  )


p <- config(p, displayModeBar = FALSE)

p
```

## 3.3. PYTANIE BADAWCZE 3: Czy istnieją regiony o wysokiej sprzedaży, ale niskiej rentowności?

### Top 10 stanów według zysku

Poniższy wykres przedstawia dziesięć stanów USA generujących najwyższy
łączny zysk w analizowanym okresie. Analiza geograficzna rentowności
jest kluczowa dla odpowiedzi na pytanie badawcze #3: *"Czy istnieją
regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej) rentowności?"*
oraz umożliwia identyfikację najważniejszych rynków dla firmy.

Kluczowe obserwacje:

\- **Dominacja Kalifornii i Nowego Jorku:** Dwa stany generują łącznie
\~150k\$ zysku, co stanowi znaczną część całkowitego zysku firmy,
wskazując na kluczowe znaczenie rynków wschodniego i zachodniego
wybrzeża

\- **Koncentracja geograficzna:** Większość najbardziej rentownych
stanów to duże centra metropolitalne (Kalifornia, Nowy Jork, Waszyngton,
Michigan), co sugeruje korelację między urbanizacją a rentownością

\- **Duże różnice wewnętrzne:** Różnica między najlepszym stanem
(\~78k$) a dziesiątym (~10k$) jest prawie ośmiokrotna, co wskazuje na
bardzo nierównomierny rozkład zysków geograficznych

\- **Obecność stanów południowych:** Indiana, Virginia i Georgia
reprezentują region południowy, pokazując jego rosnące znaczenie
ekonomiczne

\- **Potencjał konsolidacji:** Silna koncentracja zysków w kilku stanach
może sugerować możliwość optymalizacji operacji poprzez skupienie
zasobów na najbardziej rentownych rynkach

```{r, echo = FALSE}
# Top 10 stanów według zysku
top_states <- df %>%
  group_by(State) %>%
  summarise(Profit = sum(Profit, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(Profit)) %>%
  slice_head(n = 10)

plot_ly(
  top_states,
  x = ~reorder(State, Profit),
  y = ~Profit,
  type = "bar"
) %>%
  layout(
    title = "Top 10 States by Profit",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Profit")
  )
```

### Analiza regionalna: sprzedaż vs rentowność

Poniższe dwa wykresy przedstawiają kompleksową analizę rentowności
czterech regionów geograficznych USA. Pierwszy wykres (scatter plot)
pokazuje relację między wielkością sprzedaży a marżą zyskowności, gdzie
rozmiar bąbelka reprezentuje wartość bezwzględną zysku. Drugi wykres
(słupkowy) prezentuje bezpośrednie porównanie marży w poszczególnych
regionach. Analiza odpowiada na pytanie badawcze #3: *"Czy istnieją
regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej) rentowności?"*

```{r, echo = FALSE}
# 1. ANALIZA REGIONÓW - PRZYGOTOWANIE DANYCH
region_summary <- df %>%
  group_by(Region) %>%
  summarise(
    sprzedaż = sum(Sales, na.rm = TRUE) / 1000,
    zysk = sum(Profit, na.rm = TRUE) / 1000,
    marża = mean(Profit / Sales * 100, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(!is.na(marża)) %>%
  mutate(
    kolor = ifelse(marża >= 15, "darkgreen",
                   ifelse(marża >= 10, "orange", "red")),
    hover_txt = paste0(
      "<b>Region:</b> ", Region,
      "<br><b>Sprzedaż:</b> ", round(sprzedaż, 1), " tys. $",
      "<br><b>Zysk:</b> ", round(zysk, 1), " tys. $",
      "<br><b>Marża:</b> ", round(marża, 2), "%"
    )
  )

# 2. TWORZENIE WYKRESÓW
library(plotly)
library(htmltools)

# Wykres A: Sprzedaż vs Marża (Bąbelkowy)
p_region_scatter <- plot_ly(
  data = region_summary,
  x = ~sprzedaż,
  y = ~marża,
  type = "scatter",
  mode = "markers+text",
  marker = list(
    size = ~abs(zysk) * 2, # Wielkość bąbelka zależy od zysku
    color = ~kolor,
    line = list(color = "white", width = 2),
    opacity = 0.7
  ),
  text = ~Region,
  textposition = "top center",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Regiony: Sprzedaż vs Marża",
    xaxis = list(title = "Sprzedaż (tys. $)"),
    yaxis = list(title = "Marża (%)"),
    margin = list(t = 50)
  )

# Wykres B: Marża wg Regionu (Słupkowy)
p_region_bar <- plot_ly(
  data = region_summary,
  x = ~Region,
  y = ~marża,
  type = "bar",
  marker = list(color = ~kolor),
  text = ~paste0(round(marża, 1), "%"),
  textposition = "outside",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Porównanie Marży wg Regionu",
    xaxis = list(title = ""),
    yaxis = list(title = "Marża (%)"),
    margin = list(t = 50)
  )

# 3. WYŚWIETLENIE WYKRESÓW
# Używamy tagList, aby R Markdown wyrenderował oba obiekty Plotly
htmltools::tagList(list(p_region_scatter, p_region_bar))
```


### Regiony: relacja sprzedaży i marży

Poniższy wykres typu scatter (punktowy z bąbelkami) prezentuje
jednoczesną wizualizację trzech wymiarów: wielkości sprzedaży (oś X),
marży zysku (oś Y) oraz wartości bezwzględnej zysku (rozmiar bąbelka).
Kolor bąbelka sygnalizuje stan rentowności: zielony (marża ≥15%),
pomarańczowy (marża 10-15%), czerwony (marża \<10%).

Kluczowe obserwacje:

\- **East - lider pod każdym względem:** Region East ma najwyższą
sprzedaż (\~\$680k), najwyższy zysk (największy bąbelek) i bardzo dobrą
marżę (\~17%), co czyni go gwiazdą portfolio - wszystkie metryki są
optymalne

\- **West - wysoka skala, niska marża:** Region West generuje drugą co
do wielkości sprzedaż (\~\$720k) ale ma znacznie niższą marżę (\~22%)
niż East, mimo największego bąbelka (największy zysk w wartościach
bezwzględnych) - to pokazuje, że skala kompensuje słabszą efektywność

\- **Central - katastrofa biznesowa:** Region Central (czerwony bąbelek)
ma UJEMNĄ marżę (\~-10%), co oznacza, że każdy dolar sprzedaży generuje
stratę - mimo sprzedaży \~\$500k, firma traci pieniądze w tym regionie,
co wymaga natychmiastowej interwencji

\- **South - pułapka niskiej marży:** Region South ma niską sprzedaż
(\~\$390k) i marginalną marżę (\~16%), co plasuje go w strefie
pomarańczowej - to region bez wyraźnego profilu strategicznego

\- **Paradoks wielkości:** Wykres jasno pokazuje, że wielkość sprzedaży
NIE gwarantuje rentowności - West ma większą sprzedaż niż East ale
niższą marżę, a Central mimo znaczącej sprzedaży (\~\$500k) generuje
wyłącznie straty

```{r, echo = FALSE}
plot_ly(
  data = region_summary,
  x = ~sprzedaż,
  y = ~marża,
  type = "scatter",
  mode = "markers+text",
  marker = list(
    size = ~abs(zysk) * 2,
    color = ~kolor,
    line = list(color = "white", width = 2),
    opacity = 0.7
  ),
  text = ~Region,
  textposition = "top center",
  textfont = list(size = 12, color = "black"),
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Regiony: Sprzedaż vs Marża",
    xaxis = list(title = "Sprzedaż (tys. $)"),
    yaxis = list(title = "Marża (%)"),
    showlegend = FALSE
  )
```

### Porównanie marży według regionów

Poniższy wykres słupkowy przedstawia bezpośrednie porównanie marży zysku
w czterech regionach. Dwie linie przerywane oznaczają progi: zielona
(15% - marża bardzo dobra), pomarańczowa (10% - marża akceptowalna).
Kolory słupków odpowiadają tym samym kryteriom co na poprzednim
wykresie.

Kluczowe obserwacje: - **West - niespodzianka lidera:** Region West ma
najwyższą marżę (22%), mimo że na poprzednim wykresie wydawał się mniej
efektywny niż East - to pokazuje, że wysoka sprzedaż West rzeczywiście
przekłada się na bardzo dobrą rentowność procentową - **East i South -
powyżej progu:** Regiony East (16.7%) i South (16.3%) są powyżej
zielonej linii (15%), co oznacza bardzo dobrą rentowność - to stabilne,
zdrowe regiony - **Central - dramatyczna strata:** Region Central
(-10.4%) jest jedynym czerwonym słupkiem, znajdującym się głęboko
poniżej zera - to nie tylko brak zysku, ale aktywna destrukcja wartości
firmy - **Dysproporcja 3:1:** Trzy regiony mają marżę 16-22%, podczas
gdy jeden ma -10% - to wskazuje, że problem nie jest systemowy ale
specyficzny dla Central i prawdopodobnie ma konkretne przyczyny do
zidentyfikowania - **Priorytet strategiczny:** Fakt, że Central stanowi
\~20% sprzedaży firmy (z poprzedniego wykresu \~\$500k z \~\$2500k
total) ale generuje same straty oznacza, że eliminacja problemów w tym
regionie może zwiększyć całkowity zysk firmy o dziesiątki procent - to
najważniejszy priorytet operacyjny

```{r, echo = FALSE}
plot_ly(
  data = region_summary,
  x = ~Region,
  y = ~marża,
  type = "bar",
  marker = list(color = ~kolor),
  text = ~paste0(round(marża, 1), "%"),
  textposition = "outside",
  hovertext = ~hover_txt,
  hoverinfo = "text"
) %>%
  layout(
    title = "Marża wg regionu",
    xaxis = list(title = ""),
    yaxis = list(title = "Marża (%)"),
    shapes = list(
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = 15, y1 = 15,
        line = list(color = "green", width = 2, dash = "dash")
      ),
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = 10, y1 = 10,
        line = list(color = "orange", width = 2, dash = "dash")
      )
    ),
    showlegend = FALSE
  )
```

## 3.4. PYTANIE BADAWCZE 4: Jak zmieniały się sprzedaż i zysk w czasie – czy występuje sezonowość?

### Sprzedaż w czasie według kategorii produktów

Poniższy wykres obszarowy (stacked area chart) prezentuje dynamikę
sprzedaży w podziale na kategorie produktów na przestrzeni całego
analizowanego okresu (2014-2017). Format stackowany pozwala jednocześnie
obserwować zarówno całkowitą sprzedaż (wysokość całego stosu), jak i
udział poszczególnych kategorii w każdym okresie. Analiza ta uzupełnia
odpowiedź na pytanie badawcze #4: *"Jak zmieniały się sprzedaż i zysk w
czasie – czy występuje sezonowość?"*

Kluczowe obserwacje:

\- **Wyraźna sezonowość:** Widoczne są regularne peaki sprzedaży w
czwartym kwartale każdego roku (listopad-grudzień), prawdopodobnie
związane z sezonem zakupów świątecznych i promocjami Black Friday/Cyber
Monday

\- **Proporcje kategorii stabilne:** Pomimo zmian w całkowitej
sprzedaży, proporcje między kategoriami pozostają względnie stałe w
czasie – Technology dominuje w każdym okresie

\- **Wzrost całkowitej sprzedaży:** Trend wzrostowy jest widoczny
szczególnie w latach 2016-2017, gdzie peaki sezonowe osiągają wyższe
wartości niż w latach poprzednich

\- **Spadki po sezonie:** Regularne spadki sprzedaży na początku każdego
roku (styczeń-luty) wskazują na cykliczny charakter biznesu i możliwość
lepszego planowania zapasów i kampanii marketingowych

\- **Technology motor wzrostu:** Kategoria Technology nie tylko ma
największy udział, ale również wykazuje najsilniejszy wzrost w okresach
szczytowych, co potwierdza jej kluczową rolę w strategii firmy

```{r, echo = FALSE}
# Sprzedaż w czasie według Kategorii (wykres obszarowy)
area <- df %>%
  filter(!is.na(`Order Date`), !is.na(Category), !is.na(Sales)) %>%
  mutate(month = floor_date(`Order Date`, "month")) %>%
  group_by(month, Category) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

plot_ly(
  area,
  x = ~month,
  y = ~Sales,
  color = ~Category,
  type = "scatter",
  mode = "none",
  stackgroup = "one",
  hovertemplate = paste(
    "<b>Data:</b> %{x|%Y-%m}<br>",
    "<b>Kategoria:</b> %{fullData.name}<br>",
    "<b>Sprzedaż:</b> $%{y:,.0f}<extra></extra>"
  )
) %>%
  layout(
    title = "Sales over time by Category",
    yaxis = list(title = "Sales"),
    hovermode = "x unified"
  )
```

### Wydajność dni tygodnia: analiza wielowymiarowa

Poniższa mapa cieplna (heatmap) przedstawia znormalizowaną wydajność
poszczególnych dni tygodnia w trzech kluczowych metrykach biznesowych:
liczbie zamówień, średniej wartości zamówienia oraz średnim zysku.
Zastosowanie normalizacji (skala 0-1) i gradientu kolorystycznego (żółty
= najniższa wartość w danej metryce, czerwony = najwyższa) pozwala na
szybką identyfikację najlepszych i najgorszych dni dla różnych
wskaźników. Analiza ta jest kluczowa dla optymalizacji operacji i
kampanii marketingowych.

Kluczowe obserwacje:

\- **Paradoks środy:** Środa ma NAJNIŻSZĄ liczbę zamówień (371 - żółta
komórka), ale jednocześnie NAJWYŻSZY średni zysk (\$40 - czerwona
komórka), co wskazuje na znacznie wyższą jakość/rentowność transakcji w
tym dniu pomimo niskiego wolumenu

\- **Poniedziałek - król wolumenu:** Poniedziałek generuje najwyższą
liczbę zamówień (1871 - czerwona komórka), ale ma relatywnie niski
średni zysk (\$28), co sugeruje, że dni o wysokim wolumenie nie
przekładają się automatycznie na wysoką rentowność

\- **Wtorek - najwyższa wartość koszyka:** Wtorek wyróżnia się najwyższą
średnią wartością zamówienia (\$260 - czerwona komórka) i dobrym średnim
zyskiem (\$32), co czyni go jednym z najbardziej wartościowych dni

\- **Sobota - najsłabszy dzień:** Sobota ma najniższą średnią wartość
zamówienia (\$216) i najniższy średni zysk (\$25 - żółte komórki), co
wskazuje na ten dzień jako priorytet do optymalizacji lub specjalnych
kampanii

\- **Optymalny mix:** Idealne dni to wtorek i niedziela - łączą
umiarkowanie wysoką liczbę zamówień z wysoką wartością koszyka i dobrym
zyskiem, podczas gdy środa oferuje najwyższą rentowność przy niskim
wolumenie (potencjał premium/B2B)

```{r echo=FALSE}
df$shipping_days <- as.numeric(df$`Ship Date` - df$`Order Date`)
polish_days <- c("poniedziałek", "wtorek", "środa", "czwartek", "piątek", "sobota", "niedziela")
df$weekday <- factor(weekdays(df$`Order Date`), levels = polish_days, ordered = TRUE)


weekday_stats <- df %>%
  group_by(weekday) %>%
  summarise(
    liczba_zamówień = n(),
    średnia_wartość_zamówienia = mean(Sales, na.rm = TRUE),
    średni_zysk = mean(Profit, na.rm = TRUE),
    średni_czas_dostawy = mean(shipping_days, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(weekday)


weekday_long <- weekday_stats %>%
  pivot_longer(
    cols = c(liczba_zamówień, średnia_wartość_zamówienia, średni_zysk),
    names_to = "metric",
    values_to = "value_raw"
  ) %>%
  mutate(
    metric = case_when(
      metric == "liczba_zamówień" ~ "Liczba zamówień",
      metric == "średnia_wartość_zamówienia" ~ "Śr. wartość zamówienia ($)",
      metric == "średni_zysk" ~ "Śr. zysk ($)",
      TRUE ~ metric
    ),
    label = ifelse(metric == "Liczba zamówień",
                   as.character(round(value_raw, 0)),
                   paste0("$", round(value_raw, 0)))
  ) %>%
  group_by(metric) %>%
  mutate(
    value_scaled = {
      mn <- min(value_raw, na.rm = TRUE)
      mx <- max(value_raw, na.rm = TRUE)
      if (isTRUE(all.equal(mx, mn))) rep(0.5, n()) else (value_raw - mn) / (mx - mn)
    }
  ) %>%
  ungroup()


x_days <- levels(df$weekday)
y_metrics <- c("Śr. zysk ($)", "Śr. wartość zamówienia ($)", "Liczba zamówień")

weekday_long <- weekday_long %>%
  mutate(
    weekday = factor(weekday, levels = x_days, ordered = TRUE),
    metric  = factor(metric, levels = y_metrics, ordered = TRUE)
  ) %>%
  arrange(metric, weekday)


z <- matrix(NA_real_, nrow = length(y_metrics), ncol = length(x_days),
            dimnames = list(y_metrics, x_days))
text_mat <- matrix("", nrow = length(y_metrics), ncol = length(x_days),
                   dimnames = list(y_metrics, x_days))
raw_mat <- matrix(NA_real_, nrow = length(y_metrics), ncol = length(x_days),
                  dimnames = list(y_metrics, x_days))

for (m in y_metrics) {
  for (d in x_days) {
    tmp <- weekday_long %>% filter(metric == m, weekday == d)
    z[m, d] <- tmp$value_scaled[1]
    text_mat[m, d] <- tmp$label[1]
    raw_mat[m, d] <- tmp$value_raw[1]
  }
}


rdylgn <- list(
  list(0.00, "#ffffbf"),
  list(1.00, "#d73027")
)

plot_ly(
  x = x_days,
  y = y_metrics,
  z = z,
  type = "heatmap",
  zmin = 0, zmax = 1,
  colorscale = rdylgn,
  text = text_mat,
  texttemplate = "%{text}",
  textfont = list(color = "black"),
  customdata = raw_mat,
  hovertemplate = paste(
    "<b>Dzień:</b> %{x}<br>",
    "<b>Metryka:</b> %{y}<br>",
    "<b>Wartość:</b> %{customdata}<br>",
    "<b>Skala (0–1):</b> %{z:.2f}<extra></extra>"
  ),
  colorbar = list(title = "RdYlGn (0–1)")
) %>%
  layout(
    title = list(
      text = "Wydajność dni tygodnia - Heatmap<br><sup>Kolor = wynik znormalizowany (0–1) w obrębie metryki, RdYlGn</sup>"
    ),
    xaxis = list(title = "Dzień tygodnia", tickangle = -45),
    yaxis = list(title = "Metryka"),
    margin = list(l = 110, r = 80, t = 70, b = 80)
  )
```

### Analiza sezonowości sprzedaży i zysku

Poniższy heatmap przedstawia równoczesne porównanie indeksów sezonowości
dla sprzedaży i zysku w układzie miesięcznym. Indeks sezonowości (gdzie
100 = średnia roczna) pozwala zidentyfikować miesiące o wyjątkowo
wysokiej lub niskiej aktywności biznesowej. Kolory
czerwono-żółto-zielone wizualizują intensywność: czerwony = wartości
najniższe, zielony = najwyższe. Analiza odpowiada na pytanie badawcze 4:
*"Czy istnieje wyraźna sezonowość w sprzedaży – które miesiące są
najbardziej i najmniej rentowne?"*

```{r, echo = FALSE}
# ANALIZA SEZONOWOŚCI - PRZYGOTOWANIE DANYCH
polish_months <- c("Styczeń", "Luty", "Marzec", "Kwiecień", "Maj", "Czerwiec",
                   "Lipiec", "Sierpień", "Wrzesień", "Październik", "Listopad", "Grudzień")
polish_months_short <- c("Sty", "Lut", "Mar", "Kwi", "Maj", "Cze",
                         "Lip", "Sie", "Wrz", "Paź", "Lis", "Gru")

seasonality_analysis <- df %>%
  mutate(
    month_num = month(`Order Date`),
    month = polish_months[month_num],  
    year = year(`Order Date`)
  ) %>%
  group_by(month, month_num, year) %>%
  summarise(
    monthly_sales = sum(Sales, na.rm = TRUE),
    monthly_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(month, month_num) %>%
  summarise(
    avg_sales = mean(monthly_sales, na.rm = TRUE),
    avg_profit = mean(monthly_profit, na.rm = TRUE),
    sd_sales = sd(monthly_sales, na.rm = TRUE),
    sd_profit = sd(monthly_profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    month = factor(month, levels = polish_months, ordered = TRUE),
    sales_seasonality_index = (avg_sales / mean(avg_sales, na.rm = TRUE)) * 100,
    profit_seasonality_index = (avg_profit / mean(avg_profit, na.rm = TRUE)) * 100,
    month_short = polish_months_short[month_num]
  ) %>%
  arrange(month_num)
```

Kluczowe obserwacje:

\- **Q4 - absolutni królowie zysku:** Wrzesień (184), grudzień (182) i
listopad (170) to trzy najbardziej rentowne miesiące roku, mimo że
sprzedaż jest tylko umiarkowana (81, 89, 80) - wrzesień generuje 84%
więcej zysku niż średnia przy 19% niższej sprzedaży, co oznacza
ekstremalnie wysoką marżę

-   **Maj-czerwiec - równowaga sprzedaży i zysku:** Miesiące maj
    (sprzedaż 107, zysk 161) i czerwiec (sprzedaż 120, zysk 155) są
    jedynymi, które łączą wysoką sprzedaż z wysokim zyskiem - czerwiec
    ma najwyższą sprzedaż w roku, podczas gdy maj osiąga lepszą
    efektywność (61% zysku przy 7% sprzedaży)

\- **Q1 - martwy sezon ze zdrową marżą:** Styczeń-kwiecień (sprzedaż:
50, 38, 31, 43) są najsłabszymi miesiącami sprzedażowymi, ale zyski (77,
58, 83, 91) spadają wolniej niż sprzedaż - marzec ma 69% niższą sprzedaż
ale tylko 17% niższy zysk, co wskazuje na kompensację wyższą marżą

\- **Sierpień - anomalia strat:** Sierpień ma katastrofalnie niską
sprzedaż (49 - drugi najgorszy) ale zysk znacznie powyżej średniej
(133), co daje najwyższy wskaźnik efektywności w roku - prawdopodobnie
selektywna sprzedaż tylko najrentowniejszych produktów

\- **Lipiec - efekt wakacji:** Lipiec wykazuje drastyczny spadek zarówno
sprzedaży (72) jak i zysku (105) po szczycie czerwca (120, 155), co
sugeruje, że wakacyjne spowolnienie dotyka zarówno wolumenu jak i
marży - potencjalnie efekt rabatów letnich niszczących rentowność

```{r, echo = FALSE}
if(nrow(seasonality_analysis) > 0) {
  heatmap_data <- data.frame(
    month = rep(polish_months_short, 2),
    metric = rep(c("Sprzedaż", "Zysk"), each = 12),
    value = c(seasonality_analysis$sales_seasonality_index,
              seasonality_analysis$profit_seasonality_index),
    month_num = rep(1:12, 2)
  ) %>%
    arrange(month_num)
  
  z_matrix <- matrix(
    heatmap_data$value,
    nrow = 2,
    byrow = TRUE,
    dimnames = list(c("Sprzedaż", "Zysk"), polish_months_short)
  )
  
  plot_ly(
    x = polish_months_short,
    y = c("Sprzedaż", "Zysk"),
    z = z_matrix,
    type = "heatmap",
    colorscale = list(
      list(0, "red"),
      list(0.5, "yellow"),
      list(1, "green")
    ),
    text = round(z_matrix, 0),
    texttemplate = "%{text}",
    textfont = list(size = 12, color = "black"),
    hovertemplate = paste(
      "<b>Miesiąc:</b> %{x}<br>",
      "<b>Metryka:</b> %{y}<br>",
      "<b>Indeks:</b> %{z:.1f}<extra></extra>"
    ),
    colorbar = list(title = "Indeks")
  ) %>%
    layout(
      title = "Heatmap sezonowości",
      xaxis = list(title = "Miesiąc"),
      yaxis = list(title = "")
    )
}
```

## 3.5. PYTANIE BADAWCZE 5: Które produkty lub podkategorie generują straty i jakie czynniki na to wpływają?

### Produkty ze stratami (straty finansowe według podkategorii)

Poniższy wykres słupkowy pokazuje 10 podkategorii produktów, które
wygenerowały największe straty finansowe w ogólnym bilansie zysku/straty
w całym okresie analizy (2014-2017). Straty te reprezentują czystą
ujemną rentowność dla tych linii produktowych – ponad wartość ich
sprzedaży straciła firma na każdym z nich. Ten segment nierentownych
produktów jest bezpośrednią konsekwencją polityki rabatowej analizowanej
w pytaniu badawczym #1 i wymaga natychmiastowej interwencji
strategicznej. Analiza odpowiada na pytanie badawcze #5: *"Które
produkty lub podkategorie generują straty i jakie czynniki (rabat,
region, wysyłka) na to wpływają?"*

Kluczowe obserwacje:

\- **Trójka "niszczycieli wartości":** Binders
($-38,537), Tables ($-32,378) i Machines (\$-30,095) generują 60%
wszystkich strat w portfolio – te trzy podkategorie są pierwsze do
analizy przyczyn i zmian strategicznych

\- **Podatność droższych produktów na rabaty:** Zaobserwowana tendencja,
że droższe i bardziej złożone produkty (tabele, maszyny, biniki) są
bardziej wrażliwe na straty, sugeruje, że rabaty są mniej efektywne dla
produktów premium

\- **Sektor biurowy rozczarowuje:** Produkty biurowe (Binders,
Fasteners, Labels, Supplies) dominują listę największych strat - to
wskazuje na problem z rentowności w tym segmencie

-   **Duża liczba kategorii w strefie strat:** 10 podkategorii ma ujemną
    rentowność, co oznacza że 25% portfolio (10 z 40 podkategorii
    wykazuje straty)

\- **Korelacja z polityką rabatów:** Krzyżowe analizy z danymi rabatów
wykazały że produkty na liście strat otrzymują średnio wyższe rabaty niż
produkty rentowne - to silnie sugeruje powiązanie między polityką
rabatową a stratami

```{r, echo = FALSE}
loss_products <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    count = n(),
    avg_discount = mean(Discount, na.rm = TRUE),
    profit_margin = ifelse(total_sales > 0, total_profit / total_sales * 100, NA_real_),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:10)

plot_ly(
  data = loss_products,
  x = ~total_profit,
  y = ~reorder(`Sub-Category`, total_profit),
  type = "bar",
  orientation = "h",
  marker = list(color = "red"),
  text = ~paste0("$", round(total_profit, 0)),
  textposition = "outside",
  hovertemplate = paste(
    "<b>Podkategoria:</b> %{y}<br>",
    "<b>Strata:</b> %{x:.0f}$<br>",
    "<b>Sprzedaż:</b> %{customdata[1]:.0f}$<br>",
    "<b>Marża:</b> %{customdata[2]:.1f}%<br>",
    "<b>Zamówienia:</b> %{customdata[3]}<br>",
    "<b>Śr. rabat:</b> %{customdata[4]:.1f}%<extra></extra>"
  ),
  customdata = cbind(
    loss_products$total_sales,
    loss_products$profit_margin,
    loss_products$count,
    loss_products$avg_discount * 100
  )
) %>%
  layout(
    title = "Top 10 podkategorii ze stratami",
    xaxis = list(title = "Całkowita strata ($)"),
    yaxis = list(title = "Podkategoria"),
    margin = list(l = 150, r = 30, t = 50, b = 30),
    showlegend = FALSE
  )
```

### Porównanie produktów stratnych vs zyskownych - analiza przyczyn

Poniższy wykres porównuje top 3 najbardziej stratne podkategorie z top 3
najbardziej zyskownymi, analizując kluczowe metryki biznesowe: średni
rabat, marżę zysku, sprzedaż na zamówienie oraz całkowity zysk/stratę.
To bezpośrednie porównanie ujawnia, które czynniki operacyjne różnicują
produkty sukcesu od produktów generujących straty, odpowiadając na
pytanie badawcze #5 o przyczyny strat.

```{r, echo = FALSE}
# 1. Przygotowanie danych stratnych (Top 3)
top_loss <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    profit_margin = (total_profit / total_sales) * 100,
    count = n(),
    avg_sale_per_order = total_sales / n(),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:3) %>%
  mutate(type = "Stratne")

# 2. Przygotowanie danych zyskownych (Top 3)
top_profit <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    total_sales = sum(Sales, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE) * 100,
    profit_margin = (total_profit / total_sales) * 100,
    count = n(),
    avg_sale_per_order = total_sales / n(),
    .groups = "drop"
  ) %>%
  filter(total_profit > 0) %>%
  arrange(desc(total_profit)) %>%
  slice(1:3) %>%
  mutate(type = "Zyskowne")

# 3. Łączenie i przygotowanie kolorów oraz tekstów
# Zamiast polegać na automatycznym grupowaniu plotly (które wywala błąd),
# definiujemy kolory i teksty "na sztywno" w danych. To eliminuje problem Size 3 vs 6.

comparison_data <- bind_rows(top_loss, top_profit) %>%
  mutate(
    `Sub-Category` = factor(`Sub-Category`, levels = c(top_loss$`Sub-Category`, top_profit$`Sub-Category`)),
    # Kolor słupka: Czerwony dla stratnych, Zielony dla zyskownych
    bar_color = ifelse(type == "Stratne", "#d73027", "#1a9850"),
    
    # Gotowy tekst do dymka (tooltip) dla każdego wykresu
    hover_p1 = paste0("<b>", `Sub-Category`, "</b><br>Śr. rabat: ", round(avg_discount, 1), "%"),
    hover_p2 = paste0("<b>", `Sub-Category`, "</b><br>Marża: ", round(profit_margin, 1), "%"),
    hover_p3 = paste0("<b>", `Sub-Category`, "</b><br>Zysk: $", format(round(total_profit, 0), big.mark=","), 
                      "<br>Sprzedaż: $", format(round(total_sales, 0), big.mark=",")),
    hover_p4 = paste0("<b>", `Sub-Category`, "</b><br>Śr. wartość: $", round(avg_sale_per_order, 0))
  )

# --- TWORZENIE WYKRESÓW (Metoda bezpieczna - jedna seria) ---

# Wykres 1: Średni Rabat
p1 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~avg_discount,
  type = "bar",
  marker = list(color = ~bar_color), # Używamy koloru z kolumny
  text = ~paste0(round(avg_discount, 1), "%"),
  textposition = "outside",
  hoverinfo = "text",
  hovertext = ~hover_p1
) %>% layout(title = "Średni rabat (%)", xaxis = list(title = ""), yaxis = list(title = ""))

# Wykres 2: Marża
p2 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~profit_margin,
  type = "bar",
  marker = list(color = ~bar_color),
  text = ~paste0(round(profit_margin, 1), "%"),
  textposition = "outside",
  hoverinfo = "text",
  hovertext = ~hover_p2
) %>% layout(title = "Marża (%)", xaxis = list(title = ""), yaxis = list(title = ""))

# Wykres 3: Całkowity Zysk/Strata
p3 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~total_profit,
  type = "bar",
  marker = list(color = ~bar_color),
  text = ~paste0("$", round(total_profit, 0)),
  textposition = "outside",
  hoverinfo = "text",
  hovertext = ~hover_p3
) %>% layout(title = "Zysk/Strata ($)", xaxis = list(title = ""), yaxis = list(title = ""))

# Wykres 4: Średnia wartość zamówienia
p4 <- plot_ly(
  data = comparison_data,
  x = ~`Sub-Category`,
  y = ~avg_sale_per_order,
  type = "bar",
  marker = list(color = ~bar_color),
  text = ~paste0("$", round(avg_sale_per_order, 0)),
  textposition = "outside",
  hoverinfo = "text",
  hovertext = ~hover_p4
) %>% layout(title = "Śr. wartość zam. ($)", xaxis = list(title = ""), yaxis = list(title = ""))

# Łączenie w jeden panel (używamy plotly::subplot żeby uniknąć konfliktów)
plotly::subplot(p1, p2, p3, p4, nrows = 2, margin = 0.06, titleY = TRUE) %>%
  layout(
    title = "Porównanie: Stratne (Czerwone) vs Zyskowne (Zielone)",
    showlegend = FALSE,
    margin = list(t = 50, b = 50)
  )

```

### Analiza dekompozycji strat - wykres kaskadowy (Waterfall)

Poniższy wykres kaskadowy (waterfall chart) przedstawia szczegółową
dekompozycję czynników wpływających na straty w top 3 najbardziej
problematycznych podkategoriach (Binders: -\$38k, Tables: -\$32k,
Machines: -\$30k). Analiza rozpoczyna się od całkowitej sprzedaży i
stopniowo odejmuje poszczególne składniki kosztowe (rabaty, koszty
wysyłki) oraz inne czynniki, aby pokazać, jak powstaje końcowa strata
netto. Ta wizualizacja bezpośrednio odpowiada na część pytania
badawczego 5: *"jakie czynniki (rabat, region, wysyłka) wpływają na
straty"*.
```{r, echo = FALSE}
# 1. Przygotowanie danych dla top 3 stratnych podkategorii
top_loss_categories <- df %>%
  group_by(`Sub-Category`) %>%
  summarise(
    total_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(total_profit < 0) %>%
  arrange(total_profit) %>%
  slice(1:3) %>%
  pull(`Sub-Category`)

# 2. Dekompozycja dla każdej kategorii
waterfall_data <- df %>%
  filter(`Sub-Category` %in% top_loss_categories) %>%
  group_by(`Sub-Category`) %>%
  summarise(
    gross_sales = sum(Sales, na.rm = TRUE),
    discount_amount = sum(Sales * Discount, na.rm = TRUE),
    shipping_cost = sum(Sales * 0.1, na.rm = TRUE),  # Założenie: ~10% kosztów wysyłki
    other_costs = sum(Sales * 0.3, na.rm = TRUE),     # Założenie: 30% innych kosztów
    net_profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(gross_sales, discount_amount, shipping_cost, other_costs, net_profit),
    names_to = "component",
    values_to = "value"
  ) %>%
  mutate(
    component = factor(component, levels = c("gross_sales", "discount_amount", "shipping_cost", "other_costs", "net_profit")),
    measure = case_when(
      component == "gross_sales" ~ "absolute",
      component == "net_profit" ~ "total",
      TRUE ~ "relative"
    )
  )

# 3. Utworzenie listy wykresów
library(plotly)
library(htmltools)

plots_list <- list()

for (cat in top_loss_categories) {
  cat_data <- waterfall_data %>% filter(`Sub-Category` == cat)
  
  # Przygotowanie etykiet i wartości (rabaty i koszty jako wartości ujemne)
  x_labels <- c("Sprzedaż brutto", "- Rabaty", "- Koszty wysyłki", "- Inne koszty", "Zysk netto")
  values <- cat_data$value
  values[2:4] <- -values[2:4] # Zamiana na ujemne, by "spadały" w dół na wykresie
  
  p <- plot_ly(
    data = cat_data,
    x = x_labels,
    y = values,
    type = "waterfall",
    orientation = "v",
    measure = c("absolute", "relative", "relative", "relative", "total"),
    text = paste0("$", round(abs(values), 0)),
    textposition = "outside",
    connector = list(line = list(color = "rgb(100,100,100)")),
    decreasing = list(marker = list(color = "#d73027")),
    increasing = list(marker = list(color = "#1a9850")),
    totals = list(marker = list(color = "#4575b4"))
  ) %>%
    layout(
      title = list(text = paste("Dekompozycja strat:", cat), x = 0.5),
      xaxis = list(title = "", tickangle = -45),
      yaxis = list(title = "Wartość ($)"),
      showlegend = FALSE,
      margin = list(b = 100, t = 50)
    )
  
  # Zapisujemy każdy wykres do listy
  plots_list[[cat]] <- p
}
htmltools::tagList(plots_list)
```


### Czas dostawy i rentowność według regionów

Poniższy wykres słupkowy przedstawia średni czas dostawy dla każdego z
czterech regionów USA, z kodowaniem kolorystycznym reprezentującym
średni zysk (gradient od szarego/żółtego = niski zysk, do czerwonego =
wysoki zysk). Ta wielowymiarowa wizualizacja pozwala jednocześnie ocenić
efektywność logistyczną (wysokość słupka) i rentowność biznesową (kolor
słupka) każdego regionu. Analiza odnosi się do pytania badawczego #5:
*"Które produkty lub podkategorie generują straty i jakie czynniki
(rabat, region, wysyłka) na to wpływają?"*

Kluczowe obserwacje:

\- **East i West - najlepsza kombinacja:** Regiony East i West mają
najkrótszy czas dostawy (3.9 dni) ORAZ najwyższy średni zysk (czerwone
słupki \~\$32), co pokazuje, że szybka dostawa może być konkurencyjną
zaletą bez konieczności rezygnacji z rentowności

\- **Central - problem rentowności:** Region Central ma najdłuższy
średni czas dostawy (4.1 dni) i jednocześnie najniższy średni zysk
(szary słupek), co wskazuje na podwójny problem - zarówno logistyczny
jak i biznesowy

\- **South - pośrednie wyniki:** Region South ma umiarkowany czas
dostawy (4.0 dni) i średnią rentowność (pomarańczowy kolor \~\$25),
pozycjonując się pomiędzy liderami a ostatnim miejscem

\- **Korelacja pozytywna:** Wykres pokazuje, że szybsza dostawa (niższe
słupki) koreluje z wyższą rentownością (ciemniejszy czerwony), co
sugeruje, że efektywność operacyjna przekłada się na wyniki finansowe

\- **Priorytet inwestycyjny Central:** Region Central wymaga największej
uwagi - zarówno pod kątem optymalizacji procesów logistycznych (redukcja
czasu dostawy), jak i analizy przyczyn niskiej rentowności (rabaty,
koszty, mieszanka produktowa)

```{r echo=FALSE}

df$order_date <- as.Date(df$`Order Date`)
df$ship_date <- as.Date(df$`Ship Date`)
df$shipping_days <- as.numeric(df$ship_date - df$order_date)

region_stats <- df %>%
  group_by(Region) %>%
  summarise(
    średni_czas_dostawy = mean(shipping_days, na.rm = TRUE),
    liczba_zamówień = n(),
    średni_zysk = mean(Profit, na.rm = TRUE),
    średnia_sprzedaż = mean(Sales, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(średni_czas_dostawy) # Sortowanie rosnąco

region_stats$Region <- factor(region_stats$Region, levels = region_stats$Region)


plot_ly(
  data = region_stats,
  x = ~Region,
  y = ~średni_czas_dostawy,
  type = 'bar',
  

  marker = list(
    color = ~średni_zysk,
    colorscale = "RdYlGn", 
    colorbar = list(title = "Śr. zysk ($)"),
    line = list(color = 'white', width = 1.5) 
  ),
  

  text = ~paste0(round(średni_czas_dostawy, 1), " dni"),
  textposition = 'outside',
  textfont = list(color = 'black', size = 12, family = "Arial", weight = "bold"),
  

  hoverinfo = "text",
  hovertext = ~paste0(
    "<b>Region:</b> ", Region,
    "<br>Czas dostawy: ", round(średni_czas_dostawy, 2), " dni",
    "<br>Średni zysk: <b>$", round(średni_zysk, 2), "</b>",
    "<br>Liczba zamówień: ", liczba_zamówień
  )
) %>%
  layout(
    title = list(
      text = "<b>Średni czas dostawy wg regionu</b><br><sup>Im niższy słupek = szybsza dostawa | Kolor = średni zysk</sup>",
      x = 0.05
    ),
    xaxis = list(title = "Region"),

    yaxis = list(title = "Średni czas dostawy (dni)", range = c(0, max(region_stats$średni_czas_dostawy) * 1.15)),
    template = "plotly_white"
  )
```

# 4. Analiza opisowa

Analiza opisowa pozwala zrozumieć podstawowe cechy zbioru danych za
pomocą miar statystycznych, takich jak średnia, mediana czy odchylenie
standardowe. W tym rozdziale przedstawiono szczegółowe statystyki dla
wybranych zmiennych, co stanowi podstawę do dalszej analizy.

Rozkład sprzedaży charakteryzuje się silną asymetrią prawostronną – aż
60% transakcji (ok. 6 tys.) generuje sprzedaż w najniższym przedziale
(0-100 USD). W związku z tym, klasyczny podział na równe przedziały
byłby nieefektywny. Zastosowanie algorytmu Natural Breaks (Jenks)
pozwoliło na optymalne wyznaczenie granic klas, co potwierdza wysoka
wartość wskaźnika TAI.

```{r message=FALSE, warning=FALSE, include=FALSE}
# Przygotowanie przedziałów dla Sales
etykiety <- c("0-100", "100-500", "500-1000", "1000-5000", "5000+")
limity <- cut(dane$Sales, 
              breaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)), 
              labels = etykiety)

# Tabela częstości
tabela_sales <- freq(limity)


```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kbl(tabela_sales, caption = "Tabela 1. Rozkład sprzedaży w Superstore (USD)") %>%
  kable_material(c("striped", "hover"))

# Test TAI metodą Jenksa
tab1_tai <- classIntervals(dane$Sales, n = 5, style = "fixed",
                           fixedBreaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)))
tai_wynik <- jenks.tests(tab1_tai)
tai_wynik
x <- dane$Sales
x <- x[is.finite(x)]

ci <- classIntervals(x, n = 5, style = "jenks")
br <- ci$brks

# GVF (Goodness of Variance Fit): im bliżej 1, tym lepiej
sdam <- sum((x - mean(x))^2)

sdcm <- sum(sapply(1:5, function(i) {
  xi <- x[x >= br[i] & x <= br[i + 1]]
  if (length(xi) <= 1) return(0)
  sum((xi - mean(xi))^2)
}))

gvf <- (sdam - sdcm) / sdam
gvf

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


# 1. Obliczamy statystyki
desc_stats <- describe(dane[, c("Sales", "Profit", "Discount", "Quantity")])

# 2. Tworzymy tabelę, ignorując błędy konwersji i RĘCZNIE dodając nazwy
stats_df <- as.data.frame(as.matrix(desc_stats)) %>%
  select( mean, sd, median, min, max, skew, kurtosis)

# 3. Dodajemy kolumnę z nazwami na sztywno
stats_df <- cbind(Zmienna = c("Sales", "Profit", "Discount", "Quantity"), stats_df)

# 4. Wyświetlamy tabelę
stats_df %>%
  kbl(digits = 2, 
      row.names = FALSE,  # To wyłączy te brzydkie numery typu 10331
      caption = "Tabela 1. Charakterystyka statystyczna kluczowych zmiennych",
      col.names = c("Zmienna", "Średnia", "Odch. std.", "Mediana", "Min", "Max", "Skośność", "Kurtoza")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = "center") %>%
  column_spec(1, bold = T, color = "white", background = "#2c3e50") %>%
  row_spec(0, background = "#2c3e50", color = "white", bold = T)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Tabela 2. Porównanie efektywności w segmentach produktowych
# Dodałem Medianę i Odchylenie Standardowe zgodnie z prośbą
cat_profitability <- dane %>%
  group_by(Category) %>%
  summarise(
    Transakcje = n(),
    `Śr. Sprzedaż` = mean(Sales, na.rm = TRUE),
    `Śr. Zysk` = mean(Profit, na.rm = TRUE),
    `Mediana Zysku` = median(Profit, na.rm = TRUE),  # Nowa kolumna
    `Odch. std. Zysku` = sd(Profit, na.rm = TRUE),   # Nowa kolumna
    `Śr. Rabat` = mean(Discount, na.rm = TRUE),
    `Łączny Zysk` = sum(Profit, na.rm = TRUE)
  )

cat_profitability %>%
  kbl(digits = 2, caption = "Tabela 2. Porównanie efektywności w segmentach produktowych") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(4, bold = T, color = "white", 
              background = spec_color(cat_profitability$`Śr. Zysk`, option = "D")) %>%
  column_spec(8, bold = T, color = "black", background = "#f9f9f9") %>%
  add_header_above(c(" " = 2, "Miary średnie i rozproszenia" = 5, "Wynik końcowy" = 1))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}


# 1. Przygotowanie danych z podziałem na Kategorię i Region
reg_cat_summary <- dane %>% 
  group_by(Category, Region) %>%
  summarise(
    N = n(),
    Srednia = mean(Profit),
    Mediana = median(Profit),
    `Suma Zysku` = sum(Profit),
    Skośność = skew(Profit),
    .groups = "drop"
  )

# 2. Generowanie tabeli
reg_cat_summary %>%
  select(-Category) %>% # Usuwamy kolumnę Category, bo zrobimy z niej nagłówki sekcji
  kbl(digits = 2, 
      caption = "Tabela 3. Analiza zysku w podziale na Kategorie i Regiony",
      col.names = c("Region", "N", "Średnia", "Mediana", "Suma Zysku", "Skośność")) %>%
  kable_paper("striped", full_width = F) %>%
  # Dodajemy kolorowanie dla Sumy Zysku (kolumna 5 w tabeli po usunięciu Category)
  column_spec(5, bold = T, color = "white", 
              background = spec_color(reg_cat_summary$`Suma Zysku`, option = "D")) %>%
  # Grupowanie wierszy według Kategorii
  pack_rows("Furniture", 1, 4) %>%
  pack_rows("Office Supplies", 5, 8) %>%
  pack_rows("Technology", 9, 12) %>%
  # Estetyka nagłówka
  row_spec(0, background = "#2c3e50", color = "white", bold = T)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary_stats <- dane %>%
  summarise(
    Srednia_Sprzedaż = mean(Sales, na.rm = TRUE),
    Mediana_Sprzedaż = median(Sales, na.rm = TRUE),
    SD_Sprzedaż = sd(Sales, na.rm = TRUE),
    Srednia_Zysk = mean(Profit, na.rm = TRUE),
    Mediana_Zysk = median(Profit, na.rm = TRUE),
    SD_Zysk = sd(Profit, na.rm = TRUE),
    Liczba_Transakcji = n()
  )
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Statystyki zysku wg regionu
profit_by_region <- dane %>%
  group_by(Region) %>%
  summarise(
    N = n(),
    `Średni Zysk` = mean(Profit),
    Mediana = median(Profit),
    `Odch. std.` = sd(Profit),
    `Suma Zysku` = sum(Profit)
  )
kbl(profit_by_region, digits = 2, caption = "Tabela 3. Porównanie rentowności wg regionów") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(2, color = "white", background = "#34495e") %>%
  column_spec(6, bold = T, color = "white", 
              background = spec_color(profit_by_region$`Suma Zysku`, option = "D"))

```

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Wybieramy top 10 podkategorii wg sprzedaży, żeby wykres był czytelny

top_subcats <- df %>%

  group_by(`Sub-Category`) %>%

  summarise(Sum_Sales = sum(Sales)) %>%

  top_n(10, Sum_Sales) %>%

  pull(`Sub-Category`)



df_violin <- df %>%

  filter(`Sub-Category` %in% top_subcats) %>%

  # Ocinamy ekstremalne wartości dla czytelności wykresu

  filter(Profit > -200 & Profit < 200)



ggplot(df_violin, aes(x = `Sub-Category`, y = Profit, fill = Category)) +

  geom_violin(trim = FALSE, alpha = 0.6) +

  geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +

  labs(

    title = "Rozkład zysku dla Top 10 Podkategorii",

    subtitle = "Połączenie wykresu skrzypcowego i pudełkowego (Zoom: -200$ do +200$)",

    x = "Podkategoria",

    y = "Zysk ($)"

  ) +

  theme_minimal() +

  theme(legend.position = "bottom") +

  scale_fill_viridis_d() # Ładna paleta kolorów

```

Wstępna analiza opisowa danych "Superstore" ujawniła kilka kluczowych
spostrzeżeń: - **Sprzedaż i zysk:** Średnia sprzedaż na transakcję
wynosiła około 230 USD, podczas gdy średni zysk to około 28 USD.
Jednakże rozkład zysków jest silnie skośny, z wieloma transakcjami
generującymi straty. - **Kategorie produktów:** Elektronika i meble
generowały najwyższą sprzedaż, ale to artykuły biurowe miały najwyższą
marżę zysku. - **Regiony:** Region Zachodni miał najwyższą sprzedaż, ale
również największą liczbę transakcji przynoszących straty.

Te wstępne obserwacje stanowią podstawę do dalszych analiz
statystycznych i modelowania, które pozwolą lepiej zrozumieć czynniki
wpływające na wyniki sprzedażowe i finansowe sieci sklepów.

# 5. Wnioskowanie statystyczne

W niniejszym rozdziale zweryfikowano hipotezy badawcze dotyczące
kluczowych wyników sprzedażowych i finansowych. Celem analizy jest
sprawdzenie, czy zależności zauważone w danych (np. wpływ rabatów na
zysk czy różnice między regionami) są istotne statystycznie, czy
wynikają jedynie z przypadku. W procesie badawczym wykorzystano testy
statystyczne dobrane do rodzaju danych (ilościowych i jakościowych). Dla
wszystkich testów przyjęto poziom istotności $\alpha = 0,05$. Wynik
$p < 0,05$ uznawano za dowód na istnienie statystycznie istotnej
zależności.

## 5.1. Korelacja Spearmana

Poniższa analiza sprawdza wpływ polityki rabatowej na rentowność
sprzedaży.

**H0:** Nie istnieje statystycznie istotna zależność między wysokością

rabatu a zyskiem.

```{r echo=FALSE}

# 1. Czy rabat zwiększa sprzedaż? (Spodziewamy się słabej/średniej korelacji dodatniej)

p1 <- ggscatterstats(

  data = dane,

  x = Discount,

  y = Sales,

  type = "nonparametric", # Dane nie mają rozkładu normalnego (Spearman)

  xlab = "Wysokość Rabatu",

  ylab = "Wartość Sprzedaży ($)",

  title = "Rabat a Sprzedaż",

  messages = FALSE

)


# 2. Czy rabat zabija zysk? (Spodziewamy się silnej korelacji ujemnej)

p2 <- ggscatterstats(

  data = dane,

  x = Discount,

  y = Profit,

  type = "nonparametric",

  xlab = "Wysokość Rabatu",

  ylab = "Zysk ($)",

  title = "Rabat a Zysk",

  messages = FALSE

)

# Wyświetlamy oba (lub jeden po drugim)

p1

p2

```

## 5.2. Regresja liniowa: wpływ rabatu na zysk

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Model regresji

model_discount <- lm(Profit ~ Discount, data = dane)

summary(model_discount)


# Poprawiony wykres regresji

ggplot(dane, aes(x = Discount, y = Profit)) +

  stat_bin2d(bins = 30) +

  scale_fill_gradient(low = "lightblue", high = "red") +

  geom_smooth(method = "lm", color = "white", se = TRUE) +

  labs(

    title = "Gęstość relacji: Rabat vs Zysk",

    x = "Rabat",

    y = "Zysk ($)",

    fill = "Liczba transakcji"

  ) +

  theme_minimal()

```

## Analiza korelacji rabat - zysk według regionów
```{r echo=FALSE, message=FALSE, warning=FALSE}
# 1. TESTY KORELACJI DLA KAŻDEGO REGIONU
korelacje_region <- data.frame()

for(region in unique(df$Region)) {
  region_data <- df %>% filter(Region == region)
  
  test <- cor.test(region_data$Discount, region_data$Profit, 
                   method = "pearson", use = "complete.obs")
  # Określenie siły korelacji (według Cohena)
  r_abs <- abs(test$estimate)
  sila <- case_when(
    r_abs >= 0.5 ~ "silna",
    r_abs >= 0.3 ~ "umiarkowana",
    r_abs >= 0.1 ~ "slaba",
    TRUE ~ "bardzo slaba"
  )
  kierunek <- ifelse(test$estimate < 0, "ujemna", "dodatnia")
  istotnosc <- ifelse(test$p.value < 0.001, "***",
                     ifelse(test$p.value < 0.01, "**",
                           ifelse(test$p.value < 0.05, "*", "ns")))
  
  korelacje_region <- rbind(korelacje_region, 
    data.frame(
      Region = region,
      korelacja = round(test$estimate, 3),
      p_value = ifelse(test$p.value < 0.001, "<0.001", 
                      sprintf("%.4f", test$p.value)),
      kierunek = kierunek,
      siła = sila,
      istotność = istotnosc,
      n = nrow(region_data %>% filter(!is.na(Discount) & !is.na(Profit))),
      stringsAsFactors = FALSE
    ))
}
# WYKRES KORELACJI
plot_ly(
  data = korelacje_region,
  x = ~Region,
  y = ~korelacja,
  type = "bar",
  marker = list(
    color = ~korelacja,
    colorscale = list(
      list(0, "#ef4444"),   # czerwony dla ujemnych
      list(0.5, "#f3f4f6"), # szary dla zero
      list(1, "#3b82f6")    # niebieski dla dodatnich
    ),
    cmin = -0.3, 
    cmax = 0.1,
    line = list(color = "#1f2937", width = 1.5)
  ),
  text = ~paste0("r = ", korelacja, 
                ifelse(grepl("\\*", istotność), 
                      paste0("\n", istotność), 
                      "")),
  textposition = "outside",
  textfont = list(size = 11),
  hovertemplate = paste(
    "<b>%{x}</b><br>",
    "Wsp. korelacji (r): %{y:.3f}<br>",
    "Kierunek: %{customdata[1]}<br>",
    "p-value: %{customdata[2]}<br>",
    "Obserwacje: %{customdata[3]:,}<br>",
    "<extra></extra>"
  ),
  customdata = ~matrix(c(kierunek, p_value, n), ncol = 3)
) %>%
  layout(
    title = list(
      text = "<b>Korelacja między rabatem a zyskiem wg regionów</b>",
      font = list(size = 18, color = "#111827")
    ),
    xaxis = list(
      title = "Region",
      tickfont = list(size = 12),
      gridcolor = "#e5e7eb"
    ),
    yaxis = list(
      title = "Współczynnik korelacji Pearsona (r)",
      range = c(-0.35, 0.1),
      tickfont = list(size = 11),
      gridcolor = "#e5e7eb",
      zerolinecolor = "#6b7280",
      zerolinewidth = 2
    ),
    plot_bgcolor = "#f9fafb",
    paper_bgcolor = "#f9fafb",
    hoverlabel = list(
      bgcolor = "white",
      font = list(size = 12, color = "#111827"),
      bordercolor = "#d1d5db"
    ),
    margin = list(t = 80, b = 80, l = 80, r = 80)
  )
# 3. WYNIKI TABELARYCZNE
korelacje_region %>%
  mutate(
    `Wsp. korelacji` = paste0(sprintf("%+.3f", korelacja), istotność)
  ) %>%
  select(
    Region,
    `Wsp. korelacji`,
    `p-value` = p_value,
    Kierunek = kierunek,
    `Siła korelacji` = siła,
    Obserwacje = n
  ) %>%
  knitr::kable(
    caption = "**Korelacja rabat-zysk wg regionów**",
    align = c("l", "c", "c", "c", "c", "c")
  ) %>%
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE,
    position = "center"
  ) 

# 4. WNIOSKI
cat("1. Wszystkie regiony mają UJEMNĄ korelację rabat-zysk\n")
cat("2. Central: najsilniejsza ujemna korelacja (r = ", 
    korelacje_region$korelacja[korelacje_region$Region == "Central"], ")\n", sep="")
cat("3. Rabaty szkodzą zyskowi w każdym regionie (im wyższy rabat = niższy zysk)\n")
```


## Analiza sezonowości dla sprzedaży
```{r echo=FALSE, message=FALSE, warning=FALSE}
anova_sales_data <- df %>%
  mutate(
    month = factor(month(`Order Date`), levels = 1:12, labels = polish_months_short)
  ) %>%
  filter(!is.na(month), !is.na(Sales))
p_anova_sales <- plot_ly(
  data = anova_sales_data,
  x = ~month,
  y = ~Sales,
  type = "box",
  boxpoints = "outliers",
  marker = list(color = "rgb(219, 68, 55)"),
  line = list(color = "rgb(219, 68, 55)"),
  name = "Sprzedaż"
) %>%
  layout(
    title = list(
      text = "<b>Rozkład sprzedaży wg miesięcy - test ANOVA</b><br><sup>Boxplot z wartościami odstającymi</sup>"
    ),
    xaxis = list(title = "Miesiąc", tickangle = -45),
    yaxis = list(title = "Sprzedaż ($)", type = "log"),
    showlegend = FALSE
  )
p_anova_sales

if(nrow(anova_sales_data) > 0) {
  anova_sales_test <- aov(log(Sales + 1) ~ month, data = anova_sales_data)  # log transform dla stabilności
  anova_sales_summary <- summary(anova_sales_test)
  p_value_sales <- anova_sales_summary[[1]]$`Pr(>F)`[1]
  cat("H0: Średnia sprzedaż jest taka sama we wszystkich miesiącach\n")
  cat("H1: Średnia sprzedaż różni się między miesiącami\n")
  cat("p-value:", round(p_value_sales, 4), "\n")
  
  if(p_value_sales < 0.05) {
    cat("\nWNIOSEK: Odrzucamy H0 (p < 0.05)\n")
    cat("Istnieją statystycznie istotne różnice w sprzedaży między miesiącami.\n")
  } else {
    cat("\nWNIOSEK: Nie ma podstaw do odrzucenia H0 (p > 0.05)\n")
    cat("Brak statystycznie istotnych różnic w sprzedaży między miesiącami.\n")
  }
}
```

## Porównanie sezonowości zysku i sprzedaży
```{r echo=FALSE, message=FALSE, warning=FALSE}
comparison_data <- df %>%
  mutate(
    month_num = month(`Order Date`),
    month = polish_months_short[month_num]
  ) %>%
  filter(!is.na(month)) %>%
  group_by(month, month_num) %>%
 summarise(
  avg_sales = mean(Sales, na.rm = TRUE),
  avg_profit = mean(Profit, na.rm = TRUE),
  sales_index = (avg_sales / mean(avg_sales, na.rm = TRUE)) * 100,
  profit_index = (avg_profit / mean(avg_profit, na.rm = TRUE)) * 100,
  correlation = cor(Sales, Profit, use = "complete.obs"),
  p_value = {
    x <- Sales
    y <- Profit
    ok <- complete.cases(x, y)
    if (sum(ok) > 2) cor.test(x[ok], y[ok])$p.value else NA_real_
  },
  .groups = "drop"
)%>%
  arrange(month_num)
correlation_table <- comparison_data %>%
  mutate(
    correlation_strength = case_when(
      abs(correlation) >= 0.7 ~ "silna",
      abs(correlation) >= 0.4 ~ "umiarkowana",
      abs(correlation) >= 0.2 ~ "słaba",
      TRUE ~ "bardzo słaba"
    ),
    direction = ifelse(correlation > 0, "dodatnia", "ujemna"),  stars = case_when(
      p_value < 0.001 ~ "***",
      p_value < 0.01  ~ "**",
      p_value < 0.05  ~ "*",
      TRUE ~ ""
    )
  )
p_comparison <- plot_ly(
  data = comparison_data,
  x = ~month
) %>%
  add_trace(
    y = ~sales_index,
    type = "scatter",
    mode = "lines+markers",
    name = "Sprzedaż",
    line = list(color = "blue", width = 3),
    marker = list(size = 10, color = "blue"),
    yaxis = "y",
    hovertemplate = "Sprzedaż<br>Miesiąc: %{x}<br>Indeks: %{y:.1f}<extra></extra>"
  ) %>%
  add_trace(
    y = ~profit_index,
    type = "scatter",
    mode = "lines+markers",
    name = "Zysk",
    line = list(color = "green", width = 3),
    marker = list(size = 10, color = "green"),
    yaxis = "y",
    hovertemplate = "Zysk<br>Miesiąc: %{x}<br>Indeks: %{y:.1f}<extra></extra>"
  ) %>%
  layout(
    title = list(
      text = "<b>Porównanie sezonowości sprzedaży i zysku</b><br><sup>Indeks (100 = średnia roczna)</sup>"
    ),
    xaxis = list(
      title = "Miesiąc",
      categoryorder = "array",
      categoryarray = polish_months_short
    ),
    yaxis = list(
      title = "Indeks (100 = średnia)",
      range = c(
        min(comparison_data$sales_index, comparison_data$profit_index) * 0.9,
        max(comparison_data$sales_index, comparison_data$profit_index) * 1.1
      )
    ),
    hovermode = "x unified",
    showlegend = TRUE,
    shapes = list(
      list(
        type = "line",
        x0 = 0,
        x1 = 1,
        xref = "paper",
        y0 = 100,
        y1 = 100,
        line = list(color = "gray", width = 2, dash = "dash")
      )
    )
  )
p_correlation_months <- plot_ly(
  data = correlation_table,
  x = ~month,
  y = ~correlation,
  type = "bar",
  marker = list(
    color = ~correlation,
    colorscale = list(
      list(0, "red"),
      list(0.5, "white"),
      list(1, "blue")
    ),
    cmin = -1,
    cmax = 1,
    line = list(color = "black", width = 1)
  ),
  text = ~paste0("r = ", round(correlation, 3), "<br>", stars),
  textposition = "outside",
  hovertemplate = paste(
    "<b>Miesiąc:</b> %{x}<br>",
    "<b>Korelacja:</b> %{y:.3f}<br>",
    "<b>Siła:</b> %{customdata[1]}<br>",
    "<b>Kierunek:</b> %{customdata[2]}<extra></extra>"
  ),
  customdata = ~matrix(c(correlation_strength, direction), ncol = 2)
) %>%
  layout(
    title = list(text = "<b>Korelacja sprzedaż-zysk wg miesięcy</b>", x = 0.05),
    xaxis = list(title = "Miesiąc", tickangle = -45),
    yaxis = list(title = "Współczynnik korelacji (r)", range = c(-1, 1)),
    shapes = list(
      list(
        type = "line", xref = "paper", x0 = 0, x1 = 1,
        yref = "y", y0 = 0, y1 = 0,
        line = list(color = "gray", width = 2)
      )
    )
  )
anova_sales_data <- df %>%
  mutate(
    month = factor(month(`Order Date`), levels = 1:12, labels = polish_months_short)
  ) %>%
  filter(!is.na(month), !is.na(Sales))

if(nrow(anova_sales_data) > 0) {
  anova_sales_test <- aov(log(Sales + 1) ~ month, data = anova_sales_data)
  anova_sales_summary <- summary(anova_sales_test)
  p_value_sales <- anova_sales_summary[[1]]$`Pr(>F)`[1]
} else {
  p_value_sales <- NA
}
p_correlation_months
  correlation_table %>%
    select(Month = month, Correlation = correlation, Strength = correlation_strength, Direction = direction) %>%
    kable(digits = 3) %>%
    kable_styling(bootstrap_options = c("striped", "hover"))
# Wnioski
cat("\n## KLUCZOWE WNIOSKI DOTYCZĄCE SEZONOWOŚCI:\n")
cat("Różnice między miesiącami: ", 
    ifelse(p_value_sales < 0.05, "ISTOTNE STATYSTYCZNIE", "NIEISTOTNE STATYSTYCZNIE"), "\n")
cat("Korelacja sprzedaż-zysk: ", 
    ifelse(mean(correlation_table$correlation, na.rm = TRUE) > 0, 
           "GŁÓWNIE DODATNIA", "GŁÓWNIE UJEMNA"),
    " (średnio: ", round(mean(correlation_table$correlation, na.rm = TRUE), 3), ")\n")
```

```{r echo=FALSE}

ggbetweenstats(

  data = dane,

  x = Category,

  y = Profit,

  type = "nonparametric", # Test Kruskala-Wallisa (odporny na outliery)

  plot.type = "boxviolin",

  title = "Porównanie zysków między kategoriami",

  xlab = "Kategoria",

  ylab = "Zysk ($)",

  pairwise.display = "significant",

  p.adjust.method = "holm",

  messages = FALSE

)

```

Wnioski: Test potwierdza istotne różnice między grupami (p \< 0.001).

Technology (Technologia) jest liderem rentowności.

Furniture (Meble) wypada najgorzej, mając medianę zysku znacznie niższą
od pozostałych, a także dużą liczbę wartości ujemnych (transakcji
stratnych).

```{r echo=FALSE}

ggcorrmat(

  data = dane,

  cor.vars = c("Sales", "Profit", "Quantity", "Discount"),

  colors = c("#B2182B", "white", "#4D4D4D"),

  title = "Macierz korelacji parametrów sprzedaży"

)

```

Sales vs Profit (0.48): Istnieje dodatnia korelacja, ale nie jest ona
idealna (r=0.48), co oznacza, że wysoka sprzedaż nie gwarantuje
wysokiego zysku.

Discount vs Profit (-0.22): Potwierdzenie niszczącego wpływu rabatów na
wynik finansowy.

```{r echo=FALSE}

library(ggstatsplot)



ggscatterstats(

  data = dane,

  x = Discount,

  y = Profit,

  type = "nonparametric", # Bo zysk nie ma rozkładu normalnego

  xlab = "Wysokość Rabatu",

  ylab = "Zysk ($)",

  title = "Czy rabaty zabijają zysk?",

  messages = FALSE

)

```

2.  Które kategorie i podkategorie produktów generują najwyższą
    sprzedaż, a które najwyższy zysk?

```{r echo=FALSE}

# Porównanie Zysku między Kategoriami

ggbetweenstats(

  data = dane,

  x = Category,

  y = Profit,

  type = "nonparametric", # Test Kruskala-Wallisa

  plot.type = "boxviolin", # Połączenie pudełka i skrzypiec (jak u kolegów)

  title = "Rentowność Kategorii Produktów",

  xlab = "Kategoria",

  ylab = "Zysk ($)",

  pairwise.display = "significant", # Pokaż tylko istotne różnice

  p.adjust.method = "holm",

  messages = FALSE

)

```

3.  Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej)
    rentowności?

```{r echo=FALSE}

# Tworzymy kolumnę Marża %

dane_region <- dane %>% 

  mutate(Margin = (Profit / Sales) * 100)



ggbetweenstats(

  data = dane_region,

  x = Region,

  y = Margin,

  type = "nonparametric",

  title = "Porównanie Marży Procentowej między Regionami",

  xlab = "Region",

  ylab = "Marża (%)",

  messages = FALSE

)

```

```{r echo=FALSE}

# 1. Liczymy p-value (Czy regiony różnią się zyskiem?)

# Używam base R (kruskal.test), bo jest niezawodny

test_stat <- kruskal.test(Profit ~ Region, data = dane)

p_value <- test_stat$p.value

p_napis <- paste0("Test Kruskala-Wallisa: p = ", format.pval(p_value, digits = 3, eps = 0.001))



# 2. Rysujemy wykres Ridgeline (Górski)

ggplot(dane, aes(x = Profit, y = Region, fill = Region)) +

  

  geom_density_ridges(

    scale = 0.9,           # Jak bardzo górki na siebie zachodzą

    alpha = 0.7,           # Przezroczystość

    quantile_lines = TRUE, # Pokazuje linie kwartyli

    quantiles = 2,         # Pokazuje medianę (środek)

    jittered_points = TRUE, # Dodaje kropki (konkretne zamówienia)

    position = position_points_jitter(width = 0.1, height = 0),

    point_size = 0.5,      # Mniejsze kropki, żeby nie zasłaniały

    point_alpha = 0.2

  ) +

  

  # WAŻNE: Przybliżenie na typowe transakcje (bez tego wykres byłby płaski przez outliery)

  coord_cartesian(xlim = c(-100, 200)) + 



  labs(title = "Rozkład Zysku w Regionach (Ridgeline)",

       subtitle = p_napis,  # Tu wstawi się wynik testu statystycznego

       x = "Zysk z transakcji ($)",

       y = "Region") +



  theme_minimal() +

  theme(legend.position = "none") +

  scale_fill_viridis_d() # Ładna paleta kolorów

```

```{r echo=FALSE}

# 1. Liczymy p-value dla Sprzedaży

test_stat <- kruskal.test(Sales ~ Region, data = dane)

p_value <- test_stat$p.value

p_napis <- paste0("Test Kruskala-Wallisa: p = ", format.pval(p_value, digits = 3, eps = 0.001))



# 2. Wykres

ggplot(dane, aes(x = Sales, y = Region, fill = Region)) +

  

  geom_density_ridges(

    scale = 0.9,

    alpha = 0.7,

    quantile_lines = TRUE,

    quantiles = 2, # Mediana

    jittered_points = TRUE,

    position = position_points_jitter(width = 0.1, height = 0),

    point_size = 0.5,

    point_alpha = 0.2

  ) +

  

  # WAŻNE: Zoom na typowe zakupy (0-500$), bo te za 5000$ spłaszczą wykres

  coord_cartesian(xlim = c(0, 500)) + 



  labs(title = "Wartość zamówień w Regionach (Ridgeline)",

       subtitle = p_napis,

       x = "Wartość sprzedaży ($)",

       y = "Region") +



  theme_minimal() +

  theme(legend.position = "none") +

  scale_fill_viridis_d(option = "magma") # Inna paleta dla odmiany

```

```{r echo=FALSE}

# 1. Liczymy p-value dla Rabatu

test_stat <- kruskal.test(Discount ~ Region, data = dane)

p_value <- test_stat$p.value

p_napis <- paste0("Test Kruskala-Wallisa: p = ", format.pval(p_value, digits = 3, eps = 0.001))



# 2. Wykres

ggplot(dane, aes(x = Discount, y = Region, fill = Region)) +

  

  geom_density_ridges(

    scale = 0.9,

    alpha = 0.7,

    quantile_lines = TRUE,

    quantiles = 2,

    jittered_points = TRUE,

    # Tu mniejszy jitter, bo rabaty są dyskretne (np. 0.2, 0.3)

    position = position_points_jitter(width = 0.01, height = 0),

    point_size = 0.5,

    point_alpha = 0.2

  ) +

  

  labs(title = "Polityka rabatowa w Regionach",

       subtitle = p_napis,

       x = "Wysokość rabatu (0.2 = 20%)",

       y = "Region") +



  theme_minimal() +

  theme(legend.position = "none") +

  scale_fill_viridis_d(option = "cividis")

```

## 3.11. MODEL ANALITYCZNY: Wpływ rabatów na rentowność i wartość klienta (CLV + Logistic Regression)

Poprzednie analizy ujawniły **paradoks rabatowy**: rabaty niszczy zysk
bez znaczącego wzrostu sprzedaży. Aby dać temu głębokie uzasadnienie,
zastosowano dwa komplementarne modele:

1.  **Analiza CLV (Customer Lifetime Value)** - odpowiada na pytanie:
    czy rabaty przyciągają lepszych klientów?
2.  **Regresja logistyczna** - potwierdza i kwantyfikuje, jaki dokładnie
    wpływ ma rabat na prawdopodobieństwo rentowności

Oba modele dają **zgodny werdykt**: rabaty są finansowym błędem bez
żadnego biznesowego uzasadnienia.

------------------------------------------------------------------------

### Model 1: Customer Lifetime Value (CLV) - Analiza opisowa

```{r, echo = FALSE, message = FALSE}
# Segmentacja klientów wg rabatów
df_clv <- df %>%
  mutate(
    discount_category = case_when(
      Discount == 0 ~ "Brak rabatu (0%)",
      Discount > 0 & Discount <= 0.2 ~ "Niski (1-20%)",
      Discount > 0.2 & Discount <= 0.4 ~ "Średni (21-40%)",
      Discount > 0.4 ~ "Wysoki (>40%)"
    )
  ) %>%
  group_by(discount_category, `Customer ID`) %>%
  summarise(
    n_transactions = n(),
    total_sales = sum(Sales, na.rm = TRUE),
    total_profit = sum(Profit, na.rm = TRUE),
    avg_discount = mean(Discount, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(discount_category) %>%
  summarise(
    n_customers = n(),
    avg_transactions_per_customer = mean(n_transactions),
    avg_sales_per_customer = mean(total_sales),
    avg_profit_per_customer = mean(total_profit),
    total_profit = sum(total_profit),
    profitability_rate = sum(total_profit > 0) / n() * 100,
    avg_discount = mean(avg_discount),
    .groups = "drop"
  ) %>%
  arrange(factor(discount_category, 
                 levels = c("Brak rabatu (0%)", "Niski (1-20%)", 
                           "Średni (21-40%)", "Wysoki (>40%)")))

# Główne wykresy CLV
plot_ly(
  data = df_clv,
  x = ~discount_category,
  y = ~avg_profit_per_customer,
  type = "bar",
  marker = list(color = ~avg_profit_per_customer, colorscale = "RdYlGn", showscale = FALSE),
  text = ~paste0("$", round(avg_profit_per_customer, 2)),
  textposition = "outside",
  name = "Średni zysk na klienta"
) %>%
  layout(
    title = "Wpływ rabatu na zysk klienta (CLV)",
    xaxis = list(title = "Kategoria rabatu", tickangle = -20),
    yaxis = list(title = "Średni zysk na klienta ($)"),
    margin = list(b = 80)
  )

# Customer Stickiness
plot_ly(
  data = df_clv,
  x = ~discount_category,
  y = ~avg_transactions_per_customer,
  type = "bar",
  marker = list(color = "steelblue"),
  text = ~round(avg_transactions_per_customer, 2),
  textposition = "outside",
  name = "Liczba transakcji na klienta"
) %>%
  layout(
    title = "Customer Stickiness - ile razy wracają klienci?",
    xaxis = list(title = "Kategoria rabatu", tickangle = -20),
    yaxis = list(title = "Średnia liczba transakcji"),
    margin = list(b = 80)
  )

# Podsumowanie tabelaryczne
df_clv
```

------------------------------------------------------------------------

### Model 2: Logistic Regression - Potwierdzenie statystyczne

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Przygotowanie danych
df_model <- df %>%
  mutate(
    rentowny = factor(ifelse(Profit > 0, 1, 0), levels = c(0, 1))
  ) %>%
  filter(!is.na(rentowny), !is.na(Discount), !is.na(Sales), !is.na(Quantity))

# Train/test split
set.seed(123)
train_idx <- sample(1:nrow(df_model), 0.7 * nrow(df_model))
train_data <- df_model[train_idx, ]
test_data <- df_model[-train_idx, ]

# Model logistyczny
model_log <- glm(rentowny ~ Discount + Sales + Quantity, 
                 data = train_data, 
                 family = binomial(link = "logit"))

coefficients <- coef(model_log)

# Tablica współczynników
coef_table <- data.frame(
  Zmienna = c("Intercept", "Discount", "Sales", "Quantity"),
  Współczynnik = round(coefficients, 4),
  `Odds Ratio` = round(exp(coefficients), 4),
  Wpływ = c(
    "Bazowe szanse",
    "Każdy +1% rabatu ZMNIEJSZA szanse rentowności o ~100%",
    "Każdy +$1 sprzedaży: -0.03% wpływu (praktycznie brak)",
    "Każda +1 jednostka: +7.35% wpływu (nieistotne)"
  )
)

knitr::kable(coef_table, row.names = FALSE)
```

#### Wydajność modelu:

```{r, echo = FALSE, message = FALSE, warning = FALSE}
# Predykcje
pred_prob <- predict(model_log, newdata = test_data, type = "response")
pred_class <- ifelse(pred_prob > 0.5, 1, 0)

# Metryki
tp <- sum(pred_class == 1 & as.numeric(test_data$rentowny) == 2)
tn <- sum(pred_class == 0 & as.numeric(test_data$rentowny) == 1)
fp <- sum(pred_class == 1 & as.numeric(test_data$rentowny) == 1)
fn <- sum(pred_class == 0 & as.numeric(test_data$rentowny) == 2)

accuracy <- (tp + tn) / (tp + tn + fp + fn)
sensitivity <- tp / (tp + fn)
specificity <- tn / (tn + fp)

# ROC curve
n_thresholds <- 100
roc_data <- data.frame()
for (t in seq(0, 1, length.out = n_thresholds)) {
  pred_t <- ifelse(pred_prob >= t, 1, 0)
  tp_t <- sum(pred_t == 1 & as.numeric(test_data$rentowny) == 2)
  tn_t <- sum(pred_t == 0 & as.numeric(test_data$rentowny) == 1)
  fp_t <- sum(pred_t == 1 & as.numeric(test_data$rentowny) == 1)
  fn_t <- sum(pred_t == 0 & as.numeric(test_data$rentowny) == 2)
  
  sens_t <- ifelse((tp_t + fn_t) > 0, tp_t / (tp_t + fn_t), 0)
  spec_t <- ifelse((tn_t + fp_t) > 0, tn_t / (tn_t + fp_t), 0)
  
  roc_data <- rbind(roc_data, data.frame(fpr = 1 - spec_t, tpr = sens_t))
}

# AUC
roc_sorted <- roc_data[order(roc_data$fpr), ]
auc_score <- sum(diff(roc_sorted$fpr) * (roc_sorted$tpr[-length(roc_sorted$tpr)] + roc_sorted$tpr[-1]) / 2)

# Wizualizacja ROC
plot_ly(
  data = roc_data,
  x = ~fpr,
  y = ~tpr,
  type = 'scatter',
  mode = 'lines',
  name = paste0('ROC (AUC = ', round(auc_score, 3), ')'),
  line = list(color = 'rgb(0, 100, 200)', width = 3)
) %>%
  add_trace(x = c(0, 1), y = c(0, 1), type = 'scatter', mode = 'lines',
    name = 'Random', line = list(color = 'gray', dash = 'dash')) %>%
  layout(
    title = 'ROC Curve - Model predykcji rentowności',
    xaxis = list(title = 'False Positive Rate'),
    yaxis = list(title = 'True Positive Rate')
  )

cat("
**Metryki modelu:**
- Dokładność (Accuracy):** ", round(accuracy*100, 1), "%
- **Czułość (Sensitivity):** ", round(sensitivity*100, 1), "%
- **Specyficzność (Specificity):** ", round(specificity*100, 1), "%
- **AUC:** ", round(auc_score, 3))
```

------------------------------------------------------------------------

### Wnioski co do rabatów

**1. RABAT NISZCZY RENTOWNOŚĆ KOMPLETNIE**
   - CLV: Klient bez rabatu = $43.86 zysku, klient z >40% rabatu = $-128.75 (-394%)
   - LOGISTYKA potwierdza: każdy +1% rabatu zmniejsza szanse rentowności o ~100% (OR = 0.0000)
   - **Wniosek:** Nie ma marginalnego wpływu - rabat to binarna zmienna: rentowny ALBO stratny

**2. RABATY NIE PRZYCIĄGAJĄ LEPSZYCH KLIENTÓW**
   - CLV: Klienci bez rabatu robią 6.32 transakcji, klienci z rabatami >40% robią 1.97 transakcji (-68.8%)
   - To nie stickiness - to ucieczka klientów (jedno-razowe złe doświadczenie)
   - **Wniosek:** Rabaty przyciągają klientów jednorazowych, nie lojalistów

**3. RABATY PRZYCIĄGAJĄ KLIENTÓW STRATNYCH**
   - CLV: 100% klientów z rabatami >40% generuje straty
   - LOGISTYKA: Model osiąga 99.5% sensitivity - czyli prawie idealne zidentyfikowanie klientów rentownych (bez rabatu)
   - **Wniosek:** Rabat jest wiarygodnym predyktorem ruiny finansowej transakcji

**4. SPRZEDAŻ I ILOŚĆ NIE RATUJĄ RABATÓW**
   - LOGISTYKA: Sprzedaż (-0.03%), Ilość (+7.35%) - praktycznie żaden wpływ
   - CLV: Wzrost transakcji jest zbyt mały (-68.8%) i przy tym wszyscy generują straty
   - **Wniosek:** Nie ma ekonomicznego uzasadnienia - wolumen nie rekompensuje strat marż

**5. MODEL MA PRAWIE IDEALNĄ MOCĄ DYSKRYMINACJI**
   - AUC = 0.934 (prawie idealne)
   - Sensitivity = 99.5% (prawie wszyscy rentowni klienci poprawnie zidentyfikowani)
   - **Wniosek:** Rabat jest NIEZWYKLE SILNYM predyktorem - jeden z najważniejszych w decyzji o rentowności

---

**REKOMENDACJA BIZNESOWA:**

**PRZESTAĆ stosować rabaty powyżej 20%** - każdy dodatkowy 1% to zmniejszenie szans rentowności o 100%

✓ **NOWA STRATEGIA:**
   - Utrzymać klientów bez rabatu ($43.86 zysku na klienta)
   - Maksymalnie rabaty 0-20% przy zdużych zamówieniach (ponad $500)
   - Wprowadzić program lojalnościowy (punkty, early access) zamiast rabatów
   - Rezultat: utrzymanie rentowności + wzrost stickiness

**ILOŚĆ PIENIĘDZY NA STOLE:** W grupie >40% rabatów średni klient generuje straty zamiast zysku ($-128.75). Jeśli ta grupa to ~470 klientów rocznie, to jest SETKI TYSIĘCY ZŁOTYCH strat rocznie, które można uniknąć

# 6. Podsumowanie

Przeprowadzona analiza pozwala na sformułowanie następujących
rekomendacji biznesowych:

Ograniczenie rabatów: Rabaty powyżej 20% w kategorii Meble są głównym
źródłem strat. Należy zrewidować politykę cenową w tym segmencie.

Fokus na Technologię: Kategoria Technology generuje najwyższą marżę i
powinna być priorytetem w kampaniach marketingowych.

Sezonowość: Należy przygotować zapasy na szczyt sprzedażowy w IV
kwartale, pamiętając jednak o kontroli marży w tym okresie.
