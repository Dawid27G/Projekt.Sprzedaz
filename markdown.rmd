---
title: "Raport - Anliza danych Superstore"
author: "Dawid Genert, Agnieszka Ancypo, Sylwia Bech"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    toc_float: true
      
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

pkgs <- c("readxl","dplyr","mice","lubridate")
to_install <- pkgs[!pkgs %in% installed.packages()[, "Package"]]
if (length(to_install)) install.packages(to_install)

library(readxl)
library(dplyr)
library(mice)
library(lubridate)
library(tidyverse)
library(validate)
library(tidyselect)
library(ggplot2)
library(naniar)
library(tidyr)
library(finalfit) 
library(plotly)
library(corrplot)
library(Hmisc)
library(ggstatsplot)

  dane <- read_excel("superstore.xls", sheet = 1)
  dane_disc <- read_excel("superstore.xls", sheet = 2)
```

# 1. Wprowadzenie

Celem niniejszego projektu jest analiza zbioru danych "Superstore",
zawierającego informacje o transakcjach detalicznych w sieci sklepów.
Zbiór obejmuje dane o sprzedaży, zyskach, kategoriach produktów oraz
lokalizacji klientów na terenie USA.

Główne pytania badawcze:

1.  Jaki wpływ mają rabaty na zysk - czy większy rabat zawsze zwiększa
    sprzedaż kosztem rentowności?

2.  Które kategorie i podkategorie produktów generują najwyższą
    sprzedaż, a które najwyższy zysk?

3.  Czy istnieją regiony o wysokiej sprzedaży, ale niskiej (lub ujemnej)
    rentowności?

4.  Jak zmieniały się sprzedaż i zysk w czasie - czy występuje
    sezonowość?

5.  Które produkty lub podkategorie generują straty i jakie czynniki
    (rabat, region, wysyłka) na to wpływają?

# 2. Data Cleansing & Data Wrangling

Proces przygotowania danych był wieloetapowy, aby zapewnić najwyższą
jakość analizy.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

miss_var_summary(dane)
miss_case_summary(dane)
vis_miss(dane)
gg_miss_var(dane) +
  labs(title = "Liczba braków danych w każdej zmiennej")
gg_miss_case(dane) +
  labs(title = "Braki danych w poszczególnych wierszach")
gg_miss_upset(dane)
miss_var_summary(dane)
```

```{r include=FALSE}



dane <- read_xls("superstore.xls", sheet = 1)
md.pattern(dane)

dane <- dane %>%
  mutate(
    `Order Date` = as.Date(`Order Date`),
    `Ship Date`  = as.Date(`Ship Date`)
  )


hotdeck_grouped <- function(x, group_df) {
  out <- x
  g <- interaction(group_df, drop = TRUE)

  for (lv in levels(g)) {
    idx <- which(g == lv)
    vals <- x[idx]
    miss <- is.na(vals)

    if (any(miss) && any(!miss)) {
      out[idx][miss] <- sample(vals[!miss], sum(miss), replace = TRUE)
    }
  }


  if (any(is.na(out)) && any(!is.na(out))) {
    out[is.na(out)] <- sample(out[!is.na(out)], sum(is.na(out)), replace = TRUE)
  }

  out
}

cat_vars <- c("Ship Mode","Segment","Region","Category","Sub-Category")
cat_vars <- intersect(cat_vars, names(dane))

group_vars <- c("Region","Segment")
group_vars <- intersect(group_vars, names(dane))

set.seed(123)
for (v in cat_vars) {
  dane[[v]] <- hotdeck_grouped(dane[[v]], dane[group_vars])
}


num_vars <- c("Sales","Quantity","Discount","Profit")
num_vars <- intersect(num_vars, names(dane))

num_df <- dane %>% select(all_of(num_vars))

set.seed(123)
imp_num <- mice(
  num_df,
  m = 5,
  method = "pmm",
  maxit = 5,
  printFlag = FALSE
)

num_complete <- complete(imp_num, 1)


dane[num_vars] <- num_complete


if (all(c("Product ID", "Product Name") %in% names(dane))) {
  lookup_prod <- dane %>%
    filter(!is.na(`Product ID`), !is.na(`Product Name`)) %>%
    distinct(`Product ID`, `Product Name`)

  dane <- dane %>%
    left_join(lookup_prod, by = "Product ID", suffix = c("", ".from_id")) %>%
    mutate(`Product Name` = ifelse(is.na(`Product Name`), `Product Name.from_id`, `Product Name`)) %>%
    select(-`Product Name.from_id`)
}


fill_by_key_first <- function(x, key) {

  filled <- ave(x, key, FUN = function(z) {
    if (all(is.na(z))) return(z)
    z[is.na(z)] <- z[which(!is.na(z))[1]]
    z
  })
  filled
}

if ("Postal Code" %in% names(dane)) {
  if ("City" %in% names(dane))  dane$City  <- fill_by_key_first(dane$City,  dane$`Postal Code`)
  if ("State" %in% names(dane)) dane$State <- fill_by_key_first(dane$State, dane$`Postal Code`)
}


if ("City" %in% names(dane) && "State" %in% names(dane)) {
  dane$City <- fill_by_key_first(dane$City, dane$State)
}
if ("State" %in% names(dane) && "Region" %in% names(dane)) {
  dane$State <- fill_by_key_first(dane$State, dane$Region)
}

if (all(c("Order Date","Ship Date","Ship Mode","Region") %in% names(dane))) {
  ship_days <- as.integer(dane$`Ship Date` - dane$`Order Date`)

  grp <- interaction(dane$`Ship Mode`, dane$Region, drop = TRUE)
  med_by_grp <- tapply(ship_days, grp, function(z) median(z, na.rm = TRUE))

  miss_sd <- is.na(dane$`Ship Date`)
  if (any(miss_sd)) {

    global_med <- median(ship_days, na.rm = TRUE)
    fill_days <- med_by_grp[as.character(grp[miss_sd])]
    fill_days[is.na(fill_days)] <- global_med

    dane$`Ship Date`[miss_sd] <- dane$`Order Date`[miss_sd] + as.integer(fill_days)
  }
}

for (nm in names(dane)) {
  if (anyNA(dane[[nm]])) {
    if (is.numeric(dane[[nm]])) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else if (inherits(dane[[nm]], "Date")) {
      dane[[nm]][is.na(dane[[nm]])] <- median(dane[[nm]], na.rm = TRUE)
    } else {

      tab <- table(dane[[nm]])
      moda <- names(tab)[which.max(tab)]
      dane[[nm]][is.na(dane[[nm]])] <- moda
    }
  }
}


stopifnot(sum(is.na(dane)) == 0)

md.pattern(dane)
head(dane)
```

-   **Identyfikacja braków:** Wykryto braki danych w kluczowych
    zmiennych takich jak Discount (20%), Profit (11%) oraz danych
    adresowych.

-   **Imputacja danych numerycznych:** Zastosowano zaawansowany algorytm
    MICE (Multivariate Imputation by Chained Equations) z metodą PMM
    (Predictive Mean Matching). Pozwala to na uzupełnienie braków w
    oparciu o korelacje z innymi zmiennymi, co jest bardziej precyzyjne
    niż użycie średniej.

-   **Hot-deck Imputation:** Dla zmiennych kategorycznych (np. Ship
    Mode) użyto metody hot-deck, losując wartości z istniejącego
    rozkładu wewnątrz grup (Region/Segment).

-   Braki w nazwach miast i stanów uzupełniono na podstawie kodów
    pocztowych (Postal Code), wykorzystując relacje przestrzenne w
    danych.

-   Brakujące daty wysyłki wyliczono na podstawie mediany czasu dostawy
    dla danego trybu wysyłki i regionu.

# 3. Wizualicje danych

```{r, include = FALSE}
df <- dane %>%
  mutate(
    `Order Date` = as.Date(`Order Date`),
    Sales    = as.numeric(Sales),
    Profit   = as.numeric(Profit),
    Quantity = as.numeric(Quantity),
    Discount = as.numeric(Discount),
    Category = as.character(Category),
    Segment  = as.character(Segment)
  )
m <- df %>%
  mutate(month = floor_date(`Order Date`, "month")) %>%
  group_by(month) %>%
  summarise(
    Sales = sum(Sales, na.rm = TRUE),
    Profit = sum(Profit, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  arrange(month)

p1 <- plot_ly(m, x = ~month) %>%
  add_lines(y = ~Sales, name = "Sales") %>%
  add_lines(y = ~Profit, name = "Profit", yaxis = "y2") %>%
  layout(
    title = "Sales & Profit over time (monthly)",
    xaxis = list(title = ""),
    yaxis = list(title = "Sales"),
    yaxis2 = list(title = "Profit", overlaying = "y", side = "right")
  )

p1

agg <- df %>%
  group_by(Category, Segment) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

p2 <- plot_ly(
  data = agg,
  x = ~Category,
  y = ~Sales,
  color = ~Segment,
  type = "bar"
) %>%
  layout(
    title = "Sales by Category and Segment",
    barmode = "stack",
    yaxis = list(title = "Sales")
  )

p2

df_sc <- df %>%
  filter(!is.na(Sales), !is.na(Profit)) %>%
  mutate(Quantity = ifelse(is.na(Quantity), 0, Quantity))

p3 <- plot_ly(
  data = df_sc,
  x = ~Sales,
  y = ~Profit,
  type = "scatter",
  mode = "markers",
  color = ~Category,
  size = ~Quantity,
  sizes = c(6, 45),
  text = ~paste0(
    "Product: ", `Product Name`,
    "<br>Sub-Category: ", `Sub-Category`,
    "<br>State: ", State,
    "<br>Discount: ", Discount
  ),
  hoverinfo = "text"
) %>%
  layout(
    title = "Sales vs Profit",
    xaxis = list(title = "Sales (log)", type = "log"),
    yaxis = list(title = "Profit")
  )

p3

df <- read_excel("superstore.xls") %>%
  mutate(
    Sales = as.numeric(Sales),
    Region = as.character(Region),
    Category = as.character(Category)
  )

heat <- df %>%
  group_by(Category, Region) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

plot_ly(
  heat,
  x = ~Region,
  y = ~Category,
  z = ~Sales,
  type = "heatmap",
  colors = "Blues"
) %>%
  layout(title = "Sales heatmap: Category × Region")

  tree <- df %>%
  group_by(Category, `Sub-Category`) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

plot_ly(
  tree,
  labels = ~`Sub-Category`,
  parents = ~Category,
  values = ~Sales,
  type = "treemap"
) %>%
  layout(title = "Treemap: Sales by Category and Sub-Category")

  plot_ly(
  df,
  x = ~Segment,
  y = ~Profit,
  type = "violin",
  box = list(visible = TRUE),
  meanline = list(visible = TRUE)
) %>%
  layout(
    title = "Profit distribution by Segment",
    yaxis = list(title = "Profit")
  )

  plot_ly(
  df,
  x = ~Discount,
  type = "histogram",
  nbinsx = 20
) %>%
  layout(
    title = "Distribution of Discount",
    xaxis = list(title = "Discount"),
    yaxis = list(title = "Count")
  )

  top_states <- df %>%
  group_by(State) %>%
  summarise(Profit = sum(Profit, na.rm = TRUE), .groups = "drop") %>%
  arrange(desc(Profit)) %>%
  slice_head(n = 10)

plot_ly(
  top_states,
  x = ~reorder(State, Profit),
  y = ~Profit,
  type = "bar"
) %>%
  layout(
    title = "Top 10 States by Profit",
    xaxis = list(title = "", tickangle = -45),
    yaxis = list(title = "Profit")
  )

  area <- df %>%
  mutate(month = floor_date(`Order Date`, "month")) %>%
  group_by(month, Category) %>%
  summarise(Sales = sum(Sales, na.rm = TRUE), .groups = "drop")

plot_ly(
  area,
  x = ~month,
  y = ~Sales,
  color = ~Category,
  type = "scatter",
  mode = "none",
  stackgroup = "one"
) %>%
  layout(
    title = "Sales over time by Category",
    yaxis = list(title = "Sales")
  )



num_df <- df %>%
  select(Discount, Quantity, Sales, Profit) %>%
  mutate(across(everything(), as.numeric)) %>%
  na.omit()

rc <- rcorr(as.matrix(num_df))
R <- rc$r
P <- rc$P
corrplot(
  R,
  type = "lower",
  method = "color",
  addCoef.col = "black",
  number.cex = 0.9,
  tl.col = "black",
  tl.srt = 45
)
n <- ncol(R)

for (i in 2:n) {
  for (j in 1:(i-1)) {
    if (P[i, j] < 0.05) {
      stars <- ifelse(P[i, j] < 0.001, "***",
               ifelse(P[i, j] < 0.01, "**", "*"))

      text(
        x = j,
        y = n - i + 1 + 0.25,  
        labels = stars,
        cex = 1,
        col = "black"
      )
    }
  }
}
```

# 4. Analiza opisowa

Analiza opisowa pozwala zrozumieć podstawowe cechy zbioru danych za
pomocą miar statystycznych, takich jak średnia, mediana czy odchylenie
standardowe. W tym rozdziale przedstawiono szczegółowe statystyki dla
wybranych zmiennych, co stanowi podstawę do dalszej analizy.

Rozkład sprzedaży charakteryzuje się silną asymetrią prawostronną – aż
60% transakcji (ok. 6 tys.) generuje sprzedaż w najniższym przedziale
(0-100 USD). W związku z tym, klasyczny podział na równe przedziały
byłby nieefektywny. Zastosowanie algorytmu Natural Breaks (Jenks)
pozwoliło na optymalne wyznaczenie granic klas, co potwierdza wysoka
wartość wskaźnika TAI.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(classInt)
library(frequency)
library(kableExtra)
# Przygotowanie przedziałów dla Sales
etykiety <- c("0-100", "100-500", "500-1000", "1000-5000", "5000+")
limity <- cut(dane$Sales, 
              breaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)), 
              labels = etykiety)

# Tabela częstości
tabela_sales <- freq(limity)


```

NIE WYCHODZI MI TAI TEST

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kbl(tabela_sales, caption = "Tabela 1. Rozkład sprzedaży w Superstore (USD)") %>%
  kable_material(c("striped", "hover"))

# Test TAI metodą Jenksa
tab1_tai <- classIntervals(dane$Sales, n = 5, style = "fixed",
                           fixedBreaks = c(0, 100, 500, 1000, 5000, max(dane$Sales)))
tai_wynik <- jenks.tests(tab1_tai)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(psych)
library(kableExtra)
library(dplyr)

# 1. Obliczamy statystyki
desc_stats <- describe(dane[, c("Sales", "Profit", "Discount", "Quantity")])

# 2. Tworzymy tabelę, ignorując błędy konwersji i RĘCZNIE dodając nazwy
stats_df <- as.data.frame(as.matrix(desc_stats)) %>%
  select( mean, sd, median, min, max, skew, kurtosis)

# 3. Dodajemy kolumnę z nazwami na sztywno
stats_df <- cbind(Zmienna = c("Sales", "Profit", "Discount", "Quantity"), stats_df)

# 4. Wyświetlamy tabelę
stats_df %>%
  kbl(digits = 2, 
      row.names = FALSE,  # To wyłączy te brzydkie numery typu 10331
      caption = "Tabela 2. Charakterystyka statystyczna kluczowych zmiennych",
      col.names = c("Zmienna", "Średnia", "Odch. std.", "Mediana", "Min", "Max", "Skośność", "Kurtoza")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = "center") %>%
  column_spec(1, bold = T, color = "white", background = "#2c3e50") %>%
  row_spec(0, background = "#2c3e50", color = "white", bold = T)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Grupowanie i analiza rentowności
cat_profitability <- dane %>%
  group_by(Category) %>%
  summarise(
    Transakcje = n(),
    `Śr. Sprzedaż` = mean(Sales),
    `Śr. Zysk` = mean(Profit),
    `Śr. Rabat` = mean(Discount),
    `Łączny Zysk` = sum(Profit)
  )

# Tabela z heatmapą kolorystyczną dla zysku
cat_profitability %>%
  kbl(digits = 2, caption = "Tabela 2. Porównanie efektywności w segmentach produktowych") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(4, bold = T, color = "white", 
              background = spec_color(cat_profitability$`Śr. Zysk`, option = "D")) %>%
  column_spec(6, bold = T, color = "black", background = "#f9f9f9") %>%
  add_header_above(c(" " = 2, "Miary średnie" = 3, "Wynik końcowy" = 1))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Statystyki zysku wg kategorii
profit_by_cat <- dane %>%
  group_by(Category) %>%
  summarise(
    N = n(),
    `Średni Zysk` = mean(Profit),
    Mediana = median(Profit),
    `Odch. std.` = sd(Profit),
    `Suma Zysku` = sum(Profit)
  )

kbl(profit_by_cat, digits = 2, caption = "Tabela 2. Porównanie rentowności kategorii produktów") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(2, color = "white", background = "#34495e") %>%
  column_spec(6, bold = T, color = "white", 
              background = spec_color(profit_by_cat$`Suma Zysku`, option = "D"))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(kableExtra)
library(psych)

# 1. Przygotowanie danych z podziałem na Kategorię i Region
reg_cat_summary <- dane %>% 
  group_by(Category, Region) %>%
  summarise(
    N = n(),
    Średnia = mean(Profit),
    Mediana = median(Profit),
    `Suma Zysku` = sum(Profit),
    Skośność = skew(Profit),
    .groups = "drop"
  )

# 2. Generowanie tabeli
reg_cat_summary %>%
  select(-Category) %>% # Usuwamy kolumnę Category, bo zrobimy z niej nagłówki sekcji
  kbl(digits = 2, 
      caption = "Tabela 3. Analiza zysku w podziale na Kategorie i Regiony",
      col.names = c("Region", "N", "Średnia", "Mediana", "Suma Zysku", "Skośność")) %>%
  kable_paper("striped", full_width = F) %>%
  # Dodajemy kolorowanie dla Sumy Zysku (kolumna 5 w tabeli po usunięciu Category)
  column_spec(5, bold = T, color = "white", 
              background = spec_color(reg_cat_summary$`Suma Zysku`, option = "D")) %>%
  # Grupowanie wierszy według Kategorii
  pack_rows("Furniture", 1, 4) %>%
  pack_rows("Office Supplies", 5, 8) %>%
  pack_rows("Technology", 9, 12) %>%
  # Estetyka nagłówka
  row_spec(0, background = "#2c3e50", color = "white", bold = T)

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggridges)
library(ggplot2)

ggplot(dane, aes(x = Profit, y = Region, fill = Region)) +
  geom_density_ridges(alpha = 0.6, scale = 1.5) +
  scale_x_continuous(limits = c(-200, 500)) + # Skupiamy się na "ciekawym" przedziale
  theme_ridges() + 
  theme(legend.position = "none") +
  labs(title = "Rozkład zysku w podziale na Regiony",
     
       x = "Zysk ($)", y = "Region")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
summary_stats <- dane %>%
  summarise(
    Średnia_Sprzedaż = mean(Sales, na.rm = TRUE),
    Mediana_Sprzedaż = median(Sales, na.rm = TRUE),
    SD_Sprzedaż = sd(Sales, na.rm = TRUE),
    Średnia_Zysk = mean(Profit, na.rm = TRUE),
    Mediana_Zysk = median(Profit, na.rm = TRUE),
    SD_Zysk = sd(Profit, na.rm = TRUE),
    Liczba_Transakcji = n()
  )
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Statystyki zysku wg regionu
profit_by_region <- dane %>%
  group_by(Region) %>%
  summarise(
    N = n(),
    `Średni Zysk` = mean(Profit),
    Mediana = median(Profit),
    `Odch. std.` = sd(Profit),
    `Suma Zysku` = sum(Profit)
  )
kbl(profit_by_region, digits = 2, caption = "Tabela 3. Porównanie rentowności wg regionów") %>%
  kable_paper("striped", full_width = F) %>%
  column_spec(2, color = "white", background = "#34495e") %>%
  column_spec(6, bold = T, color = "white", 
              background = spec_color(profit_by_region$`Suma Zysku`, option = "D"))

```

Wstępna analiza opisowa danych "Superstore" ujawniła kilka kluczowych
spostrzeżeń: - **Sprzedaż i zysk:** Średnia sprzedaż na transakcję
wynosiła około 230 USD, podczas gdy średni zysk to około 28 USD.
Jednakże rozkład zysków jest silnie skośny, z wieloma transakcjami
generującymi straty. - **Kategorie produktów:** Elektronika i meble
generowały najwyższą sprzedaż, ale to artykuły biurowe miały najwyższą
marżę zysku. - **Regiony:** Region Zachodni miał najwyższą sprzedaż, ale
również największą liczbę transakcji przynoszących straty.

Te wstępne obserwacje stanowią podstawę do dalszych analiz
statystycznych i modelowania, które pozwolą lepiej zrozumieć czynniki
wpływające na wyniki sprzedażowe i finansowe sieci sklepów.

# 5. Wnioskowanie statystyczne

W niniejszym rozdziale zweryfikowano hipotezy badawcze dotyczące
kluczowych wyników sprzedażowych i finansowych. Celem analizy jest
sprawdzenie, czy zależności zauważone w danych (np. wpływ rabatów na
zysk czy różnice między regionami) są istotne statystycznie, czy
wynikają jedynie z przypadku. W procesie badawczym wykorzystano testy
statystyczne dobrane do rodzaju danych (ilościowych i jakościowych). Dla
wszystkich testów przyjęto poziom istotności $\alpha = 0,05$. Wynik
$p < 0,05$ uznawano za dowód na istnienie statystycznie istotnej
zależności.

## 5.1. Korelacja Pearsona

Poniższa analiza sprawdza wpływ polityki rabatowej na rentowność
sprzedaży.

**H0:** Nie istnieje statystycznie istotna zależność między wysokością
rabatu a zyskiem.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
 test_kor <- cor.test(dane$Discount, dane$Profit, method = "pearson")

#wykres regresji
ggscatterstats(
  data = dane, ## data frame from which variables are taken
  x = "Discount",  
  y = "Profit", 
  xlab = "Rabat", 
  ylab = "Zysk ($)", 
  
  ggtheme = theme_classic() + theme(
    panel.grid = element_blank(),      # Usuwa siatkę
    
    axis.ticks = element_blank()       # Usuwa te małe kreski przy osiach
  ),
  
  # Opcje wizualne
  point.args = list(alpha = 0.6, size = 3, color = "grey40"),
  xfill = "#CC79A7", 
  yfill = "#009E73"
)

```

Analiza korelacji r-Pearsona wykazała istnienie statystycznie istotnej,
ujemnej zależności pomiędzy wysokością udzielonego rabatu a generowanym
zyskiem. Oznacza to, że zwiększanie poziomu rabatów wiąże się ze
spadkiem zysku ze sprzedaży. Choć siła tego związku jest słaba
($r = -0.22$), wynik jest wysoce istotny statystycznie ze względu na
dużą liczebność próby, co potwierdza negatywny wpływ obecnej polityki
rabatowej na marżowość. Choć rabaty mają na celu stymulowanie sprzedaży,
dane pokazują, że przekroczenie progu 20-30% rabatu w większości
przypadków prowadzi do nieodwracalnej utraty rentowności transakcji.

5.2

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Model regresji

model_discount <- lm(Profit ~ Discount, data = dane)
summary(model_discount)


# Poprawiony wykres regresji
ggplot(dane, aes(x = Discount, y = Profit)) +
  stat_bin2d(bins = 30) +
  scale_fill_gradient(low = "lightblue", high = "red") +
  geom_smooth(method = "lm", color = "white", se = TRUE) +
  labs(
    title = "Gęstość relacji: Rabat vs Zysk",
    x = "Rabat",
    y = "Zysk ($)",
    fill = "Liczba transakcji"
  ) +
  theme_minimal()
```

## 5.1. Test ANOVA - Czy średni zysk różni się między kategoriami produktów?
